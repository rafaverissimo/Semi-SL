{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Projet MI203 - Semi Supervised Learning.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"papermill":{"default_parameters":{},"duration":467.866169,"end_time":"2021-03-23T08:54:39.191745","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2021-03-23T08:46:51.325576","version":"2.2.2"}},"cells":[{"cell_type":"code","metadata":{"id":"SwRVyUbBxbVq"},"source":["import os\n","import glob\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.nn.init as init\n","import torchvision.models as models\n","from torchvision import transforms\n","import torchvision.transforms as transforms\n","import torch.utils.data as data\n","import torchvision\n","import random\n","import math\n","from torch.autograd import Variable\n","import matplotlib.pyplot as plt\n","from torch.nn.functional import kl_div, softmax, log_softmax\n","import torch.optim as optim\n","import torch.utils.data as data\n","from os.path import exists, join, split\n","from os import listdir\n","from os.path import join\n","from PIL import Image\n","import random\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","import sys\n","DIR = 'gdrive/My Drive/Colab Notebooks/Projeto MI203/'\n","sys.path.append(DIR)\n","import augmentations\n","from numpy.random import default_rng"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HlybZiqzxbVw"},"source":["num_class = 10 #number of classes\n","seed=111 #seed for the algorithm\n","num_train =100 # number of training image by classe\n","cutout=16  # parameter for the cutout\n","valid_size = 500  #Validation set size\n","bn_momentum = 0.9\n","\n","\n","#Dataset loading\n","CIFAR10_train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=None, download=True)\n","CIFAR10_test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=None, download=True)\n","np.random.seed(seed=seed)\n","permutation=np.random.permutation(len(CIFAR10_train_dataset.targets))\n","\n","Original_train_data_x = (CIFAR10_train_dataset.data)\n","Original_train_data_y = np.array(CIFAR10_train_dataset.targets)\n","Original_train_data_x = Original_train_data_x[permutation]\n","Original_train_data_y = Original_train_data_y[permutation]\n","\n","Original_test_data_x = CIFAR10_test_dataset.data\n","Original_test_data_y = np.array(CIFAR10_test_dataset.targets)\n","\n","\n","#Selection of 1000 labeled images for training and 5000 for validation\n","incr_class = torch.zeros(num_class)\n","train_idx_dico = {} #labeled images index dictionnary\n","\n","for i in range(num_class):\n","    train_idx_dico[str(i)] = []\n","\n","valid_idx = np.zeros(num_class * valid_size, dtype=np.int32) #Validation images indexes (2000)\n","incr_t = 0\n","incr_v = 0\n","incrtotal = 0\n","\n","for idx in range(len(Original_train_data_y)):\n","    class_y = Original_train_data_y[idx]\n","    incrtotal += 1\n","\n","    train_idx_dico[str(class_y)].append(idx)\n","    incr_class[class_y] += 1 #Count the number of image per class\n","    incr_t += 1\n","\n","\n","train_idx = np.zeros(num_class * num_train, dtype=np.int32) #Train labeled images indexes (250)\n","list_train_id = []\n","list_unalabel_id = []\n","valid_idx = []\n","unlabel_idx_dico = {}\n","for i in range(num_class):\n","    unlabel_idx_dico[str(i)] = []\n","for i in range(num_class):\n","    list_train_id = list_train_id + train_idx_dico[str(i)][0:num_train]\n","    valid_idx =valid_idx + train_idx_dico[str(i)][num_train:num_train+valid_size]\n","    list_unalabel_id = list_unalabel_id + train_idx_dico[str(i)][num_train+valid_size::]\n","    unlabel_idx_dico[str(i)] = train_idx_dico[str(i)][num_train::]\n","\n","#Get labeled and unlabeled data\n","\n","x_train = Original_train_data_x[[int(i) for i in list_train_id]]\n","y_train = Original_train_data_y[[int(i) for i in list_train_id]]\n","\n","x_unlabeled = Original_train_data_x[[int(i) for i in list_unalabel_id]]\n","y_unlabeled = Original_train_data_y[[int(i) for i in list_unalabel_id]]\n","\n","#Get validation set data\n","x_valid = Original_train_data_x[[int(i) for i in valid_idx]]\n","y_valid = Original_train_data_y[[int(i) for i in valid_idx]]\n","\n","# Printing the size of the training, validation and test sets\n","print('Number of training examples: ' + str(x_train.shape[0]))\n","print('Number of unlabeled examples: ' + str(x_unlabeled.shape[0]))\n","print('Number of validation examples: ' + str(x_valid.shape[0]))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6fJorUY9H5oQ"},"source":["# Image Transformation and DataLoader creation"]},{"cell_type":"code","metadata":{"id":"xRIV6IVo6h8P"},"source":["batch_size = 64\n","class Dataset_sub_CIFAR(data.Dataset):\n","\n","    def __init__(self, data_feature, data_target,transform,phase='label'):\n","        self.data_feature = data_feature\n","        self.data_target = data_target\n","        self.transform = transform\n","        self.phase=phase\n","\n","\n","\n","    def __len__(self):\n","        return len(self.data_feature)\n","\n","    def __getitem__(self, index):\n","        # load image as ndarray type (Height * Width * Channels)\n","        # be carefull for converting dtype to np.uint8 [Unsigned integer (0 to 255)]\n","        # in this example, i don't use ToTensor() method of torchvision.transforms\n","        # so you can convert numpy ndarray shape to tensor in PyTorch (H, W, C) --> (C, H, W)\n","        if self.phase=='label':\n","            data_feature = self.transform(Image.fromarray(np.uint8(self.data_feature[index])))\n","            data_target =  self.data_target[index]\n","            return data_feature, data_target, index\n","\n","        else:\n","            data_feature = self.data_feature[index].float()\n","            return data_feature\n","\n","\n","class CutoutDefault(object):\n","    \"\"\"\n","    Reference : https://github.com/quark0/darts/blob/master/cnn/utils.py\n","    \"\"\"\n","    def __init__(self, length):\n","        self.length = length\n","\n","    def __call__(self, img):\n","        if self.length <= 0:\n","            return img\n","        h, w = img.size(1), img.size(2)\n","        mask = np.ones((h, w), np.float32)\n","        y = np.random.randint(h)\n","        x = np.random.randint(w)\n","\n","        y1 = np.clip(y - self.length // 2, 0, h)\n","        y2 = np.clip(y + self.length // 2, 0, h)\n","        x1 = np.clip(x - self.length // 2, 0, w)\n","        x2 = np.clip(x + self.length // 2, 0, w)\n","\n","        mask[y1: y2, x1: x2] = 0.\n","        mask = torch.from_numpy(mask)\n","        mask = mask.expand_as(img)\n","        img *= mask\n","        return img\n","\n","    \n","simple_transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n","])\n","\n","weak_transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4, padding_mode = 'reflect'),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation([-10,10]),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n","])\n","\n","strong_transform_train = transforms.Compose([\n","     augmentations.RandAugment(2),\n","     transforms.ToTensor(),           \n","     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n","     CutoutDefault(cutout),\n"," ])\n","\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n","])\n","\n","final_dataset = torch.utils.data.ConcatDataset([Dataset_sub_CIFAR(x_train, y_train, transform=weak_transform_train),Dataset_sub_CIFAR(x_train, y_train, transform=strong_transform_train), Dataset_sub_CIFAR(x_train, y_train, transform=simple_transform)])\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","#Dataloader creation\n","\n","train_loader = torch.utils.data.DataLoader(\n","    final_dataset, \n","    batch_size=batch_size,shuffle=True, num_workers=2) #num_workers = 2 ou 1\n","\n","test_loader = torch.utils.data.DataLoader(\n","    Dataset_sub_CIFAR(Original_test_data_x, Original_test_data_y, transform=simple_transform),\n","    batch_size = batch_size,\n","    shuffle=False, num_workers=2)\n","\n","valid_loader = torch.utils.data.DataLoader(\n","    Dataset_sub_CIFAR(x_valid, y_valid, transform=simple_transform),\n","    batch_size=batch_size,\n","    shuffle=False, num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TY4MtCMmJW2W","executionInfo":{"status":"ok","timestamp":1618870034140,"user_tz":-120,"elapsed":4363,"user":{"displayName":"Rafael Verissimo Martins","photoUrl":"","userId":"09165089013938111915"}},"outputId":"f7e58a79-8279-4266-a849-2d95c4b274a6"},"source":["len(train_loader.dataset)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3000"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":305},"id":"0B4MvhT0INfm","executionInfo":{"status":"ok","timestamp":1618870034926,"user_tz":-120,"elapsed":5141,"user":{"displayName":"Rafael Verissimo Martins","photoUrl":"","userId":"09165089013938111915"}},"outputId":"380b397c-c5e9-47d4-b660-289a6c652316"},"source":["def show(img):\n","    npimg = img.numpy()\n","    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n","\n","sample = next(iter(train_loader))[0]\n","show(torchvision.utils.make_grid(sample))\n","print(sample.shape)  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"stream","text":["torch.Size([64, 3, 32, 32])\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"KcsBk5HhsecU"},"source":["from model import *\n","criterion = nn.CrossEntropyLoss()\n","#Networks creation\n","net = WideResNet(28, 4, dropout_rate=0.2, num_classes=num_class)\n","net =net.cuda()\n","net_save = WideResNet(28, 4, dropout_rate=0.2, num_classes=num_class) # model where to save the results\n","net_save =net_save.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pLl0IonixbV5"},"source":["# Training\n","def train(epoch,net,trainloader,learing_rate, log_interval=15):\n","    net.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","    print('\\n=> Training Epoch #%d, LR=%.4f' %(epoch, learing_rate ))\n","    optimizer = optim.SGD(net.parameters(), lr=learing_rate, momentum=bn_momentum , weight_decay=5e-4)\n","    for batch_idx, (inputs, targets,index) in enumerate(trainloader):\n","\n","        inputs, targets = inputs.cuda(), targets.cuda() # GPU settings\n","        optimizer.zero_grad()\n","        inputs, targets = Variable(inputs), Variable(targets)\n","        outputs = net(inputs)               # Forward Propagation\n","        loss = criterion(outputs, targets)  # Loss\n","        loss.backward()  # Backward Propagation\n","        optimizer.step() # Optimizer update\n","\n","        train_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets.data).cpu().sum()\n","        if batch_idx % log_interval == 0:\n","            print('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%%'\n","                %(epoch, num_epochs, batch_idx+1,\n","                    (len(trainloader.dataset)//batch_size)+1, loss.item(), 100.*correct/total))\n","\n","\n","def test(epoch,net,testloader):\n","    net.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets, index) in enumerate(testloader):\n","            \n","            inputs, targets = inputs.cuda(), targets.cuda()\n","            inputs, targets = Variable(inputs), Variable(targets)\n","            outputs = net(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            test_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets.data).cpu().sum()\n","\n","        \n","    acc = 100.*correct/total\n","    print(\"\\n| Validation Epoch #%d\\t\\t\\tLoss: %.4f Acc@1: %.2f%%\" %(epoch, loss.item(), acc))\n","    return acc\n","\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lr2Z20hMxbV5","executionInfo":{"status":"ok","timestamp":1618870767231,"user_tz":-120,"elapsed":720752,"user":{"displayName":"Rafael Verissimo Martins","photoUrl":"","userId":"09165089013938111915"}},"outputId":"09b36b55-9bba-4ff9-9ed4-52919786ab91"},"source":["num_epochs = 120\n","lr = 0.03\n","best_acc=0\n","for epoch in range(num_epochs):\n","\n","\n","    train(epoch,net,train_loader,learing_rate = lr)\n","    acc =test(epoch,net,valid_loader)\n","    # Save checkpoint when best model\n","    if acc > best_acc:\n","        print('| Saving Best model...\\t\\t\\tTop1 = %.2f%%' %(acc))\n","        net_save.load_state_dict(net.state_dict(), strict=True)\n","        best_acc=acc"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","=> Training Epoch #0, LR=0.0300\n","| Epoch [  0/120] Iter[  1/ 47]\t\tLoss: 2.0718 Acc@1: 18.750%\n","| Epoch [  0/120] Iter[ 16/ 47]\t\tLoss: 2.0984 Acc@1: 17.676%\n","| Epoch [  0/120] Iter[ 31/ 47]\t\tLoss: 1.9558 Acc@1: 19.355%\n","| Epoch [  0/120] Iter[ 46/ 47]\t\tLoss: 1.9884 Acc@1: 20.279%\n","\n","| Validation Epoch #0\t\t\tLoss: 2.3032 Acc@1: 25.08%\n","| Saving Best model...\t\t\tTop1 = 25.08%\n","\n","=> Training Epoch #1, LR=0.0300\n","| Epoch [  1/120] Iter[  1/ 47]\t\tLoss: 2.1987 Acc@1: 20.312%\n","| Epoch [  1/120] Iter[ 16/ 47]\t\tLoss: 2.1232 Acc@1: 23.145%\n","| Epoch [  1/120] Iter[ 31/ 47]\t\tLoss: 2.0053 Acc@1: 23.790%\n","| Epoch [  1/120] Iter[ 46/ 47]\t\tLoss: 2.0073 Acc@1: 23.743%\n","\n","| Validation Epoch #1\t\t\tLoss: 1.8817 Acc@1: 26.76%\n","| Saving Best model...\t\t\tTop1 = 26.76%\n","\n","=> Training Epoch #2, LR=0.0300\n","| Epoch [  2/120] Iter[  1/ 47]\t\tLoss: 1.8433 Acc@1: 26.562%\n","| Epoch [  2/120] Iter[ 16/ 47]\t\tLoss: 1.9956 Acc@1: 26.270%\n","| Epoch [  2/120] Iter[ 31/ 47]\t\tLoss: 2.0357 Acc@1: 24.143%\n","| Epoch [  2/120] Iter[ 46/ 47]\t\tLoss: 1.9554 Acc@1: 23.845%\n","\n","| Validation Epoch #2\t\t\tLoss: 2.1211 Acc@1: 31.52%\n","| Saving Best model...\t\t\tTop1 = 31.52%\n","\n","=> Training Epoch #3, LR=0.0300\n","| Epoch [  3/120] Iter[  1/ 47]\t\tLoss: 1.7176 Acc@1: 32.812%\n","| Epoch [  3/120] Iter[ 16/ 47]\t\tLoss: 1.9146 Acc@1: 26.074%\n","| Epoch [  3/120] Iter[ 31/ 47]\t\tLoss: 2.0068 Acc@1: 27.621%\n","| Epoch [  3/120] Iter[ 46/ 47]\t\tLoss: 1.8628 Acc@1: 27.853%\n","\n","| Validation Epoch #3\t\t\tLoss: 1.8692 Acc@1: 34.80%\n","| Saving Best model...\t\t\tTop1 = 34.80%\n","\n","=> Training Epoch #4, LR=0.0300\n","| Epoch [  4/120] Iter[  1/ 47]\t\tLoss: 1.7305 Acc@1: 31.250%\n","| Epoch [  4/120] Iter[ 16/ 47]\t\tLoss: 1.9302 Acc@1: 30.664%\n","| Epoch [  4/120] Iter[ 31/ 47]\t\tLoss: 1.6560 Acc@1: 30.544%\n","| Epoch [  4/120] Iter[ 46/ 47]\t\tLoss: 1.8285 Acc@1: 30.027%\n","\n","| Validation Epoch #4\t\t\tLoss: 1.0757 Acc@1: 34.78%\n","\n","=> Training Epoch #5, LR=0.0300\n","| Epoch [  5/120] Iter[  1/ 47]\t\tLoss: 1.9942 Acc@1: 20.312%\n","| Epoch [  5/120] Iter[ 16/ 47]\t\tLoss: 2.0122 Acc@1: 32.520%\n","| Epoch [  5/120] Iter[ 31/ 47]\t\tLoss: 1.8571 Acc@1: 31.552%\n","| Epoch [  5/120] Iter[ 46/ 47]\t\tLoss: 1.7993 Acc@1: 31.012%\n","\n","| Validation Epoch #5\t\t\tLoss: 1.7387 Acc@1: 35.22%\n","| Saving Best model...\t\t\tTop1 = 35.22%\n","\n","=> Training Epoch #6, LR=0.0300\n","| Epoch [  6/120] Iter[  1/ 47]\t\tLoss: 1.9489 Acc@1: 29.688%\n","| Epoch [  6/120] Iter[ 16/ 47]\t\tLoss: 1.7514 Acc@1: 30.957%\n","| Epoch [  6/120] Iter[ 31/ 47]\t\tLoss: 1.6389 Acc@1: 32.460%\n","| Epoch [  6/120] Iter[ 46/ 47]\t\tLoss: 1.8823 Acc@1: 32.303%\n","\n","| Validation Epoch #6\t\t\tLoss: 1.5163 Acc@1: 39.60%\n","| Saving Best model...\t\t\tTop1 = 39.60%\n","\n","=> Training Epoch #7, LR=0.0300\n","| Epoch [  7/120] Iter[  1/ 47]\t\tLoss: 1.8899 Acc@1: 25.000%\n","| Epoch [  7/120] Iter[ 16/ 47]\t\tLoss: 1.7667 Acc@1: 35.547%\n","| Epoch [  7/120] Iter[ 31/ 47]\t\tLoss: 1.7551 Acc@1: 34.980%\n","| Epoch [  7/120] Iter[ 46/ 47]\t\tLoss: 1.5489 Acc@1: 35.802%\n","\n","| Validation Epoch #7\t\t\tLoss: 2.1593 Acc@1: 41.46%\n","| Saving Best model...\t\t\tTop1 = 41.46%\n","\n","=> Training Epoch #8, LR=0.0300\n","| Epoch [  8/120] Iter[  1/ 47]\t\tLoss: 1.4918 Acc@1: 43.750%\n","| Epoch [  8/120] Iter[ 16/ 47]\t\tLoss: 1.5817 Acc@1: 39.062%\n","| Epoch [  8/120] Iter[ 31/ 47]\t\tLoss: 1.7716 Acc@1: 38.558%\n","| Epoch [  8/120] Iter[ 46/ 47]\t\tLoss: 1.7781 Acc@1: 37.568%\n","\n","| Validation Epoch #8\t\t\tLoss: 1.0439 Acc@1: 41.36%\n","\n","=> Training Epoch #9, LR=0.0300\n","| Epoch [  9/120] Iter[  1/ 47]\t\tLoss: 1.7265 Acc@1: 31.250%\n","| Epoch [  9/120] Iter[ 16/ 47]\t\tLoss: 1.7363 Acc@1: 39.453%\n","| Epoch [  9/120] Iter[ 31/ 47]\t\tLoss: 1.6967 Acc@1: 37.147%\n","| Epoch [  9/120] Iter[ 46/ 47]\t\tLoss: 1.7563 Acc@1: 36.379%\n","\n","| Validation Epoch #9\t\t\tLoss: 1.5287 Acc@1: 41.64%\n","| Saving Best model...\t\t\tTop1 = 41.64%\n","\n","=> Training Epoch #10, LR=0.0300\n","| Epoch [ 10/120] Iter[  1/ 47]\t\tLoss: 1.7632 Acc@1: 31.250%\n","| Epoch [ 10/120] Iter[ 16/ 47]\t\tLoss: 1.6760 Acc@1: 40.039%\n","| Epoch [ 10/120] Iter[ 31/ 47]\t\tLoss: 1.6722 Acc@1: 39.466%\n","| Epoch [ 10/120] Iter[ 46/ 47]\t\tLoss: 1.6170 Acc@1: 39.266%\n","\n","| Validation Epoch #10\t\t\tLoss: 2.0557 Acc@1: 39.44%\n","\n","=> Training Epoch #11, LR=0.0300\n","| Epoch [ 11/120] Iter[  1/ 47]\t\tLoss: 1.4794 Acc@1: 46.875%\n","| Epoch [ 11/120] Iter[ 16/ 47]\t\tLoss: 1.6747 Acc@1: 41.895%\n","| Epoch [ 11/120] Iter[ 31/ 47]\t\tLoss: 1.6500 Acc@1: 40.171%\n","| Epoch [ 11/120] Iter[ 46/ 47]\t\tLoss: 1.6731 Acc@1: 40.591%\n","\n","| Validation Epoch #11\t\t\tLoss: 2.0310 Acc@1: 44.98%\n","| Saving Best model...\t\t\tTop1 = 44.98%\n","\n","=> Training Epoch #12, LR=0.0300\n","| Epoch [ 12/120] Iter[  1/ 47]\t\tLoss: 1.4830 Acc@1: 43.750%\n","| Epoch [ 12/120] Iter[ 16/ 47]\t\tLoss: 1.6389 Acc@1: 43.945%\n","| Epoch [ 12/120] Iter[ 31/ 47]\t\tLoss: 1.9279 Acc@1: 42.188%\n","| Epoch [ 12/120] Iter[ 46/ 47]\t\tLoss: 1.8121 Acc@1: 42.154%\n","\n","| Validation Epoch #12\t\t\tLoss: 1.8139 Acc@1: 44.96%\n","\n","=> Training Epoch #13, LR=0.0300\n","| Epoch [ 13/120] Iter[  1/ 47]\t\tLoss: 1.7013 Acc@1: 40.625%\n","| Epoch [ 13/120] Iter[ 16/ 47]\t\tLoss: 1.5848 Acc@1: 44.238%\n","| Epoch [ 13/120] Iter[ 31/ 47]\t\tLoss: 1.5565 Acc@1: 44.153%\n","| Epoch [ 13/120] Iter[ 46/ 47]\t\tLoss: 1.7532 Acc@1: 42.765%\n","\n","| Validation Epoch #13\t\t\tLoss: 1.7065 Acc@1: 42.82%\n","\n","=> Training Epoch #14, LR=0.0300\n","| Epoch [ 14/120] Iter[  1/ 47]\t\tLoss: 1.4125 Acc@1: 45.312%\n","| Epoch [ 14/120] Iter[ 16/ 47]\t\tLoss: 1.5262 Acc@1: 44.434%\n","| Epoch [ 14/120] Iter[ 31/ 47]\t\tLoss: 1.4173 Acc@1: 44.607%\n","| Epoch [ 14/120] Iter[ 46/ 47]\t\tLoss: 1.2757 Acc@1: 44.565%\n","\n","| Validation Epoch #14\t\t\tLoss: 2.2525 Acc@1: 44.02%\n","\n","=> Training Epoch #15, LR=0.0300\n","| Epoch [ 15/120] Iter[  1/ 47]\t\tLoss: 1.5678 Acc@1: 45.312%\n","| Epoch [ 15/120] Iter[ 16/ 47]\t\tLoss: 1.2991 Acc@1: 49.023%\n","| Epoch [ 15/120] Iter[ 31/ 47]\t\tLoss: 1.3348 Acc@1: 47.581%\n","| Epoch [ 15/120] Iter[ 46/ 47]\t\tLoss: 1.5593 Acc@1: 47.181%\n","\n","| Validation Epoch #15\t\t\tLoss: 1.8127 Acc@1: 45.78%\n","| Saving Best model...\t\t\tTop1 = 45.78%\n","\n","=> Training Epoch #16, LR=0.0300\n","| Epoch [ 16/120] Iter[  1/ 47]\t\tLoss: 1.7008 Acc@1: 32.812%\n","| Epoch [ 16/120] Iter[ 16/ 47]\t\tLoss: 1.4632 Acc@1: 47.852%\n","| Epoch [ 16/120] Iter[ 31/ 47]\t\tLoss: 1.1380 Acc@1: 46.018%\n","| Epoch [ 16/120] Iter[ 46/ 47]\t\tLoss: 1.5921 Acc@1: 44.837%\n","\n","| Validation Epoch #16\t\t\tLoss: 1.5354 Acc@1: 44.56%\n","\n","=> Training Epoch #17, LR=0.0300\n","| Epoch [ 17/120] Iter[  1/ 47]\t\tLoss: 1.3534 Acc@1: 54.688%\n","| Epoch [ 17/120] Iter[ 16/ 47]\t\tLoss: 1.3774 Acc@1: 49.609%\n","| Epoch [ 17/120] Iter[ 31/ 47]\t\tLoss: 1.3966 Acc@1: 48.085%\n","| Epoch [ 17/120] Iter[ 46/ 47]\t\tLoss: 1.4148 Acc@1: 47.452%\n","\n","| Validation Epoch #17\t\t\tLoss: 1.4579 Acc@1: 46.16%\n","| Saving Best model...\t\t\tTop1 = 46.16%\n","\n","=> Training Epoch #18, LR=0.0300\n","| Epoch [ 18/120] Iter[  1/ 47]\t\tLoss: 1.3925 Acc@1: 48.438%\n","| Epoch [ 18/120] Iter[ 16/ 47]\t\tLoss: 1.2790 Acc@1: 50.879%\n","| Epoch [ 18/120] Iter[ 31/ 47]\t\tLoss: 1.5622 Acc@1: 48.992%\n","| Epoch [ 18/120] Iter[ 46/ 47]\t\tLoss: 1.5428 Acc@1: 48.404%\n","\n","| Validation Epoch #18\t\t\tLoss: 2.0644 Acc@1: 46.72%\n","| Saving Best model...\t\t\tTop1 = 46.72%\n","\n","=> Training Epoch #19, LR=0.0300\n","| Epoch [ 19/120] Iter[  1/ 47]\t\tLoss: 1.2858 Acc@1: 42.188%\n","| Epoch [ 19/120] Iter[ 16/ 47]\t\tLoss: 1.2823 Acc@1: 52.539%\n","| Epoch [ 19/120] Iter[ 31/ 47]\t\tLoss: 1.5364 Acc@1: 51.512%\n","| Epoch [ 19/120] Iter[ 46/ 47]\t\tLoss: 1.3756 Acc@1: 50.136%\n","\n","| Validation Epoch #19\t\t\tLoss: 1.0950 Acc@1: 50.06%\n","| Saving Best model...\t\t\tTop1 = 50.06%\n","\n","=> Training Epoch #20, LR=0.0300\n","| Epoch [ 20/120] Iter[  1/ 47]\t\tLoss: 1.6012 Acc@1: 43.750%\n","| Epoch [ 20/120] Iter[ 16/ 47]\t\tLoss: 1.4643 Acc@1: 53.516%\n","| Epoch [ 20/120] Iter[ 31/ 47]\t\tLoss: 1.3641 Acc@1: 52.722%\n","| Epoch [ 20/120] Iter[ 46/ 47]\t\tLoss: 1.5100 Acc@1: 50.510%\n","\n","| Validation Epoch #20\t\t\tLoss: 1.7942 Acc@1: 49.90%\n","\n","=> Training Epoch #21, LR=0.0300\n","| Epoch [ 21/120] Iter[  1/ 47]\t\tLoss: 1.5179 Acc@1: 43.750%\n","| Epoch [ 21/120] Iter[ 16/ 47]\t\tLoss: 1.3463 Acc@1: 53.711%\n","| Epoch [ 21/120] Iter[ 31/ 47]\t\tLoss: 1.3766 Acc@1: 54.133%\n","| Epoch [ 21/120] Iter[ 46/ 47]\t\tLoss: 1.3051 Acc@1: 52.615%\n","\n","| Validation Epoch #21\t\t\tLoss: 1.2149 Acc@1: 49.74%\n","\n","=> Training Epoch #22, LR=0.0300\n","| Epoch [ 22/120] Iter[  1/ 47]\t\tLoss: 1.0556 Acc@1: 64.062%\n","| Epoch [ 22/120] Iter[ 16/ 47]\t\tLoss: 1.4968 Acc@1: 56.250%\n","| Epoch [ 22/120] Iter[ 31/ 47]\t\tLoss: 1.3901 Acc@1: 53.780%\n","| Epoch [ 22/120] Iter[ 46/ 47]\t\tLoss: 1.5224 Acc@1: 53.261%\n","\n","| Validation Epoch #22\t\t\tLoss: 2.3989 Acc@1: 44.70%\n","\n","=> Training Epoch #23, LR=0.0300\n","| Epoch [ 23/120] Iter[  1/ 47]\t\tLoss: 1.3122 Acc@1: 46.875%\n","| Epoch [ 23/120] Iter[ 16/ 47]\t\tLoss: 1.6097 Acc@1: 54.688%\n","| Epoch [ 23/120] Iter[ 31/ 47]\t\tLoss: 1.3227 Acc@1: 55.595%\n","| Epoch [ 23/120] Iter[ 46/ 47]\t\tLoss: 1.1379 Acc@1: 54.314%\n","\n","| Validation Epoch #23\t\t\tLoss: 1.2452 Acc@1: 49.42%\n","\n","=> Training Epoch #24, LR=0.0300\n","| Epoch [ 24/120] Iter[  1/ 47]\t\tLoss: 1.2008 Acc@1: 56.250%\n","| Epoch [ 24/120] Iter[ 16/ 47]\t\tLoss: 1.1494 Acc@1: 57.812%\n","| Epoch [ 24/120] Iter[ 31/ 47]\t\tLoss: 1.4172 Acc@1: 55.595%\n","| Epoch [ 24/120] Iter[ 46/ 47]\t\tLoss: 1.1036 Acc@1: 54.857%\n","\n","| Validation Epoch #24\t\t\tLoss: 0.5302 Acc@1: 50.50%\n","| Saving Best model...\t\t\tTop1 = 50.50%\n","\n","=> Training Epoch #25, LR=0.0300\n","| Epoch [ 25/120] Iter[  1/ 47]\t\tLoss: 1.0963 Acc@1: 62.500%\n","| Epoch [ 25/120] Iter[ 16/ 47]\t\tLoss: 1.1943 Acc@1: 59.863%\n","| Epoch [ 25/120] Iter[ 31/ 47]\t\tLoss: 0.9841 Acc@1: 58.921%\n","| Epoch [ 25/120] Iter[ 46/ 47]\t\tLoss: 1.2235 Acc@1: 57.065%\n","\n","| Validation Epoch #25\t\t\tLoss: 1.4479 Acc@1: 48.60%\n","\n","=> Training Epoch #26, LR=0.0300\n","| Epoch [ 26/120] Iter[  1/ 47]\t\tLoss: 1.0396 Acc@1: 56.250%\n","| Epoch [ 26/120] Iter[ 16/ 47]\t\tLoss: 1.2830 Acc@1: 60.059%\n","| Epoch [ 26/120] Iter[ 31/ 47]\t\tLoss: 1.2242 Acc@1: 59.375%\n","| Epoch [ 26/120] Iter[ 46/ 47]\t\tLoss: 1.0712 Acc@1: 58.628%\n","\n","| Validation Epoch #26\t\t\tLoss: 1.2002 Acc@1: 49.44%\n","\n","=> Training Epoch #27, LR=0.0300\n","| Epoch [ 27/120] Iter[  1/ 47]\t\tLoss: 1.0241 Acc@1: 67.188%\n","| Epoch [ 27/120] Iter[ 16/ 47]\t\tLoss: 1.0678 Acc@1: 61.035%\n","| Epoch [ 27/120] Iter[ 31/ 47]\t\tLoss: 1.5433 Acc@1: 59.224%\n","| Epoch [ 27/120] Iter[ 46/ 47]\t\tLoss: 1.1042 Acc@1: 57.846%\n","\n","| Validation Epoch #27\t\t\tLoss: 0.3958 Acc@1: 49.84%\n","\n","=> Training Epoch #28, LR=0.0300\n","| Epoch [ 28/120] Iter[  1/ 47]\t\tLoss: 1.0720 Acc@1: 62.500%\n","| Epoch [ 28/120] Iter[ 16/ 47]\t\tLoss: 1.3265 Acc@1: 58.496%\n","| Epoch [ 28/120] Iter[ 31/ 47]\t\tLoss: 1.3450 Acc@1: 57.056%\n","| Epoch [ 28/120] Iter[ 46/ 47]\t\tLoss: 1.2326 Acc@1: 57.201%\n","\n","| Validation Epoch #28\t\t\tLoss: 1.3409 Acc@1: 47.32%\n","\n","=> Training Epoch #29, LR=0.0300\n","| Epoch [ 29/120] Iter[  1/ 47]\t\tLoss: 1.1751 Acc@1: 56.250%\n","| Epoch [ 29/120] Iter[ 16/ 47]\t\tLoss: 1.0587 Acc@1: 58.984%\n","| Epoch [ 29/120] Iter[ 31/ 47]\t\tLoss: 1.0638 Acc@1: 60.585%\n","| Epoch [ 29/120] Iter[ 46/ 47]\t\tLoss: 1.3326 Acc@1: 59.477%\n","\n","| Validation Epoch #29\t\t\tLoss: 0.4541 Acc@1: 49.26%\n","\n","=> Training Epoch #30, LR=0.0300\n","| Epoch [ 30/120] Iter[  1/ 47]\t\tLoss: 1.1516 Acc@1: 57.812%\n","| Epoch [ 30/120] Iter[ 16/ 47]\t\tLoss: 1.1519 Acc@1: 60.645%\n","| Epoch [ 30/120] Iter[ 31/ 47]\t\tLoss: 1.2837 Acc@1: 60.081%\n","| Epoch [ 30/120] Iter[ 46/ 47]\t\tLoss: 1.1207 Acc@1: 59.171%\n","\n","| Validation Epoch #30\t\t\tLoss: 1.6371 Acc@1: 47.14%\n","\n","=> Training Epoch #31, LR=0.0300\n","| Epoch [ 31/120] Iter[  1/ 47]\t\tLoss: 1.1265 Acc@1: 56.250%\n","| Epoch [ 31/120] Iter[ 16/ 47]\t\tLoss: 1.3138 Acc@1: 60.938%\n","| Epoch [ 31/120] Iter[ 31/ 47]\t\tLoss: 1.3758 Acc@1: 61.190%\n","| Epoch [ 31/120] Iter[ 46/ 47]\t\tLoss: 1.0172 Acc@1: 60.700%\n","\n","| Validation Epoch #31\t\t\tLoss: 1.8924 Acc@1: 50.80%\n","| Saving Best model...\t\t\tTop1 = 50.80%\n","\n","=> Training Epoch #32, LR=0.0300\n","| Epoch [ 32/120] Iter[  1/ 47]\t\tLoss: 0.7728 Acc@1: 71.875%\n","| Epoch [ 32/120] Iter[ 16/ 47]\t\tLoss: 0.9102 Acc@1: 65.039%\n","| Epoch [ 32/120] Iter[ 31/ 47]\t\tLoss: 1.5876 Acc@1: 62.802%\n","| Epoch [ 32/120] Iter[ 46/ 47]\t\tLoss: 0.9694 Acc@1: 61.753%\n","\n","| Validation Epoch #32\t\t\tLoss: 0.1003 Acc@1: 51.84%\n","| Saving Best model...\t\t\tTop1 = 51.84%\n","\n","=> Training Epoch #33, LR=0.0300\n","| Epoch [ 33/120] Iter[  1/ 47]\t\tLoss: 0.9621 Acc@1: 62.500%\n","| Epoch [ 33/120] Iter[ 16/ 47]\t\tLoss: 0.9211 Acc@1: 62.891%\n","| Epoch [ 33/120] Iter[ 31/ 47]\t\tLoss: 1.1993 Acc@1: 61.542%\n","| Epoch [ 33/120] Iter[ 46/ 47]\t\tLoss: 1.2754 Acc@1: 60.836%\n","\n","| Validation Epoch #33\t\t\tLoss: 0.8344 Acc@1: 52.56%\n","| Saving Best model...\t\t\tTop1 = 52.56%\n","\n","=> Training Epoch #34, LR=0.0300\n","| Epoch [ 34/120] Iter[  1/ 47]\t\tLoss: 1.1013 Acc@1: 62.500%\n","| Epoch [ 34/120] Iter[ 16/ 47]\t\tLoss: 0.7924 Acc@1: 64.453%\n","| Epoch [ 34/120] Iter[ 31/ 47]\t\tLoss: 0.9495 Acc@1: 63.357%\n","| Epoch [ 34/120] Iter[ 46/ 47]\t\tLoss: 0.9128 Acc@1: 62.296%\n","\n","| Validation Epoch #34\t\t\tLoss: 0.6075 Acc@1: 51.24%\n","\n","=> Training Epoch #35, LR=0.0300\n","| Epoch [ 35/120] Iter[  1/ 47]\t\tLoss: 0.7857 Acc@1: 73.438%\n","| Epoch [ 35/120] Iter[ 16/ 47]\t\tLoss: 0.6697 Acc@1: 65.527%\n","| Epoch [ 35/120] Iter[ 31/ 47]\t\tLoss: 0.9912 Acc@1: 64.567%\n","| Epoch [ 35/120] Iter[ 46/ 47]\t\tLoss: 1.3111 Acc@1: 64.232%\n","\n","| Validation Epoch #35\t\t\tLoss: 0.6716 Acc@1: 52.44%\n","\n","=> Training Epoch #36, LR=0.0300\n","| Epoch [ 36/120] Iter[  1/ 47]\t\tLoss: 1.0205 Acc@1: 67.188%\n","| Epoch [ 36/120] Iter[ 16/ 47]\t\tLoss: 0.9825 Acc@1: 64.160%\n","| Epoch [ 36/120] Iter[ 31/ 47]\t\tLoss: 0.8395 Acc@1: 62.298%\n","| Epoch [ 36/120] Iter[ 46/ 47]\t\tLoss: 1.1254 Acc@1: 61.685%\n","\n","| Validation Epoch #36\t\t\tLoss: 0.1883 Acc@1: 50.26%\n","\n","=> Training Epoch #37, LR=0.0300\n","| Epoch [ 37/120] Iter[  1/ 47]\t\tLoss: 1.2042 Acc@1: 56.250%\n","| Epoch [ 37/120] Iter[ 16/ 47]\t\tLoss: 0.9118 Acc@1: 63.086%\n","| Epoch [ 37/120] Iter[ 31/ 47]\t\tLoss: 0.7965 Acc@1: 64.365%\n","| Epoch [ 37/120] Iter[ 46/ 47]\t\tLoss: 0.9980 Acc@1: 62.942%\n","\n","| Validation Epoch #37\t\t\tLoss: 0.2292 Acc@1: 53.36%\n","| Saving Best model...\t\t\tTop1 = 53.36%\n","\n","=> Training Epoch #38, LR=0.0300\n","| Epoch [ 38/120] Iter[  1/ 47]\t\tLoss: 1.0346 Acc@1: 64.062%\n","| Epoch [ 38/120] Iter[ 16/ 47]\t\tLoss: 0.9658 Acc@1: 63.379%\n","| Epoch [ 38/120] Iter[ 31/ 47]\t\tLoss: 1.1612 Acc@1: 61.190%\n","| Epoch [ 38/120] Iter[ 46/ 47]\t\tLoss: 1.0380 Acc@1: 61.549%\n","\n","| Validation Epoch #38\t\t\tLoss: 1.2239 Acc@1: 48.26%\n","\n","=> Training Epoch #39, LR=0.0300\n","| Epoch [ 39/120] Iter[  1/ 47]\t\tLoss: 1.0149 Acc@1: 62.500%\n","| Epoch [ 39/120] Iter[ 16/ 47]\t\tLoss: 0.8329 Acc@1: 65.234%\n","| Epoch [ 39/120] Iter[ 31/ 47]\t\tLoss: 0.9184 Acc@1: 64.062%\n","| Epoch [ 39/120] Iter[ 46/ 47]\t\tLoss: 0.8865 Acc@1: 63.111%\n","\n","| Validation Epoch #39\t\t\tLoss: 2.6157 Acc@1: 48.58%\n","\n","=> Training Epoch #40, LR=0.0300\n","| Epoch [ 40/120] Iter[  1/ 47]\t\tLoss: 0.9671 Acc@1: 64.062%\n","| Epoch [ 40/120] Iter[ 16/ 47]\t\tLoss: 0.9523 Acc@1: 65.918%\n","| Epoch [ 40/120] Iter[ 31/ 47]\t\tLoss: 0.9378 Acc@1: 65.323%\n","| Epoch [ 40/120] Iter[ 46/ 47]\t\tLoss: 1.0263 Acc@1: 64.538%\n","\n","| Validation Epoch #40\t\t\tLoss: 0.5345 Acc@1: 54.58%\n","| Saving Best model...\t\t\tTop1 = 54.58%\n","\n","=> Training Epoch #41, LR=0.0300\n","| Epoch [ 41/120] Iter[  1/ 47]\t\tLoss: 0.7525 Acc@1: 71.875%\n","| Epoch [ 41/120] Iter[ 16/ 47]\t\tLoss: 1.1233 Acc@1: 66.016%\n","| Epoch [ 41/120] Iter[ 31/ 47]\t\tLoss: 1.0641 Acc@1: 65.171%\n","| Epoch [ 41/120] Iter[ 46/ 47]\t\tLoss: 0.8982 Acc@1: 65.353%\n","\n","| Validation Epoch #41\t\t\tLoss: 1.6920 Acc@1: 48.84%\n","\n","=> Training Epoch #42, LR=0.0300\n","| Epoch [ 42/120] Iter[  1/ 47]\t\tLoss: 0.8837 Acc@1: 68.750%\n","| Epoch [ 42/120] Iter[ 16/ 47]\t\tLoss: 0.9026 Acc@1: 63.379%\n","| Epoch [ 42/120] Iter[ 31/ 47]\t\tLoss: 0.8387 Acc@1: 64.113%\n","| Epoch [ 42/120] Iter[ 46/ 47]\t\tLoss: 1.2066 Acc@1: 63.519%\n","\n","| Validation Epoch #42\t\t\tLoss: 1.4881 Acc@1: 48.02%\n","\n","=> Training Epoch #43, LR=0.0300\n","| Epoch [ 43/120] Iter[  1/ 47]\t\tLoss: 0.7449 Acc@1: 75.000%\n","| Epoch [ 43/120] Iter[ 16/ 47]\t\tLoss: 0.8353 Acc@1: 66.602%\n","| Epoch [ 43/120] Iter[ 31/ 47]\t\tLoss: 0.9717 Acc@1: 65.121%\n","| Epoch [ 43/120] Iter[ 46/ 47]\t\tLoss: 1.1992 Acc@1: 63.791%\n","\n","| Validation Epoch #43\t\t\tLoss: 1.5788 Acc@1: 50.60%\n","\n","=> Training Epoch #44, LR=0.0300\n","| Epoch [ 44/120] Iter[  1/ 47]\t\tLoss: 1.1539 Acc@1: 51.562%\n","| Epoch [ 44/120] Iter[ 16/ 47]\t\tLoss: 0.7615 Acc@1: 62.988%\n","| Epoch [ 44/120] Iter[ 31/ 47]\t\tLoss: 0.8888 Acc@1: 65.222%\n","| Epoch [ 44/120] Iter[ 46/ 47]\t\tLoss: 0.9520 Acc@1: 64.572%\n","\n","| Validation Epoch #44\t\t\tLoss: 1.3882 Acc@1: 48.48%\n","\n","=> Training Epoch #45, LR=0.0300\n","| Epoch [ 45/120] Iter[  1/ 47]\t\tLoss: 0.9521 Acc@1: 64.062%\n","| Epoch [ 45/120] Iter[ 16/ 47]\t\tLoss: 0.8497 Acc@1: 65.137%\n","| Epoch [ 45/120] Iter[ 31/ 47]\t\tLoss: 0.7952 Acc@1: 63.760%\n","| Epoch [ 45/120] Iter[ 46/ 47]\t\tLoss: 0.7681 Acc@1: 63.587%\n","\n","| Validation Epoch #45\t\t\tLoss: 0.2684 Acc@1: 53.42%\n","\n","=> Training Epoch #46, LR=0.0300\n","| Epoch [ 46/120] Iter[  1/ 47]\t\tLoss: 0.9195 Acc@1: 65.625%\n","| Epoch [ 46/120] Iter[ 16/ 47]\t\tLoss: 1.0965 Acc@1: 65.527%\n","| Epoch [ 46/120] Iter[ 31/ 47]\t\tLoss: 1.0116 Acc@1: 65.524%\n","| Epoch [ 46/120] Iter[ 46/ 47]\t\tLoss: 1.1539 Acc@1: 64.742%\n","\n","| Validation Epoch #46\t\t\tLoss: 0.6179 Acc@1: 51.76%\n","\n","=> Training Epoch #47, LR=0.0300\n","| Epoch [ 47/120] Iter[  1/ 47]\t\tLoss: 0.8334 Acc@1: 70.312%\n","| Epoch [ 47/120] Iter[ 16/ 47]\t\tLoss: 1.0948 Acc@1: 65.918%\n","| Epoch [ 47/120] Iter[ 31/ 47]\t\tLoss: 1.1965 Acc@1: 66.129%\n","| Epoch [ 47/120] Iter[ 46/ 47]\t\tLoss: 0.8326 Acc@1: 65.761%\n","\n","| Validation Epoch #47\t\t\tLoss: 2.2401 Acc@1: 51.54%\n","\n","=> Training Epoch #48, LR=0.0300\n","| Epoch [ 48/120] Iter[  1/ 47]\t\tLoss: 1.0085 Acc@1: 68.750%\n","| Epoch [ 48/120] Iter[ 16/ 47]\t\tLoss: 0.7472 Acc@1: 65.625%\n","| Epoch [ 48/120] Iter[ 31/ 47]\t\tLoss: 0.6674 Acc@1: 65.323%\n","| Epoch [ 48/120] Iter[ 46/ 47]\t\tLoss: 0.8551 Acc@1: 66.067%\n","\n","| Validation Epoch #48\t\t\tLoss: 0.1773 Acc@1: 53.98%\n","\n","=> Training Epoch #49, LR=0.0300\n","| Epoch [ 49/120] Iter[  1/ 47]\t\tLoss: 0.9473 Acc@1: 60.938%\n","| Epoch [ 49/120] Iter[ 16/ 47]\t\tLoss: 0.7710 Acc@1: 67.578%\n","| Epoch [ 49/120] Iter[ 31/ 47]\t\tLoss: 0.9432 Acc@1: 67.893%\n","| Epoch [ 49/120] Iter[ 46/ 47]\t\tLoss: 1.0904 Acc@1: 66.576%\n","\n","| Validation Epoch #49\t\t\tLoss: 0.7185 Acc@1: 49.28%\n","\n","=> Training Epoch #50, LR=0.0300\n","| Epoch [ 50/120] Iter[  1/ 47]\t\tLoss: 0.6776 Acc@1: 71.875%\n","| Epoch [ 50/120] Iter[ 16/ 47]\t\tLoss: 0.8904 Acc@1: 69.434%\n","| Epoch [ 50/120] Iter[ 31/ 47]\t\tLoss: 0.9051 Acc@1: 67.591%\n","| Epoch [ 50/120] Iter[ 46/ 47]\t\tLoss: 0.7774 Acc@1: 67.018%\n","\n","| Validation Epoch #50\t\t\tLoss: 0.7850 Acc@1: 51.62%\n","\n","=> Training Epoch #51, LR=0.0300\n","| Epoch [ 51/120] Iter[  1/ 47]\t\tLoss: 0.8771 Acc@1: 67.188%\n","| Epoch [ 51/120] Iter[ 16/ 47]\t\tLoss: 0.7280 Acc@1: 65.234%\n","| Epoch [ 51/120] Iter[ 31/ 47]\t\tLoss: 1.0292 Acc@1: 65.978%\n","| Epoch [ 51/120] Iter[ 46/ 47]\t\tLoss: 0.8404 Acc@1: 66.033%\n","\n","| Validation Epoch #51\t\t\tLoss: 3.1658 Acc@1: 48.64%\n","\n","=> Training Epoch #52, LR=0.0300\n","| Epoch [ 52/120] Iter[  1/ 47]\t\tLoss: 0.7622 Acc@1: 71.875%\n","| Epoch [ 52/120] Iter[ 16/ 47]\t\tLoss: 1.0397 Acc@1: 67.285%\n","| Epoch [ 52/120] Iter[ 31/ 47]\t\tLoss: 1.1605 Acc@1: 65.827%\n","| Epoch [ 52/120] Iter[ 46/ 47]\t\tLoss: 0.8603 Acc@1: 66.135%\n","\n","| Validation Epoch #52\t\t\tLoss: 1.8451 Acc@1: 52.06%\n","\n","=> Training Epoch #53, LR=0.0300\n","| Epoch [ 53/120] Iter[  1/ 47]\t\tLoss: 1.3425 Acc@1: 51.562%\n","| Epoch [ 53/120] Iter[ 16/ 47]\t\tLoss: 0.8577 Acc@1: 66.797%\n","| Epoch [ 53/120] Iter[ 31/ 47]\t\tLoss: 0.6668 Acc@1: 66.583%\n","| Epoch [ 53/120] Iter[ 46/ 47]\t\tLoss: 0.9399 Acc@1: 66.372%\n","\n","| Validation Epoch #53\t\t\tLoss: 1.0789 Acc@1: 53.92%\n","\n","=> Training Epoch #54, LR=0.0300\n","| Epoch [ 54/120] Iter[  1/ 47]\t\tLoss: 0.7005 Acc@1: 76.562%\n","| Epoch [ 54/120] Iter[ 16/ 47]\t\tLoss: 1.1859 Acc@1: 66.797%\n","| Epoch [ 54/120] Iter[ 31/ 47]\t\tLoss: 1.0629 Acc@1: 66.532%\n","| Epoch [ 54/120] Iter[ 46/ 47]\t\tLoss: 0.7058 Acc@1: 66.067%\n","\n","| Validation Epoch #54\t\t\tLoss: 1.2735 Acc@1: 53.92%\n","\n","=> Training Epoch #55, LR=0.0300\n","| Epoch [ 55/120] Iter[  1/ 47]\t\tLoss: 0.8590 Acc@1: 68.750%\n","| Epoch [ 55/120] Iter[ 16/ 47]\t\tLoss: 0.8101 Acc@1: 67.773%\n","| Epoch [ 55/120] Iter[ 31/ 47]\t\tLoss: 1.0576 Acc@1: 68.548%\n","| Epoch [ 55/120] Iter[ 46/ 47]\t\tLoss: 0.7665 Acc@1: 67.697%\n","\n","| Validation Epoch #55\t\t\tLoss: 1.2743 Acc@1: 53.58%\n","\n","=> Training Epoch #56, LR=0.0300\n","| Epoch [ 56/120] Iter[  1/ 47]\t\tLoss: 0.8732 Acc@1: 67.188%\n","| Epoch [ 56/120] Iter[ 16/ 47]\t\tLoss: 0.8805 Acc@1: 68.457%\n","| Epoch [ 56/120] Iter[ 31/ 47]\t\tLoss: 0.8049 Acc@1: 67.540%\n","| Epoch [ 56/120] Iter[ 46/ 47]\t\tLoss: 0.8756 Acc@1: 66.984%\n","\n","| Validation Epoch #56\t\t\tLoss: 1.6829 Acc@1: 52.10%\n","\n","=> Training Epoch #57, LR=0.0300\n","| Epoch [ 57/120] Iter[  1/ 47]\t\tLoss: 0.8573 Acc@1: 70.312%\n","| Epoch [ 57/120] Iter[ 16/ 47]\t\tLoss: 0.7411 Acc@1: 68.359%\n","| Epoch [ 57/120] Iter[ 31/ 47]\t\tLoss: 0.8908 Acc@1: 66.079%\n","| Epoch [ 57/120] Iter[ 46/ 47]\t\tLoss: 0.8053 Acc@1: 66.746%\n","\n","| Validation Epoch #57\t\t\tLoss: 1.4659 Acc@1: 46.04%\n","\n","=> Training Epoch #58, LR=0.0300\n","| Epoch [ 58/120] Iter[  1/ 47]\t\tLoss: 0.7166 Acc@1: 70.312%\n","| Epoch [ 58/120] Iter[ 16/ 47]\t\tLoss: 0.7000 Acc@1: 69.531%\n","| Epoch [ 58/120] Iter[ 31/ 47]\t\tLoss: 0.7358 Acc@1: 68.397%\n","| Epoch [ 58/120] Iter[ 46/ 47]\t\tLoss: 0.8942 Acc@1: 67.935%\n","\n","| Validation Epoch #58\t\t\tLoss: 0.0269 Acc@1: 51.88%\n","\n","=> Training Epoch #59, LR=0.0300\n","| Epoch [ 59/120] Iter[  1/ 47]\t\tLoss: 1.0585 Acc@1: 62.500%\n","| Epoch [ 59/120] Iter[ 16/ 47]\t\tLoss: 1.0537 Acc@1: 69.531%\n","| Epoch [ 59/120] Iter[ 31/ 47]\t\tLoss: 1.1342 Acc@1: 68.599%\n","| Epoch [ 59/120] Iter[ 46/ 47]\t\tLoss: 0.9623 Acc@1: 68.716%\n","\n","| Validation Epoch #59\t\t\tLoss: 0.1444 Acc@1: 48.08%\n","\n","=> Training Epoch #60, LR=0.0300\n","| Epoch [ 60/120] Iter[  1/ 47]\t\tLoss: 1.0086 Acc@1: 56.250%\n","| Epoch [ 60/120] Iter[ 16/ 47]\t\tLoss: 0.6250 Acc@1: 71.387%\n","| Epoch [ 60/120] Iter[ 31/ 47]\t\tLoss: 0.9196 Acc@1: 69.304%\n","| Epoch [ 60/120] Iter[ 46/ 47]\t\tLoss: 0.6556 Acc@1: 68.648%\n","\n","| Validation Epoch #60\t\t\tLoss: 0.4430 Acc@1: 54.16%\n","\n","=> Training Epoch #61, LR=0.0300\n","| Epoch [ 61/120] Iter[  1/ 47]\t\tLoss: 0.7379 Acc@1: 73.438%\n","| Epoch [ 61/120] Iter[ 16/ 47]\t\tLoss: 0.6569 Acc@1: 70.508%\n","| Epoch [ 61/120] Iter[ 31/ 47]\t\tLoss: 0.8052 Acc@1: 69.758%\n","| Epoch [ 61/120] Iter[ 46/ 47]\t\tLoss: 0.9386 Acc@1: 68.546%\n","\n","| Validation Epoch #61\t\t\tLoss: 0.9937 Acc@1: 50.88%\n","\n","=> Training Epoch #62, LR=0.0300\n","| Epoch [ 62/120] Iter[  1/ 47]\t\tLoss: 0.9092 Acc@1: 64.062%\n","| Epoch [ 62/120] Iter[ 16/ 47]\t\tLoss: 0.8135 Acc@1: 67.969%\n","| Epoch [ 62/120] Iter[ 31/ 47]\t\tLoss: 0.9008 Acc@1: 67.641%\n","| Epoch [ 62/120] Iter[ 46/ 47]\t\tLoss: 1.0030 Acc@1: 67.255%\n","\n","| Validation Epoch #62\t\t\tLoss: 0.7623 Acc@1: 53.02%\n","\n","=> Training Epoch #63, LR=0.0300\n","| Epoch [ 63/120] Iter[  1/ 47]\t\tLoss: 0.6814 Acc@1: 71.875%\n","| Epoch [ 63/120] Iter[ 16/ 47]\t\tLoss: 0.6899 Acc@1: 68.164%\n","| Epoch [ 63/120] Iter[ 31/ 47]\t\tLoss: 0.7206 Acc@1: 68.800%\n","| Epoch [ 63/120] Iter[ 46/ 47]\t\tLoss: 0.7635 Acc@1: 67.833%\n","\n","| Validation Epoch #63\t\t\tLoss: 0.5782 Acc@1: 54.76%\n","| Saving Best model...\t\t\tTop1 = 54.76%\n","\n","=> Training Epoch #64, LR=0.0300\n","| Epoch [ 64/120] Iter[  1/ 47]\t\tLoss: 0.7469 Acc@1: 73.438%\n","| Epoch [ 64/120] Iter[ 16/ 47]\t\tLoss: 0.8259 Acc@1: 70.801%\n","| Epoch [ 64/120] Iter[ 31/ 47]\t\tLoss: 0.9508 Acc@1: 69.607%\n","| Epoch [ 64/120] Iter[ 46/ 47]\t\tLoss: 0.8725 Acc@1: 69.260%\n","\n","| Validation Epoch #64\t\t\tLoss: 0.7746 Acc@1: 52.98%\n","\n","=> Training Epoch #65, LR=0.0300\n","| Epoch [ 65/120] Iter[  1/ 47]\t\tLoss: 0.8669 Acc@1: 67.188%\n","| Epoch [ 65/120] Iter[ 16/ 47]\t\tLoss: 0.8908 Acc@1: 67.969%\n","| Epoch [ 65/120] Iter[ 31/ 47]\t\tLoss: 0.5781 Acc@1: 69.254%\n","| Epoch [ 65/120] Iter[ 46/ 47]\t\tLoss: 0.9229 Acc@1: 68.173%\n","\n","| Validation Epoch #65\t\t\tLoss: 0.6218 Acc@1: 48.44%\n","\n","=> Training Epoch #66, LR=0.0300\n","| Epoch [ 66/120] Iter[  1/ 47]\t\tLoss: 0.9010 Acc@1: 65.625%\n","| Epoch [ 66/120] Iter[ 16/ 47]\t\tLoss: 0.6228 Acc@1: 70.410%\n","| Epoch [ 66/120] Iter[ 31/ 47]\t\tLoss: 1.0168 Acc@1: 68.196%\n","| Epoch [ 66/120] Iter[ 46/ 47]\t\tLoss: 0.7576 Acc@1: 68.614%\n","\n","| Validation Epoch #66\t\t\tLoss: 0.0940 Acc@1: 54.84%\n","| Saving Best model...\t\t\tTop1 = 54.84%\n","\n","=> Training Epoch #67, LR=0.0300\n","| Epoch [ 67/120] Iter[  1/ 47]\t\tLoss: 0.6506 Acc@1: 73.438%\n","| Epoch [ 67/120] Iter[ 16/ 47]\t\tLoss: 1.0324 Acc@1: 68.066%\n","| Epoch [ 67/120] Iter[ 31/ 47]\t\tLoss: 0.6212 Acc@1: 69.758%\n","| Epoch [ 67/120] Iter[ 46/ 47]\t\tLoss: 0.8968 Acc@1: 69.429%\n","\n","| Validation Epoch #67\t\t\tLoss: 0.6781 Acc@1: 53.18%\n","\n","=> Training Epoch #68, LR=0.0300\n","| Epoch [ 68/120] Iter[  1/ 47]\t\tLoss: 0.8954 Acc@1: 67.188%\n","| Epoch [ 68/120] Iter[ 16/ 47]\t\tLoss: 0.8555 Acc@1: 69.629%\n","| Epoch [ 68/120] Iter[ 31/ 47]\t\tLoss: 0.7242 Acc@1: 69.002%\n","| Epoch [ 68/120] Iter[ 46/ 47]\t\tLoss: 0.8656 Acc@1: 68.512%\n","\n","| Validation Epoch #68\t\t\tLoss: 0.6345 Acc@1: 53.92%\n","\n","=> Training Epoch #69, LR=0.0300\n","| Epoch [ 69/120] Iter[  1/ 47]\t\tLoss: 0.7350 Acc@1: 73.438%\n","| Epoch [ 69/120] Iter[ 16/ 47]\t\tLoss: 0.6121 Acc@1: 69.336%\n","| Epoch [ 69/120] Iter[ 31/ 47]\t\tLoss: 0.8810 Acc@1: 67.944%\n","| Epoch [ 69/120] Iter[ 46/ 47]\t\tLoss: 0.9050 Acc@1: 67.391%\n","\n","| Validation Epoch #69\t\t\tLoss: 0.9682 Acc@1: 51.04%\n","\n","=> Training Epoch #70, LR=0.0300\n","| Epoch [ 70/120] Iter[  1/ 47]\t\tLoss: 0.8658 Acc@1: 68.750%\n","| Epoch [ 70/120] Iter[ 16/ 47]\t\tLoss: 0.9150 Acc@1: 66.992%\n","| Epoch [ 70/120] Iter[ 31/ 47]\t\tLoss: 0.8801 Acc@1: 68.901%\n","| Epoch [ 70/120] Iter[ 46/ 47]\t\tLoss: 0.9703 Acc@1: 68.308%\n","\n","| Validation Epoch #70\t\t\tLoss: 0.0046 Acc@1: 52.80%\n","\n","=> Training Epoch #71, LR=0.0300\n","| Epoch [ 71/120] Iter[  1/ 47]\t\tLoss: 0.6023 Acc@1: 76.562%\n","| Epoch [ 71/120] Iter[ 16/ 47]\t\tLoss: 0.7292 Acc@1: 68.457%\n","| Epoch [ 71/120] Iter[ 31/ 47]\t\tLoss: 0.7548 Acc@1: 68.498%\n","| Epoch [ 71/120] Iter[ 46/ 47]\t\tLoss: 0.6262 Acc@1: 67.799%\n","\n","| Validation Epoch #71\t\t\tLoss: 1.4759 Acc@1: 52.28%\n","\n","=> Training Epoch #72, LR=0.0300\n","| Epoch [ 72/120] Iter[  1/ 47]\t\tLoss: 0.7252 Acc@1: 71.875%\n","| Epoch [ 72/120] Iter[ 16/ 47]\t\tLoss: 0.7084 Acc@1: 70.996%\n","| Epoch [ 72/120] Iter[ 31/ 47]\t\tLoss: 0.7352 Acc@1: 68.750%\n","| Epoch [ 72/120] Iter[ 46/ 47]\t\tLoss: 0.9861 Acc@1: 68.750%\n","\n","| Validation Epoch #72\t\t\tLoss: 0.4212 Acc@1: 55.02%\n","| Saving Best model...\t\t\tTop1 = 55.02%\n","\n","=> Training Epoch #73, LR=0.0300\n","| Epoch [ 73/120] Iter[  1/ 47]\t\tLoss: 0.9675 Acc@1: 64.062%\n","| Epoch [ 73/120] Iter[ 16/ 47]\t\tLoss: 0.8901 Acc@1: 68.457%\n","| Epoch [ 73/120] Iter[ 31/ 47]\t\tLoss: 0.4773 Acc@1: 69.808%\n","| Epoch [ 73/120] Iter[ 46/ 47]\t\tLoss: 0.9523 Acc@1: 69.056%\n","\n","| Validation Epoch #73\t\t\tLoss: 0.9990 Acc@1: 52.98%\n","\n","=> Training Epoch #74, LR=0.0300\n","| Epoch [ 74/120] Iter[  1/ 47]\t\tLoss: 0.8543 Acc@1: 71.875%\n","| Epoch [ 74/120] Iter[ 16/ 47]\t\tLoss: 0.8247 Acc@1: 69.043%\n","| Epoch [ 74/120] Iter[ 31/ 47]\t\tLoss: 0.7609 Acc@1: 69.405%\n","| Epoch [ 74/120] Iter[ 46/ 47]\t\tLoss: 0.9021 Acc@1: 69.429%\n","\n","| Validation Epoch #74\t\t\tLoss: 1.6383 Acc@1: 53.32%\n","\n","=> Training Epoch #75, LR=0.0300\n","| Epoch [ 75/120] Iter[  1/ 47]\t\tLoss: 0.7731 Acc@1: 68.750%\n","| Epoch [ 75/120] Iter[ 16/ 47]\t\tLoss: 1.0329 Acc@1: 71.191%\n","| Epoch [ 75/120] Iter[ 31/ 47]\t\tLoss: 1.0828 Acc@1: 70.060%\n","| Epoch [ 75/120] Iter[ 46/ 47]\t\tLoss: 0.9847 Acc@1: 69.769%\n","\n","| Validation Epoch #75\t\t\tLoss: 1.4614 Acc@1: 53.08%\n","\n","=> Training Epoch #76, LR=0.0300\n","| Epoch [ 76/120] Iter[  1/ 47]\t\tLoss: 0.7180 Acc@1: 75.000%\n","| Epoch [ 76/120] Iter[ 16/ 47]\t\tLoss: 0.9944 Acc@1: 71.289%\n","| Epoch [ 76/120] Iter[ 31/ 47]\t\tLoss: 0.7907 Acc@1: 70.615%\n","| Epoch [ 76/120] Iter[ 46/ 47]\t\tLoss: 0.6311 Acc@1: 69.497%\n","\n","| Validation Epoch #76\t\t\tLoss: 0.5546 Acc@1: 51.20%\n","\n","=> Training Epoch #77, LR=0.0300\n","| Epoch [ 77/120] Iter[  1/ 47]\t\tLoss: 0.7273 Acc@1: 71.875%\n","| Epoch [ 77/120] Iter[ 16/ 47]\t\tLoss: 0.9820 Acc@1: 69.922%\n","| Epoch [ 77/120] Iter[ 31/ 47]\t\tLoss: 1.0439 Acc@1: 69.405%\n","| Epoch [ 77/120] Iter[ 46/ 47]\t\tLoss: 0.8930 Acc@1: 69.090%\n","\n","| Validation Epoch #77\t\t\tLoss: 0.7279 Acc@1: 52.86%\n","\n","=> Training Epoch #78, LR=0.0300\n","| Epoch [ 78/120] Iter[  1/ 47]\t\tLoss: 0.8289 Acc@1: 67.188%\n","| Epoch [ 78/120] Iter[ 16/ 47]\t\tLoss: 0.9156 Acc@1: 70.020%\n","| Epoch [ 78/120] Iter[ 31/ 47]\t\tLoss: 0.7355 Acc@1: 70.161%\n","| Epoch [ 78/120] Iter[ 46/ 47]\t\tLoss: 0.8479 Acc@1: 69.701%\n","\n","| Validation Epoch #78\t\t\tLoss: 1.0413 Acc@1: 51.38%\n","\n","=> Training Epoch #79, LR=0.0300\n","| Epoch [ 79/120] Iter[  1/ 47]\t\tLoss: 0.8355 Acc@1: 65.625%\n","| Epoch [ 79/120] Iter[ 16/ 47]\t\tLoss: 0.8105 Acc@1: 69.629%\n","| Epoch [ 79/120] Iter[ 31/ 47]\t\tLoss: 0.8480 Acc@1: 68.548%\n","| Epoch [ 79/120] Iter[ 46/ 47]\t\tLoss: 0.7130 Acc@1: 69.395%\n","\n","| Validation Epoch #79\t\t\tLoss: 0.1503 Acc@1: 53.58%\n","\n","=> Training Epoch #80, LR=0.0300\n","| Epoch [ 80/120] Iter[  1/ 47]\t\tLoss: 0.6912 Acc@1: 73.438%\n","| Epoch [ 80/120] Iter[ 16/ 47]\t\tLoss: 0.8825 Acc@1: 68.652%\n","| Epoch [ 80/120] Iter[ 31/ 47]\t\tLoss: 0.8589 Acc@1: 68.700%\n","| Epoch [ 80/120] Iter[ 46/ 47]\t\tLoss: 0.7497 Acc@1: 68.750%\n","\n","| Validation Epoch #80\t\t\tLoss: 1.1465 Acc@1: 53.64%\n","\n","=> Training Epoch #81, LR=0.0300\n","| Epoch [ 81/120] Iter[  1/ 47]\t\tLoss: 0.9278 Acc@1: 64.062%\n","| Epoch [ 81/120] Iter[ 16/ 47]\t\tLoss: 0.8119 Acc@1: 69.531%\n","| Epoch [ 81/120] Iter[ 31/ 47]\t\tLoss: 0.6223 Acc@1: 70.363%\n","| Epoch [ 81/120] Iter[ 46/ 47]\t\tLoss: 0.6286 Acc@1: 69.633%\n","\n","| Validation Epoch #81\t\t\tLoss: 0.0148 Acc@1: 55.54%\n","| Saving Best model...\t\t\tTop1 = 55.54%\n","\n","=> Training Epoch #82, LR=0.0300\n","| Epoch [ 82/120] Iter[  1/ 47]\t\tLoss: 0.6783 Acc@1: 78.125%\n","| Epoch [ 82/120] Iter[ 16/ 47]\t\tLoss: 0.8451 Acc@1: 70.410%\n","| Epoch [ 82/120] Iter[ 31/ 47]\t\tLoss: 0.9667 Acc@1: 69.607%\n","| Epoch [ 82/120] Iter[ 46/ 47]\t\tLoss: 0.6751 Acc@1: 68.750%\n","\n","| Validation Epoch #82\t\t\tLoss: 0.3178 Acc@1: 53.24%\n","\n","=> Training Epoch #83, LR=0.0300\n","| Epoch [ 83/120] Iter[  1/ 47]\t\tLoss: 0.7660 Acc@1: 68.750%\n","| Epoch [ 83/120] Iter[ 16/ 47]\t\tLoss: 0.7496 Acc@1: 67.969%\n","| Epoch [ 83/120] Iter[ 31/ 47]\t\tLoss: 0.9287 Acc@1: 67.944%\n","| Epoch [ 83/120] Iter[ 46/ 47]\t\tLoss: 0.9364 Acc@1: 68.037%\n","\n","| Validation Epoch #83\t\t\tLoss: 0.7421 Acc@1: 54.08%\n","\n","=> Training Epoch #84, LR=0.0300\n","| Epoch [ 84/120] Iter[  1/ 47]\t\tLoss: 0.6854 Acc@1: 71.875%\n","| Epoch [ 84/120] Iter[ 16/ 47]\t\tLoss: 0.8570 Acc@1: 67.188%\n","| Epoch [ 84/120] Iter[ 31/ 47]\t\tLoss: 0.6713 Acc@1: 69.153%\n","| Epoch [ 84/120] Iter[ 46/ 47]\t\tLoss: 0.6987 Acc@1: 69.361%\n","\n","| Validation Epoch #84\t\t\tLoss: 0.9630 Acc@1: 54.58%\n","\n","=> Training Epoch #85, LR=0.0300\n","| Epoch [ 85/120] Iter[  1/ 47]\t\tLoss: 0.7610 Acc@1: 75.000%\n","| Epoch [ 85/120] Iter[ 16/ 47]\t\tLoss: 0.9608 Acc@1: 70.703%\n","| Epoch [ 85/120] Iter[ 31/ 47]\t\tLoss: 0.7315 Acc@1: 69.758%\n","| Epoch [ 85/120] Iter[ 46/ 47]\t\tLoss: 1.0051 Acc@1: 69.803%\n","\n","| Validation Epoch #85\t\t\tLoss: 0.4636 Acc@1: 55.52%\n","\n","=> Training Epoch #86, LR=0.0300\n","| Epoch [ 86/120] Iter[  1/ 47]\t\tLoss: 0.7415 Acc@1: 70.312%\n","| Epoch [ 86/120] Iter[ 16/ 47]\t\tLoss: 0.7256 Acc@1: 68.750%\n","| Epoch [ 86/120] Iter[ 31/ 47]\t\tLoss: 0.5818 Acc@1: 70.010%\n","| Epoch [ 86/120] Iter[ 46/ 47]\t\tLoss: 0.5853 Acc@1: 69.565%\n","\n","| Validation Epoch #86\t\t\tLoss: 0.3147 Acc@1: 55.46%\n","\n","=> Training Epoch #87, LR=0.0300\n","| Epoch [ 87/120] Iter[  1/ 47]\t\tLoss: 0.6391 Acc@1: 75.000%\n","| Epoch [ 87/120] Iter[ 16/ 47]\t\tLoss: 0.9650 Acc@1: 69.629%\n","| Epoch [ 87/120] Iter[ 31/ 47]\t\tLoss: 0.8701 Acc@1: 69.808%\n","| Epoch [ 87/120] Iter[ 46/ 47]\t\tLoss: 0.9684 Acc@1: 69.667%\n","\n","| Validation Epoch #87\t\t\tLoss: 0.9118 Acc@1: 53.40%\n","\n","=> Training Epoch #88, LR=0.0300\n","| Epoch [ 88/120] Iter[  1/ 47]\t\tLoss: 0.6791 Acc@1: 76.562%\n","| Epoch [ 88/120] Iter[ 16/ 47]\t\tLoss: 0.9061 Acc@1: 70.801%\n","| Epoch [ 88/120] Iter[ 31/ 47]\t\tLoss: 0.9086 Acc@1: 71.018%\n","| Epoch [ 88/120] Iter[ 46/ 47]\t\tLoss: 0.8744 Acc@1: 69.599%\n","\n","| Validation Epoch #88\t\t\tLoss: 0.9842 Acc@1: 50.58%\n","\n","=> Training Epoch #89, LR=0.0300\n","| Epoch [ 89/120] Iter[  1/ 47]\t\tLoss: 0.8612 Acc@1: 64.062%\n","| Epoch [ 89/120] Iter[ 16/ 47]\t\tLoss: 0.8382 Acc@1: 71.680%\n","| Epoch [ 89/120] Iter[ 31/ 47]\t\tLoss: 0.8461 Acc@1: 70.716%\n","| Epoch [ 89/120] Iter[ 46/ 47]\t\tLoss: 0.6873 Acc@1: 70.177%\n","\n","| Validation Epoch #89\t\t\tLoss: 1.2361 Acc@1: 53.42%\n","\n","=> Training Epoch #90, LR=0.0300\n","| Epoch [ 90/120] Iter[  1/ 47]\t\tLoss: 0.9368 Acc@1: 68.750%\n","| Epoch [ 90/120] Iter[ 16/ 47]\t\tLoss: 0.7386 Acc@1: 70.117%\n","| Epoch [ 90/120] Iter[ 31/ 47]\t\tLoss: 0.9954 Acc@1: 69.758%\n","| Epoch [ 90/120] Iter[ 46/ 47]\t\tLoss: 0.7757 Acc@1: 69.769%\n","\n","| Validation Epoch #90\t\t\tLoss: 0.0095 Acc@1: 52.64%\n","\n","=> Training Epoch #91, LR=0.0300\n","| Epoch [ 91/120] Iter[  1/ 47]\t\tLoss: 0.6524 Acc@1: 79.688%\n","| Epoch [ 91/120] Iter[ 16/ 47]\t\tLoss: 0.5759 Acc@1: 70.898%\n","| Epoch [ 91/120] Iter[ 31/ 47]\t\tLoss: 0.8721 Acc@1: 69.506%\n","| Epoch [ 91/120] Iter[ 46/ 47]\t\tLoss: 0.8185 Acc@1: 69.090%\n","\n","| Validation Epoch #91\t\t\tLoss: 3.2486 Acc@1: 52.32%\n","\n","=> Training Epoch #92, LR=0.0300\n","| Epoch [ 92/120] Iter[  1/ 47]\t\tLoss: 0.8514 Acc@1: 65.625%\n","| Epoch [ 92/120] Iter[ 16/ 47]\t\tLoss: 0.8030 Acc@1: 69.629%\n","| Epoch [ 92/120] Iter[ 31/ 47]\t\tLoss: 0.7189 Acc@1: 70.867%\n","| Epoch [ 92/120] Iter[ 46/ 47]\t\tLoss: 0.9299 Acc@1: 70.516%\n","\n","| Validation Epoch #92\t\t\tLoss: 1.6748 Acc@1: 53.22%\n","\n","=> Training Epoch #93, LR=0.0300\n","| Epoch [ 93/120] Iter[  1/ 47]\t\tLoss: 0.5557 Acc@1: 79.688%\n","| Epoch [ 93/120] Iter[ 16/ 47]\t\tLoss: 0.6505 Acc@1: 70.605%\n","| Epoch [ 93/120] Iter[ 31/ 47]\t\tLoss: 0.8583 Acc@1: 70.968%\n","| Epoch [ 93/120] Iter[ 46/ 47]\t\tLoss: 0.7192 Acc@1: 70.550%\n","\n","| Validation Epoch #93\t\t\tLoss: 1.0088 Acc@1: 55.20%\n","\n","=> Training Epoch #94, LR=0.0300\n","| Epoch [ 94/120] Iter[  1/ 47]\t\tLoss: 0.9018 Acc@1: 67.188%\n","| Epoch [ 94/120] Iter[ 16/ 47]\t\tLoss: 0.9787 Acc@1: 71.582%\n","| Epoch [ 94/120] Iter[ 31/ 47]\t\tLoss: 0.8072 Acc@1: 71.018%\n","| Epoch [ 94/120] Iter[ 46/ 47]\t\tLoss: 0.8309 Acc@1: 69.565%\n","\n","| Validation Epoch #94\t\t\tLoss: 2.3228 Acc@1: 53.06%\n","\n","=> Training Epoch #95, LR=0.0300\n","| Epoch [ 95/120] Iter[  1/ 47]\t\tLoss: 0.9432 Acc@1: 62.500%\n","| Epoch [ 95/120] Iter[ 16/ 47]\t\tLoss: 0.8628 Acc@1: 69.336%\n","| Epoch [ 95/120] Iter[ 31/ 47]\t\tLoss: 0.8480 Acc@1: 70.312%\n","| Epoch [ 95/120] Iter[ 46/ 47]\t\tLoss: 1.1868 Acc@1: 69.565%\n","\n","| Validation Epoch #95\t\t\tLoss: 0.7758 Acc@1: 53.18%\n","\n","=> Training Epoch #96, LR=0.0300\n","| Epoch [ 96/120] Iter[  1/ 47]\t\tLoss: 0.5315 Acc@1: 78.125%\n","| Epoch [ 96/120] Iter[ 16/ 47]\t\tLoss: 1.0146 Acc@1: 69.727%\n","| Epoch [ 96/120] Iter[ 31/ 47]\t\tLoss: 0.8982 Acc@1: 70.565%\n","| Epoch [ 96/120] Iter[ 46/ 47]\t\tLoss: 0.5848 Acc@1: 69.667%\n","\n","| Validation Epoch #96\t\t\tLoss: 0.9289 Acc@1: 54.22%\n","\n","=> Training Epoch #97, LR=0.0300\n","| Epoch [ 97/120] Iter[  1/ 47]\t\tLoss: 0.6552 Acc@1: 75.000%\n","| Epoch [ 97/120] Iter[ 16/ 47]\t\tLoss: 0.9103 Acc@1: 70.996%\n","| Epoch [ 97/120] Iter[ 31/ 47]\t\tLoss: 0.7679 Acc@1: 69.909%\n","| Epoch [ 97/120] Iter[ 46/ 47]\t\tLoss: 1.0056 Acc@1: 69.769%\n","\n","| Validation Epoch #97\t\t\tLoss: 2.1033 Acc@1: 51.56%\n","\n","=> Training Epoch #98, LR=0.0300\n","| Epoch [ 98/120] Iter[  1/ 47]\t\tLoss: 0.7966 Acc@1: 71.875%\n","| Epoch [ 98/120] Iter[ 16/ 47]\t\tLoss: 0.7799 Acc@1: 69.629%\n","| Epoch [ 98/120] Iter[ 31/ 47]\t\tLoss: 0.7309 Acc@1: 70.464%\n","| Epoch [ 98/120] Iter[ 46/ 47]\t\tLoss: 1.1039 Acc@1: 69.260%\n","\n","| Validation Epoch #98\t\t\tLoss: 1.4961 Acc@1: 54.82%\n","\n","=> Training Epoch #99, LR=0.0300\n","| Epoch [ 99/120] Iter[  1/ 47]\t\tLoss: 0.8993 Acc@1: 65.625%\n","| Epoch [ 99/120] Iter[ 16/ 47]\t\tLoss: 0.6597 Acc@1: 71.387%\n","| Epoch [ 99/120] Iter[ 31/ 47]\t\tLoss: 0.9594 Acc@1: 70.010%\n","| Epoch [ 99/120] Iter[ 46/ 47]\t\tLoss: 0.5961 Acc@1: 70.924%\n","\n","| Validation Epoch #99\t\t\tLoss: 0.7381 Acc@1: 55.82%\n","| Saving Best model...\t\t\tTop1 = 55.82%\n","\n","=> Training Epoch #100, LR=0.0300\n","| Epoch [100/120] Iter[  1/ 47]\t\tLoss: 0.8682 Acc@1: 65.625%\n","| Epoch [100/120] Iter[ 16/ 47]\t\tLoss: 0.8993 Acc@1: 71.289%\n","| Epoch [100/120] Iter[ 31/ 47]\t\tLoss: 0.6115 Acc@1: 70.766%\n","| Epoch [100/120] Iter[ 46/ 47]\t\tLoss: 0.6145 Acc@1: 70.686%\n","\n","| Validation Epoch #100\t\t\tLoss: 0.8138 Acc@1: 51.16%\n","\n","=> Training Epoch #101, LR=0.0300\n","| Epoch [101/120] Iter[  1/ 47]\t\tLoss: 0.8404 Acc@1: 70.312%\n","| Epoch [101/120] Iter[ 16/ 47]\t\tLoss: 0.7911 Acc@1: 69.238%\n","| Epoch [101/120] Iter[ 31/ 47]\t\tLoss: 0.7518 Acc@1: 70.716%\n","| Epoch [101/120] Iter[ 46/ 47]\t\tLoss: 1.1733 Acc@1: 70.075%\n","\n","| Validation Epoch #101\t\t\tLoss: 0.3153 Acc@1: 54.14%\n","\n","=> Training Epoch #102, LR=0.0300\n","| Epoch [102/120] Iter[  1/ 47]\t\tLoss: 0.8200 Acc@1: 65.625%\n","| Epoch [102/120] Iter[ 16/ 47]\t\tLoss: 0.5809 Acc@1: 70.117%\n","| Epoch [102/120] Iter[ 31/ 47]\t\tLoss: 0.4699 Acc@1: 69.960%\n","| Epoch [102/120] Iter[ 46/ 47]\t\tLoss: 0.9513 Acc@1: 69.226%\n","\n","| Validation Epoch #102\t\t\tLoss: 0.0330 Acc@1: 53.00%\n","\n","=> Training Epoch #103, LR=0.0300\n","| Epoch [103/120] Iter[  1/ 47]\t\tLoss: 0.9131 Acc@1: 68.750%\n","| Epoch [103/120] Iter[ 16/ 47]\t\tLoss: 0.5695 Acc@1: 70.312%\n","| Epoch [103/120] Iter[ 31/ 47]\t\tLoss: 0.8048 Acc@1: 68.599%\n","| Epoch [103/120] Iter[ 46/ 47]\t\tLoss: 0.6946 Acc@1: 68.954%\n","\n","| Validation Epoch #103\t\t\tLoss: 0.3342 Acc@1: 52.16%\n","\n","=> Training Epoch #104, LR=0.0300\n","| Epoch [104/120] Iter[  1/ 47]\t\tLoss: 0.8854 Acc@1: 65.625%\n","| Epoch [104/120] Iter[ 16/ 47]\t\tLoss: 0.8750 Acc@1: 68.750%\n","| Epoch [104/120] Iter[ 31/ 47]\t\tLoss: 0.5058 Acc@1: 68.952%\n","| Epoch [104/120] Iter[ 46/ 47]\t\tLoss: 0.7939 Acc@1: 69.429%\n","\n","| Validation Epoch #104\t\t\tLoss: 0.4165 Acc@1: 55.92%\n","| Saving Best model...\t\t\tTop1 = 55.92%\n","\n","=> Training Epoch #105, LR=0.0300\n","| Epoch [105/120] Iter[  1/ 47]\t\tLoss: 0.8708 Acc@1: 65.625%\n","| Epoch [105/120] Iter[ 16/ 47]\t\tLoss: 0.7935 Acc@1: 68.945%\n","| Epoch [105/120] Iter[ 31/ 47]\t\tLoss: 1.0347 Acc@1: 68.750%\n","| Epoch [105/120] Iter[ 46/ 47]\t\tLoss: 0.7720 Acc@1: 69.939%\n","\n","| Validation Epoch #105\t\t\tLoss: 0.4572 Acc@1: 57.06%\n","| Saving Best model...\t\t\tTop1 = 57.06%\n","\n","=> Training Epoch #106, LR=0.0300\n","| Epoch [106/120] Iter[  1/ 47]\t\tLoss: 0.6223 Acc@1: 75.000%\n","| Epoch [106/120] Iter[ 16/ 47]\t\tLoss: 0.9538 Acc@1: 70.801%\n","| Epoch [106/120] Iter[ 31/ 47]\t\tLoss: 0.9524 Acc@1: 70.514%\n","| Epoch [106/120] Iter[ 46/ 47]\t\tLoss: 1.0756 Acc@1: 69.361%\n","\n","| Validation Epoch #106\t\t\tLoss: 0.1066 Acc@1: 51.14%\n","\n","=> Training Epoch #107, LR=0.0300\n","| Epoch [107/120] Iter[  1/ 47]\t\tLoss: 0.6605 Acc@1: 78.125%\n","| Epoch [107/120] Iter[ 16/ 47]\t\tLoss: 0.9036 Acc@1: 69.336%\n","| Epoch [107/120] Iter[ 31/ 47]\t\tLoss: 0.7693 Acc@1: 69.556%\n","| Epoch [107/120] Iter[ 46/ 47]\t\tLoss: 0.6026 Acc@1: 69.531%\n","\n","| Validation Epoch #107\t\t\tLoss: 0.2428 Acc@1: 56.68%\n","\n","=> Training Epoch #108, LR=0.0300\n","| Epoch [108/120] Iter[  1/ 47]\t\tLoss: 0.7588 Acc@1: 78.125%\n","| Epoch [108/120] Iter[ 16/ 47]\t\tLoss: 0.5752 Acc@1: 72.852%\n","| Epoch [108/120] Iter[ 31/ 47]\t\tLoss: 0.9350 Acc@1: 71.875%\n","| Epoch [108/120] Iter[ 46/ 47]\t\tLoss: 0.8117 Acc@1: 70.177%\n","\n","| Validation Epoch #108\t\t\tLoss: 0.1976 Acc@1: 48.56%\n","\n","=> Training Epoch #109, LR=0.0300\n","| Epoch [109/120] Iter[  1/ 47]\t\tLoss: 0.8461 Acc@1: 67.188%\n","| Epoch [109/120] Iter[ 16/ 47]\t\tLoss: 0.9585 Acc@1: 70.312%\n","| Epoch [109/120] Iter[ 31/ 47]\t\tLoss: 0.8464 Acc@1: 70.312%\n","| Epoch [109/120] Iter[ 46/ 47]\t\tLoss: 0.7988 Acc@1: 69.633%\n","\n","| Validation Epoch #109\t\t\tLoss: 0.9549 Acc@1: 52.98%\n","\n","=> Training Epoch #110, LR=0.0300\n","| Epoch [110/120] Iter[  1/ 47]\t\tLoss: 0.6782 Acc@1: 73.438%\n","| Epoch [110/120] Iter[ 16/ 47]\t\tLoss: 0.9604 Acc@1: 71.973%\n","| Epoch [110/120] Iter[ 31/ 47]\t\tLoss: 0.9403 Acc@1: 70.262%\n","| Epoch [110/120] Iter[ 46/ 47]\t\tLoss: 0.7913 Acc@1: 69.531%\n","\n","| Validation Epoch #110\t\t\tLoss: 0.3473 Acc@1: 57.12%\n","| Saving Best model...\t\t\tTop1 = 57.12%\n","\n","=> Training Epoch #111, LR=0.0300\n","| Epoch [111/120] Iter[  1/ 47]\t\tLoss: 0.6290 Acc@1: 78.125%\n","| Epoch [111/120] Iter[ 16/ 47]\t\tLoss: 0.5208 Acc@1: 71.777%\n","| Epoch [111/120] Iter[ 31/ 47]\t\tLoss: 0.7656 Acc@1: 70.363%\n","| Epoch [111/120] Iter[ 46/ 47]\t\tLoss: 0.7040 Acc@1: 69.871%\n","\n","| Validation Epoch #111\t\t\tLoss: 1.6708 Acc@1: 53.48%\n","\n","=> Training Epoch #112, LR=0.0300\n","| Epoch [112/120] Iter[  1/ 47]\t\tLoss: 0.9682 Acc@1: 62.500%\n","| Epoch [112/120] Iter[ 16/ 47]\t\tLoss: 0.6858 Acc@1: 71.289%\n","| Epoch [112/120] Iter[ 31/ 47]\t\tLoss: 0.8365 Acc@1: 70.867%\n","| Epoch [112/120] Iter[ 46/ 47]\t\tLoss: 0.8935 Acc@1: 70.177%\n","\n","| Validation Epoch #112\t\t\tLoss: 0.9848 Acc@1: 51.16%\n","\n","=> Training Epoch #113, LR=0.0300\n","| Epoch [113/120] Iter[  1/ 47]\t\tLoss: 0.6810 Acc@1: 73.438%\n","| Epoch [113/120] Iter[ 16/ 47]\t\tLoss: 0.8604 Acc@1: 71.094%\n","| Epoch [113/120] Iter[ 31/ 47]\t\tLoss: 0.6986 Acc@1: 70.665%\n","| Epoch [113/120] Iter[ 46/ 47]\t\tLoss: 0.8856 Acc@1: 70.380%\n","\n","| Validation Epoch #113\t\t\tLoss: 1.2935 Acc@1: 52.16%\n","\n","=> Training Epoch #114, LR=0.0300\n","| Epoch [114/120] Iter[  1/ 47]\t\tLoss: 0.9027 Acc@1: 60.938%\n","| Epoch [114/120] Iter[ 16/ 47]\t\tLoss: 0.8266 Acc@1: 71.582%\n","| Epoch [114/120] Iter[ 31/ 47]\t\tLoss: 0.7950 Acc@1: 70.111%\n","| Epoch [114/120] Iter[ 46/ 47]\t\tLoss: 1.0248 Acc@1: 70.109%\n","\n","| Validation Epoch #114\t\t\tLoss: 0.5889 Acc@1: 56.64%\n","\n","=> Training Epoch #115, LR=0.0300\n","| Epoch [115/120] Iter[  1/ 47]\t\tLoss: 0.9359 Acc@1: 65.625%\n","| Epoch [115/120] Iter[ 16/ 47]\t\tLoss: 0.7343 Acc@1: 70.898%\n","| Epoch [115/120] Iter[ 31/ 47]\t\tLoss: 0.7180 Acc@1: 71.119%\n","| Epoch [115/120] Iter[ 46/ 47]\t\tLoss: 0.7541 Acc@1: 71.196%\n","\n","| Validation Epoch #115\t\t\tLoss: 0.2389 Acc@1: 53.12%\n","\n","=> Training Epoch #116, LR=0.0300\n","| Epoch [116/120] Iter[  1/ 47]\t\tLoss: 0.7582 Acc@1: 70.312%\n","| Epoch [116/120] Iter[ 16/ 47]\t\tLoss: 0.8498 Acc@1: 72.266%\n","| Epoch [116/120] Iter[ 31/ 47]\t\tLoss: 0.7830 Acc@1: 71.774%\n","| Epoch [116/120] Iter[ 46/ 47]\t\tLoss: 0.6672 Acc@1: 71.569%\n","\n","| Validation Epoch #116\t\t\tLoss: 0.7450 Acc@1: 54.18%\n","\n","=> Training Epoch #117, LR=0.0300\n","| Epoch [117/120] Iter[  1/ 47]\t\tLoss: 1.0712 Acc@1: 60.938%\n","| Epoch [117/120] Iter[ 16/ 47]\t\tLoss: 0.9209 Acc@1: 70.996%\n","| Epoch [117/120] Iter[ 31/ 47]\t\tLoss: 0.6431 Acc@1: 70.565%\n","| Epoch [117/120] Iter[ 46/ 47]\t\tLoss: 0.7929 Acc@1: 70.482%\n","\n","| Validation Epoch #117\t\t\tLoss: 1.3613 Acc@1: 52.36%\n","\n","=> Training Epoch #118, LR=0.0300\n","| Epoch [118/120] Iter[  1/ 47]\t\tLoss: 0.8779 Acc@1: 65.625%\n","| Epoch [118/120] Iter[ 16/ 47]\t\tLoss: 0.7566 Acc@1: 70.801%\n","| Epoch [118/120] Iter[ 31/ 47]\t\tLoss: 0.7492 Acc@1: 70.464%\n","| Epoch [118/120] Iter[ 46/ 47]\t\tLoss: 0.6947 Acc@1: 70.211%\n","\n","| Validation Epoch #118\t\t\tLoss: 0.0948 Acc@1: 53.14%\n","\n","=> Training Epoch #119, LR=0.0300\n","| Epoch [119/120] Iter[  1/ 47]\t\tLoss: 1.0281 Acc@1: 65.625%\n","| Epoch [119/120] Iter[ 16/ 47]\t\tLoss: 0.6435 Acc@1: 69.727%\n","| Epoch [119/120] Iter[ 31/ 47]\t\tLoss: 0.8555 Acc@1: 70.262%\n","| Epoch [119/120] Iter[ 46/ 47]\t\tLoss: 1.0452 Acc@1: 69.192%\n","\n","| Validation Epoch #119\t\t\tLoss: 0.3431 Acc@1: 54.06%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o_7i2arPr7ZL"},"source":["weak_transform = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4, padding_mode = 'reflect'),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2471, 0.2435, 0.2616)),\n","])\n","\n","\n","x_pseudolabeled = np.empty(shape = [0,32,32,3])\n","y_pseudolabeled = np.empty(shape = [0,])\n","\n","# Dataset where we will save the new data with pseudolabels\n","pseudolabel_dataset = Dataset_sub_CIFAR(x_pseudolabeled , y_pseudolabeled, transform=strong_transform_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"su5jOisKy52q"},"source":["def get_pseudolabels(pseudolabel_dataset, x_unlabeled, y_unlabeled, mu, thresh=0.9):\n","    \n","    #First we create a data loader with the remaining unlabeled data\n","    unloader = torch.utils.data.DataLoader(\n","        Dataset_sub_CIFAR(x_unlabeled, y_unlabeled, transform=weak_transform),\n","        batch_size = batch_size,\n","        shuffle=True, num_workers=2)\n","\n","    #Create dictionary with images and the respective pseudolabel\n","    dic={}\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets, index) in enumerate(unloader):\n","            inputs, targets = inputs.cuda(), targets.cuda()\n","            inputs, targets = Variable(inputs), Variable(targets)\n","            outputs = net_save(inputs)\n","            probs = torch.softmax(outputs, dim=1)\n","            scores, lbs = torch.max(probs, dim=1)\n","            idx = scores > thresh\n","            ind = index[idx].tolist()\n","            label = lbs[idx].tolist()\n","            for i in range(len(ind)):\n","                if ind[i] in dic:\n","                    if label[i]!=dic[ind[i]]:\n","                        print(\"Different Labels\")\n","                else:\n","                    dic[ind[i]]=label[i]\n","                    \n","                    \n","    #Select mu*size samples with score greater then the thresh\n","    indexes = np.array(list(dic.keys()), dtype= int)\n","    select_idx = np.random.choice(indexes, size=min(2*(1000+len(pseudolabel_dataset)), len(indexes)), replace=False)\n","    \n","    #Get the data\n","    new_data = x_unlabeled[select_idx].astype('uint8')\n","    new_label = [dic.get(key) for key in select_idx]\n","    new_label = np.array(new_label).astype('int64')\n","    \n","    # Add the new data to the pseudolabeled dataset\n","    new_dataset = Dataset_sub_CIFAR(new_data , new_label, transform=strong_transform_train)\n","    pseudolabel_dataset = torch.utils.data.ConcatDataset([pseudolabel_dataset, new_dataset])\n","  \n","    # And then we remove the data from the unlabeled dataset\n","    x_unlabeled = np.delete(x_unlabeled, select_idx, axis=0)\n","    y_unlabeled = np.delete(y_unlabeled, select_idx, axis=0)\n","    \n","    \n","    #Create a new dataloader with the pseudolabel dataset\n","    if len(new_dataset)>0:\n","        dataloader = torch.utils.data.DataLoader(pseudolabel_dataset, batch_size=32,shuffle=True, num_workers=1) #num_workers = 2 ou 1\n","    else:\n","        dataloader= train_loader\n","    \n","    \n","    #Return the new pseudolabel dataset, the dataloader, and the unlabeled data and labels\n","    return pseudolabel_dataset, dataloader, x_unlabeled, y_unlabeled\n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iLozeIniAzS9"},"source":["from torch.optim.lr_scheduler import _LRScheduler\n","class WarmupCosineLrScheduler(_LRScheduler):\n","    '''\n","    This is different from official definition, this is implemented according to\n","    the paper of fix-match\n","    '''\n","    def __init__(\n","            self,\n","            optimizer,\n","            max_iter,\n","            warmup_iter,\n","            warmup_ratio=5e-4,\n","            warmup='exp',\n","            last_epoch=-1,\n","    ):\n","        self.max_iter = max_iter\n","        self.warmup_iter = warmup_iter\n","        self.warmup_ratio = warmup_ratio\n","        self.warmup = warmup\n","        super(WarmupCosineLrScheduler, self).__init__(optimizer, last_epoch)\n","\n","    def get_lr(self):\n","        ratio = self.get_lr_ratio()\n","        lrs = [ratio * lr for lr in self.base_lrs]\n","        return lrs\n","\n","    def get_lr_ratio(self):\n","        if self.last_epoch < self.warmup_iter:\n","            ratio = self.get_warmup_ratio()\n","        else:\n","            real_iter = self.last_epoch - self.warmup_iter\n","            real_max_iter = self.max_iter - self.warmup_iter\n","            ratio = np.cos((7 * np.pi * real_iter) / (16 * real_max_iter))\n","        return ratio\n","\n","    def get_warmup_ratio(self):\n","        assert self.warmup in ('linear', 'exp')\n","        alpha = self.last_epoch / self.warmup_iter\n","        if self.warmup == 'linear':\n","            ratio = self.warmup_ratio + (1 - self.warmup_ratio) * alpha\n","        elif self.warmup == 'exp':\n","            ratio = self.warmup_ratio ** (1. - alpha)\n","        return ratio\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5k7o2kbvsecW"},"source":["![pipeline.png](data:image/png;base64,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)"]},{"cell_type":"code","metadata":{"id":"x9VX8IxC-NsG"},"source":["# Training\n","def train(epoch,net, trainloader, new_trainloader, learning_rate, log_interval=15, lamb = 1):\n","    net.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","    print('\\n=> Training Epoch #%d, LR=%.4f' %(epoch, learning_rate))\n","    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=bn_momentum , weight_decay=0.0004)\n","    for batch_idx, data in enumerate(zip(train_loader, new_trainloader)):\n","        \n","        (inputs_x, targets_x , index_x), (inputs_u, targets_u , index_u) = data\n","        # GPU settings\n","        inputs_x, targets_x = inputs_x.cuda(), targets_x.cuda()\n","        inputs_u, targets_u = inputs_u.cuda(), targets_u.cuda() \n","        \n","        #Data \n","        inputs_x, targets_x = Variable(inputs_x), Variable(targets_x)\n","        inputs_u, targets_u = Variable(inputs_u), Variable(targets_u)\n","\n","        \n","        optimizer.zero_grad()\n","        outputs_x = net(inputs_x)               # Forward Propagation\n","        outputs_u = net(inputs_u)               \n","        \n","        # Loss for each type of data and final loss\n","        loss_x = criterion(outputs_x, targets_x)  \n","        loss_u = criterion(outputs_u, targets_u) \n","        loss = loss_x + lamb* loss_u\n","        # Loss\n","        loss.backward()  # Backward Propagation\n","        optimizer.step() # Optimizer update\n","\n","        train_loss += loss.item()\n","        _, predicted_x = torch.max(outputs_x.data, 1)\n","        _, predicted_u = torch.max(outputs_u.data, 1)\n","        total += targets_x.size(0)\n","        total += targets_u.size(0)\n","        correct += predicted_x.eq(targets_x.data).cpu().sum()\n","        correct += predicted_u.eq(targets_u.data).cpu().sum()\n","        if batch_idx % log_interval == 0:\n","            print('| Epoch [%3d/%3d] Iter[%3d/%3d]\\t\\tLoss: %.4f Acc@1: %.3f%%'\n","                %(epoch, num_epochs, batch_idx+1,\n","                    ((len(new_trainloader.dataset)//batch_size)+(len(trainloader.dataset)//batch_size))+1, loss.item(), 100.*correct/total))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QRWRnq04secX"},"source":["mu = 2\n","batch_size = 64\n","num_epochs=1080\n","bn_momentum = 0.9\n","l_thresh = np.linspace(0.98, 0.95 , num=num_epochs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vz8vbGpvsecX","outputId":"6c9cabe4-c34c-494a-b43d-4ab2f43b1bd2"},"source":["op = optim.SGD(net.parameters(), lr=0.06, momentum=bn_momentum , weight_decay=0.0004)\n","lr_scheduler = WarmupCosineLrScheduler(op, 1080, 0, 0.06, 'linear', -1)\n","net.load_state_dict(net_save.state_dict(), strict=True)\n","for epoch in range(num_epochs):\n","    if(epoch%120==0):\n","        pseudolabel_dataset , new_train_loader , x_unlabeled, y_unlabeled = get_pseudolabels(pseudolabel_dataset, x_unlabeled, y_unlabeled, mu=2, thresh= 0.95)\n","        print('| New Samples', len(new_train_loader.dataset) )\n","    \n","    train(epoch, net, train_loader, new_train_loader, learning_rate=lr_scheduler.get_lr()[0], lamb = 1)\n","    lr_scheduler.step()\n","    acc =test(epoch,net,valid_loader)\n","    # Save checkpoint when best model\n","    if acc > best_acc:\n","        print('| Saving Best model...\\t\\t\\tTop1 = %.2f%%' %(acc))\n","        net_save.load_state_dict(net.state_dict(), strict=True)\n","        best_acc=acc"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","=> Training Epoch #1, LR=0.0600\n","| Epoch [  1/1080] Iter[  1/234]\t\tLoss: 2.8198 Acc@1: 55.208%\n","| Epoch [  1/1080] Iter[ 16/234]\t\tLoss: 3.3248 Acc@1: 52.604%\n","| Epoch [  1/1080] Iter[ 31/234]\t\tLoss: 3.0482 Acc@1: 52.319%\n","| Epoch [  1/1080] Iter[ 46/234]\t\tLoss: 2.8828 Acc@1: 52.627%\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["\u001b[1;30;43mA saída de streaming foi truncada nas últimas 5000 linhas.\u001b[0m\n","=> Training Epoch #225, LR=0.0576\n","| Epoch [225/1080] Iter[  1/370]\t\tLoss: 2.7253 Acc@1: 60.417%\n","| Epoch [225/1080] Iter[ 16/370]\t\tLoss: 2.8761 Acc@1: 55.534%\n","| Epoch [225/1080] Iter[ 31/370]\t\tLoss: 2.9024 Acc@1: 55.309%\n","| Epoch [225/1080] Iter[ 46/370]\t\tLoss: 2.7871 Acc@1: 54.348%\n","\n","| Validation Epoch #225\t\t\tLoss: 0.3426 Acc@1: 64.44%\n","\n","=> Training Epoch #226, LR=0.0576\n","| Epoch [226/1080] Iter[  1/370]\t\tLoss: 2.6031 Acc@1: 58.333%\n","| Epoch [226/1080] Iter[ 16/370]\t\tLoss: 2.8935 Acc@1: 54.362%\n","| Epoch [226/1080] Iter[ 31/370]\t\tLoss: 2.8860 Acc@1: 53.965%\n","| Epoch [226/1080] Iter[ 46/370]\t\tLoss: 2.8386 Acc@1: 53.623%\n","\n","| Validation Epoch #226\t\t\tLoss: 0.0015 Acc@1: 63.30%\n","\n","=> Training Epoch #227, LR=0.0575\n","| Epoch [227/1080] Iter[  1/370]\t\tLoss: 2.8319 Acc@1: 56.250%\n","| Epoch [227/1080] Iter[ 16/370]\t\tLoss: 2.7462 Acc@1: 54.818%\n","| Epoch [227/1080] Iter[ 31/370]\t\tLoss: 2.5571 Acc@1: 53.864%\n","| Epoch [227/1080] Iter[ 46/370]\t\tLoss: 2.8499 Acc@1: 54.348%\n","\n","| Validation Epoch #227\t\t\tLoss: 0.0330 Acc@1: 61.66%\n","\n","=> Training Epoch #228, LR=0.0575\n","| Epoch [228/1080] Iter[  1/370]\t\tLoss: 2.8360 Acc@1: 54.167%\n","| Epoch [228/1080] Iter[ 16/370]\t\tLoss: 2.7171 Acc@1: 54.362%\n","| Epoch [228/1080] Iter[ 31/370]\t\tLoss: 2.9525 Acc@1: 54.301%\n","| Epoch [228/1080] Iter[ 46/370]\t\tLoss: 2.9036 Acc@1: 54.348%\n","\n","| Validation Epoch #228\t\t\tLoss: 0.0010 Acc@1: 58.78%\n","\n","=> Training Epoch #229, LR=0.0575\n","| Epoch [229/1080] Iter[  1/370]\t\tLoss: 2.9583 Acc@1: 53.125%\n","| Epoch [229/1080] Iter[ 16/370]\t\tLoss: 3.1130 Acc@1: 53.385%\n","| Epoch [229/1080] Iter[ 31/370]\t\tLoss: 2.8045 Acc@1: 53.293%\n","| Epoch [229/1080] Iter[ 46/370]\t\tLoss: 2.9562 Acc@1: 53.351%\n","\n","| Validation Epoch #229\t\t\tLoss: 0.0015 Acc@1: 62.82%\n","\n","=> Training Epoch #230, LR=0.0575\n","| Epoch [230/1080] Iter[  1/370]\t\tLoss: 3.1429 Acc@1: 47.917%\n","| Epoch [230/1080] Iter[ 16/370]\t\tLoss: 2.7593 Acc@1: 55.599%\n","| Epoch [230/1080] Iter[ 31/370]\t\tLoss: 2.9337 Acc@1: 55.175%\n","| Epoch [230/1080] Iter[ 46/370]\t\tLoss: 2.6334 Acc@1: 53.963%\n","\n","| Validation Epoch #230\t\t\tLoss: 0.0044 Acc@1: 63.48%\n","\n","=> Training Epoch #231, LR=0.0574\n","| Epoch [231/1080] Iter[  1/370]\t\tLoss: 3.0313 Acc@1: 45.833%\n","| Epoch [231/1080] Iter[ 16/370]\t\tLoss: 2.7415 Acc@1: 54.167%\n","| Epoch [231/1080] Iter[ 31/370]\t\tLoss: 3.0056 Acc@1: 54.301%\n","| Epoch [231/1080] Iter[ 46/370]\t\tLoss: 3.1413 Acc@1: 53.850%\n","\n","| Validation Epoch #231\t\t\tLoss: 0.5023 Acc@1: 63.70%\n","\n","=> Training Epoch #232, LR=0.0574\n","| Epoch [232/1080] Iter[  1/370]\t\tLoss: 2.9374 Acc@1: 53.125%\n","| Epoch [232/1080] Iter[ 16/370]\t\tLoss: 2.9186 Acc@1: 53.646%\n","| Epoch [232/1080] Iter[ 31/370]\t\tLoss: 2.9657 Acc@1: 53.898%\n","| Epoch [232/1080] Iter[ 46/370]\t\tLoss: 2.8994 Acc@1: 53.850%\n","\n","| Validation Epoch #232\t\t\tLoss: 0.3995 Acc@1: 64.68%\n","\n","=> Training Epoch #233, LR=0.0574\n","| Epoch [233/1080] Iter[  1/370]\t\tLoss: 2.8250 Acc@1: 52.083%\n","| Epoch [233/1080] Iter[ 16/370]\t\tLoss: 3.2131 Acc@1: 53.711%\n","| Epoch [233/1080] Iter[ 31/370]\t\tLoss: 2.5475 Acc@1: 53.965%\n","| Epoch [233/1080] Iter[ 46/370]\t\tLoss: 2.9191 Acc@1: 53.759%\n","\n","| Validation Epoch #233\t\t\tLoss: 0.6384 Acc@1: 63.42%\n","\n","=> Training Epoch #234, LR=0.0574\n","| Epoch [234/1080] Iter[  1/370]\t\tLoss: 2.8100 Acc@1: 56.250%\n","| Epoch [234/1080] Iter[ 16/370]\t\tLoss: 3.0200 Acc@1: 52.734%\n","| Epoch [234/1080] Iter[ 31/370]\t\tLoss: 2.7506 Acc@1: 53.058%\n","| Epoch [234/1080] Iter[ 46/370]\t\tLoss: 2.9138 Acc@1: 53.306%\n","\n","| Validation Epoch #234\t\t\tLoss: 0.0067 Acc@1: 58.40%\n","\n","=> Training Epoch #235, LR=0.0574\n","| Epoch [235/1080] Iter[  1/370]\t\tLoss: 2.9260 Acc@1: 51.042%\n","| Epoch [235/1080] Iter[ 16/370]\t\tLoss: 3.0450 Acc@1: 52.995%\n","| Epoch [235/1080] Iter[ 31/370]\t\tLoss: 2.9237 Acc@1: 53.125%\n","| Epoch [235/1080] Iter[ 46/370]\t\tLoss: 2.8236 Acc@1: 53.012%\n","\n","| Validation Epoch #235\t\t\tLoss: 1.0026 Acc@1: 59.70%\n","\n","=> Training Epoch #236, LR=0.0573\n","| Epoch [236/1080] Iter[  1/370]\t\tLoss: 3.1876 Acc@1: 47.917%\n","| Epoch [236/1080] Iter[ 16/370]\t\tLoss: 2.7114 Acc@1: 54.232%\n","| Epoch [236/1080] Iter[ 31/370]\t\tLoss: 3.1195 Acc@1: 54.167%\n","| Epoch [236/1080] Iter[ 46/370]\t\tLoss: 2.9009 Acc@1: 54.393%\n","\n","| Validation Epoch #236\t\t\tLoss: 0.0005 Acc@1: 58.54%\n","\n","=> Training Epoch #237, LR=0.0573\n","| Epoch [237/1080] Iter[  1/370]\t\tLoss: 2.9423 Acc@1: 51.042%\n","| Epoch [237/1080] Iter[ 16/370]\t\tLoss: 2.8325 Acc@1: 56.641%\n","| Epoch [237/1080] Iter[ 31/370]\t\tLoss: 3.0248 Acc@1: 55.645%\n","| Epoch [237/1080] Iter[ 46/370]\t\tLoss: 3.0470 Acc@1: 54.642%\n","\n","| Validation Epoch #237\t\t\tLoss: 0.1961 Acc@1: 65.24%\n","\n","=> Training Epoch #238, LR=0.0573\n","| Epoch [238/1080] Iter[  1/370]\t\tLoss: 2.8632 Acc@1: 52.083%\n","| Epoch [238/1080] Iter[ 16/370]\t\tLoss: 2.8059 Acc@1: 58.073%\n","| Epoch [238/1080] Iter[ 31/370]\t\tLoss: 2.9339 Acc@1: 54.805%\n","| Epoch [238/1080] Iter[ 46/370]\t\tLoss: 3.2182 Acc@1: 54.393%\n","\n","| Validation Epoch #238\t\t\tLoss: 0.0109 Acc@1: 63.04%\n","\n","=> Training Epoch #239, LR=0.0573\n","| Epoch [239/1080] Iter[  1/370]\t\tLoss: 2.6945 Acc@1: 53.125%\n","| Epoch [239/1080] Iter[ 16/370]\t\tLoss: 2.7669 Acc@1: 52.995%\n","| Epoch [239/1080] Iter[ 31/370]\t\tLoss: 3.0180 Acc@1: 53.495%\n","| Epoch [239/1080] Iter[ 46/370]\t\tLoss: 2.8573 Acc@1: 53.623%\n","\n","| Validation Epoch #239\t\t\tLoss: 0.2064 Acc@1: 63.46%\n","| New Samples 24424\n","\n","=> Training Epoch #240, LR=0.0572\n","| Epoch [240/1080] Iter[  1/428]\t\tLoss: 2.9605 Acc@1: 51.042%\n","| Epoch [240/1080] Iter[ 16/428]\t\tLoss: 3.2088 Acc@1: 54.167%\n","| Epoch [240/1080] Iter[ 31/428]\t\tLoss: 3.0378 Acc@1: 52.923%\n","| Epoch [240/1080] Iter[ 46/428]\t\tLoss: 2.8859 Acc@1: 53.216%\n","\n","| Validation Epoch #240\t\t\tLoss: 0.6908 Acc@1: 60.84%\n","\n","=> Training Epoch #241, LR=0.0572\n","| Epoch [241/1080] Iter[  1/428]\t\tLoss: 2.3293 Acc@1: 69.792%\n","| Epoch [241/1080] Iter[ 16/428]\t\tLoss: 2.8193 Acc@1: 55.013%\n","| Epoch [241/1080] Iter[ 31/428]\t\tLoss: 2.9085 Acc@1: 54.167%\n","| Epoch [241/1080] Iter[ 46/428]\t\tLoss: 3.1424 Acc@1: 54.189%\n","\n","| Validation Epoch #241\t\t\tLoss: 0.5101 Acc@1: 63.02%\n","\n","=> Training Epoch #242, LR=0.0572\n","| Epoch [242/1080] Iter[  1/428]\t\tLoss: 3.0702 Acc@1: 51.042%\n","| Epoch [242/1080] Iter[ 16/428]\t\tLoss: 2.5628 Acc@1: 53.646%\n","| Epoch [242/1080] Iter[ 31/428]\t\tLoss: 2.8500 Acc@1: 53.831%\n","| Epoch [242/1080] Iter[ 46/428]\t\tLoss: 2.6796 Acc@1: 53.986%\n","\n","| Validation Epoch #242\t\t\tLoss: 0.1259 Acc@1: 58.14%\n","\n","=> Training Epoch #243, LR=0.0572\n","| Epoch [243/1080] Iter[  1/428]\t\tLoss: 2.8948 Acc@1: 50.000%\n","| Epoch [243/1080] Iter[ 16/428]\t\tLoss: 2.6702 Acc@1: 54.362%\n","| Epoch [243/1080] Iter[ 31/428]\t\tLoss: 3.2090 Acc@1: 53.293%\n","| Epoch [243/1080] Iter[ 46/428]\t\tLoss: 2.7615 Acc@1: 53.736%\n","\n","| Validation Epoch #243\t\t\tLoss: 0.8431 Acc@1: 52.24%\n","\n","=> Training Epoch #244, LR=0.0572\n","| Epoch [244/1080] Iter[  1/428]\t\tLoss: 3.0006 Acc@1: 57.292%\n","| Epoch [244/1080] Iter[ 16/428]\t\tLoss: 2.8716 Acc@1: 53.255%\n","| Epoch [244/1080] Iter[ 31/428]\t\tLoss: 2.9689 Acc@1: 52.957%\n","| Epoch [244/1080] Iter[ 46/428]\t\tLoss: 2.9664 Acc@1: 52.763%\n","\n","| Validation Epoch #244\t\t\tLoss: 1.9271 Acc@1: 59.04%\n","\n","=> Training Epoch #245, LR=0.0571\n","| Epoch [245/1080] Iter[  1/428]\t\tLoss: 3.0262 Acc@1: 52.083%\n","| Epoch [245/1080] Iter[ 16/428]\t\tLoss: 2.8781 Acc@1: 55.078%\n","| Epoch [245/1080] Iter[ 31/428]\t\tLoss: 3.0115 Acc@1: 54.469%\n","| Epoch [245/1080] Iter[ 46/428]\t\tLoss: 2.9291 Acc@1: 54.099%\n","\n","| Validation Epoch #245\t\t\tLoss: 0.5547 Acc@1: 61.58%\n","\n","=> Training Epoch #246, LR=0.0571\n","| Epoch [246/1080] Iter[  1/428]\t\tLoss: 2.9552 Acc@1: 50.000%\n","| Epoch [246/1080] Iter[ 16/428]\t\tLoss: 2.8827 Acc@1: 53.581%\n","| Epoch [246/1080] Iter[ 31/428]\t\tLoss: 2.9084 Acc@1: 53.629%\n","| Epoch [246/1080] Iter[ 46/428]\t\tLoss: 2.9403 Acc@1: 53.736%\n","\n","| Validation Epoch #246\t\t\tLoss: 0.9985 Acc@1: 44.22%\n","\n","=> Training Epoch #247, LR=0.0571\n","| Epoch [247/1080] Iter[  1/428]\t\tLoss: 3.1684 Acc@1: 48.958%\n","| Epoch [247/1080] Iter[ 16/428]\t\tLoss: 2.7390 Acc@1: 54.297%\n","| Epoch [247/1080] Iter[ 31/428]\t\tLoss: 3.0983 Acc@1: 54.301%\n","| Epoch [247/1080] Iter[ 46/428]\t\tLoss: 2.9343 Acc@1: 53.329%\n","\n","| Validation Epoch #247\t\t\tLoss: 0.0031 Acc@1: 57.42%\n","\n","=> Training Epoch #248, LR=0.0571\n","| Epoch [248/1080] Iter[  1/428]\t\tLoss: 2.8143 Acc@1: 54.167%\n","| Epoch [248/1080] Iter[ 16/428]\t\tLoss: 2.7495 Acc@1: 53.971%\n","| Epoch [248/1080] Iter[ 31/428]\t\tLoss: 2.8670 Acc@1: 53.730%\n","| Epoch [248/1080] Iter[ 46/428]\t\tLoss: 3.1740 Acc@1: 53.533%\n","\n","| Validation Epoch #248\t\t\tLoss: 0.0230 Acc@1: 63.60%\n","\n","=> Training Epoch #249, LR=0.0570\n","| Epoch [249/1080] Iter[  1/428]\t\tLoss: 2.5134 Acc@1: 62.500%\n","| Epoch [249/1080] Iter[ 16/428]\t\tLoss: 2.8307 Acc@1: 54.492%\n","| Epoch [249/1080] Iter[ 31/428]\t\tLoss: 3.4337 Acc@1: 53.562%\n","| Epoch [249/1080] Iter[ 46/428]\t\tLoss: 2.8716 Acc@1: 53.351%\n","\n","| Validation Epoch #249\t\t\tLoss: 0.0960 Acc@1: 62.56%\n","\n","=> Training Epoch #250, LR=0.0570\n","| Epoch [250/1080] Iter[  1/428]\t\tLoss: 2.7554 Acc@1: 54.167%\n","| Epoch [250/1080] Iter[ 16/428]\t\tLoss: 3.1244 Acc@1: 53.646%\n","| Epoch [250/1080] Iter[ 31/428]\t\tLoss: 2.7674 Acc@1: 54.402%\n","| Epoch [250/1080] Iter[ 46/428]\t\tLoss: 3.0317 Acc@1: 53.736%\n","\n","| Validation Epoch #250\t\t\tLoss: 0.3256 Acc@1: 64.12%\n","\n","=> Training Epoch #251, LR=0.0570\n","| Epoch [251/1080] Iter[  1/428]\t\tLoss: 2.5995 Acc@1: 58.333%\n","| Epoch [251/1080] Iter[ 16/428]\t\tLoss: 3.3701 Acc@1: 53.385%\n","| Epoch [251/1080] Iter[ 31/428]\t\tLoss: 2.8044 Acc@1: 53.562%\n","| Epoch [251/1080] Iter[ 46/428]\t\tLoss: 3.1813 Acc@1: 53.261%\n","\n","| Validation Epoch #251\t\t\tLoss: 0.2961 Acc@1: 63.62%\n","\n","=> Training Epoch #252, LR=0.0570\n","| Epoch [252/1080] Iter[  1/428]\t\tLoss: 2.8024 Acc@1: 53.125%\n","| Epoch [252/1080] Iter[ 16/428]\t\tLoss: 3.0502 Acc@1: 52.669%\n","| Epoch [252/1080] Iter[ 31/428]\t\tLoss: 2.7230 Acc@1: 53.797%\n","| Epoch [252/1080] Iter[ 46/428]\t\tLoss: 3.0599 Acc@1: 54.008%\n","\n","| Validation Epoch #252\t\t\tLoss: 1.0680 Acc@1: 59.02%\n","\n","=> Training Epoch #253, LR=0.0569\n","| Epoch [253/1080] Iter[  1/428]\t\tLoss: 2.8209 Acc@1: 59.375%\n","| Epoch [253/1080] Iter[ 16/428]\t\tLoss: 2.7818 Acc@1: 54.036%\n","| Epoch [253/1080] Iter[ 31/428]\t\tLoss: 2.5866 Acc@1: 55.141%\n","| Epoch [253/1080] Iter[ 46/428]\t\tLoss: 2.8368 Acc@1: 54.076%\n","\n","| Validation Epoch #253\t\t\tLoss: 0.0237 Acc@1: 59.06%\n","\n","=> Training Epoch #254, LR=0.0569\n","| Epoch [254/1080] Iter[  1/428]\t\tLoss: 2.8133 Acc@1: 57.292%\n","| Epoch [254/1080] Iter[ 16/428]\t\tLoss: 2.8551 Acc@1: 56.250%\n","| Epoch [254/1080] Iter[ 31/428]\t\tLoss: 2.6786 Acc@1: 54.738%\n","| Epoch [254/1080] Iter[ 46/428]\t\tLoss: 2.8769 Acc@1: 55.050%\n","\n","| Validation Epoch #254\t\t\tLoss: 0.3013 Acc@1: 58.88%\n","\n","=> Training Epoch #255, LR=0.0569\n","| Epoch [255/1080] Iter[  1/428]\t\tLoss: 2.9302 Acc@1: 52.083%\n","| Epoch [255/1080] Iter[ 16/428]\t\tLoss: 2.8268 Acc@1: 54.622%\n","| Epoch [255/1080] Iter[ 31/428]\t\tLoss: 2.8311 Acc@1: 53.595%\n","| Epoch [255/1080] Iter[ 46/428]\t\tLoss: 2.8459 Acc@1: 54.031%\n","\n","| Validation Epoch #255\t\t\tLoss: 0.0360 Acc@1: 60.46%\n","\n","=> Training Epoch #256, LR=0.0569\n","| Epoch [256/1080] Iter[  1/428]\t\tLoss: 2.9200 Acc@1: 54.167%\n","| Epoch [256/1080] Iter[ 16/428]\t\tLoss: 3.1362 Acc@1: 54.362%\n","| Epoch [256/1080] Iter[ 31/428]\t\tLoss: 3.3008 Acc@1: 53.293%\n","| Epoch [256/1080] Iter[ 46/428]\t\tLoss: 2.9042 Acc@1: 53.261%\n","\n","| Validation Epoch #256\t\t\tLoss: 0.3689 Acc@1: 58.24%\n","\n","=> Training Epoch #257, LR=0.0568\n","| Epoch [257/1080] Iter[  1/428]\t\tLoss: 2.8820 Acc@1: 53.125%\n","| Epoch [257/1080] Iter[ 16/428]\t\tLoss: 3.1857 Acc@1: 52.995%\n","| Epoch [257/1080] Iter[ 31/428]\t\tLoss: 3.0157 Acc@1: 53.259%\n","| Epoch [257/1080] Iter[ 46/428]\t\tLoss: 2.8368 Acc@1: 53.465%\n","\n","| Validation Epoch #257\t\t\tLoss: 0.1708 Acc@1: 59.80%\n","\n","=> Training Epoch #258, LR=0.0568\n","| Epoch [258/1080] Iter[  1/428]\t\tLoss: 3.1941 Acc@1: 45.833%\n","| Epoch [258/1080] Iter[ 16/428]\t\tLoss: 2.7076 Acc@1: 55.664%\n","| Epoch [258/1080] Iter[ 31/428]\t\tLoss: 2.8679 Acc@1: 54.435%\n","| Epoch [258/1080] Iter[ 46/428]\t\tLoss: 3.0414 Acc@1: 54.325%\n","\n","| Validation Epoch #258\t\t\tLoss: 0.1017 Acc@1: 65.08%\n","\n","=> Training Epoch #259, LR=0.0568\n","| Epoch [259/1080] Iter[  1/428]\t\tLoss: 2.9406 Acc@1: 50.000%\n","| Epoch [259/1080] Iter[ 16/428]\t\tLoss: 2.7609 Acc@1: 54.622%\n","| Epoch [259/1080] Iter[ 31/428]\t\tLoss: 2.8645 Acc@1: 53.999%\n","| Epoch [259/1080] Iter[ 46/428]\t\tLoss: 3.2320 Acc@1: 53.940%\n","\n","| Validation Epoch #259\t\t\tLoss: 0.0479 Acc@1: 63.36%\n","\n","=> Training Epoch #260, LR=0.0568\n","| Epoch [260/1080] Iter[  1/428]\t\tLoss: 2.6806 Acc@1: 64.583%\n","| Epoch [260/1080] Iter[ 16/428]\t\tLoss: 2.8308 Acc@1: 55.729%\n","| Epoch [260/1080] Iter[ 31/428]\t\tLoss: 2.6576 Acc@1: 53.696%\n","| Epoch [260/1080] Iter[ 46/428]\t\tLoss: 3.0444 Acc@1: 53.012%\n","\n","| Validation Epoch #260\t\t\tLoss: 0.5298 Acc@1: 61.60%\n","\n","=> Training Epoch #261, LR=0.0567\n","| Epoch [261/1080] Iter[  1/428]\t\tLoss: 2.9082 Acc@1: 51.042%\n","| Epoch [261/1080] Iter[ 16/428]\t\tLoss: 2.9930 Acc@1: 54.362%\n","| Epoch [261/1080] Iter[ 31/428]\t\tLoss: 2.9613 Acc@1: 54.335%\n","| Epoch [261/1080] Iter[ 46/428]\t\tLoss: 2.9142 Acc@1: 53.827%\n","\n","| Validation Epoch #261\t\t\tLoss: 0.9225 Acc@1: 48.00%\n","\n","=> Training Epoch #262, LR=0.0567\n","| Epoch [262/1080] Iter[  1/428]\t\tLoss: 2.9773 Acc@1: 48.958%\n","| Epoch [262/1080] Iter[ 16/428]\t\tLoss: 2.7708 Acc@1: 52.279%\n","| Epoch [262/1080] Iter[ 31/428]\t\tLoss: 2.9452 Acc@1: 53.024%\n","| Epoch [262/1080] Iter[ 46/428]\t\tLoss: 2.6063 Acc@1: 52.944%\n","\n","| Validation Epoch #262\t\t\tLoss: 0.0409 Acc@1: 63.32%\n","\n","=> Training Epoch #263, LR=0.0567\n","| Epoch [263/1080] Iter[  1/428]\t\tLoss: 3.2285 Acc@1: 50.000%\n","| Epoch [263/1080] Iter[ 16/428]\t\tLoss: 2.8412 Acc@1: 52.409%\n","| Epoch [263/1080] Iter[ 31/428]\t\tLoss: 2.8282 Acc@1: 53.159%\n","| Epoch [263/1080] Iter[ 46/428]\t\tLoss: 3.0846 Acc@1: 53.238%\n","\n","| Validation Epoch #263\t\t\tLoss: 0.0006 Acc@1: 59.94%\n","\n","=> Training Epoch #264, LR=0.0567\n","| Epoch [264/1080] Iter[  1/428]\t\tLoss: 2.9447 Acc@1: 59.375%\n","| Epoch [264/1080] Iter[ 16/428]\t\tLoss: 3.2132 Acc@1: 52.865%\n","| Epoch [264/1080] Iter[ 31/428]\t\tLoss: 2.8050 Acc@1: 53.024%\n","| Epoch [264/1080] Iter[ 46/428]\t\tLoss: 2.6566 Acc@1: 52.876%\n","\n","| Validation Epoch #264\t\t\tLoss: 0.8902 Acc@1: 58.88%\n","\n","=> Training Epoch #265, LR=0.0566\n","| Epoch [265/1080] Iter[  1/428]\t\tLoss: 3.1059 Acc@1: 46.875%\n","| Epoch [265/1080] Iter[ 16/428]\t\tLoss: 2.6528 Acc@1: 52.604%\n","| Epoch [265/1080] Iter[ 31/428]\t\tLoss: 2.8952 Acc@1: 53.159%\n","| Epoch [265/1080] Iter[ 46/428]\t\tLoss: 2.6917 Acc@1: 53.193%\n","\n","| Validation Epoch #265\t\t\tLoss: 0.0069 Acc@1: 65.34%\n","\n","=> Training Epoch #266, LR=0.0566\n","| Epoch [266/1080] Iter[  1/428]\t\tLoss: 2.6157 Acc@1: 61.458%\n","| Epoch [266/1080] Iter[ 16/428]\t\tLoss: 2.8533 Acc@1: 55.534%\n","| Epoch [266/1080] Iter[ 31/428]\t\tLoss: 2.9647 Acc@1: 55.208%\n","| Epoch [266/1080] Iter[ 46/428]\t\tLoss: 2.8799 Acc@1: 54.099%\n","\n","| Validation Epoch #266\t\t\tLoss: 0.4450 Acc@1: 64.38%\n","\n","=> Training Epoch #267, LR=0.0566\n","| Epoch [267/1080] Iter[  1/428]\t\tLoss: 2.8456 Acc@1: 53.125%\n","| Epoch [267/1080] Iter[ 16/428]\t\tLoss: 3.0573 Acc@1: 53.125%\n","| Epoch [267/1080] Iter[ 31/428]\t\tLoss: 3.1747 Acc@1: 52.823%\n","| Epoch [267/1080] Iter[ 46/428]\t\tLoss: 3.0922 Acc@1: 53.057%\n","\n","| Validation Epoch #267\t\t\tLoss: 0.0067 Acc@1: 60.48%\n","\n","=> Training Epoch #268, LR=0.0566\n","| Epoch [268/1080] Iter[  1/428]\t\tLoss: 2.9448 Acc@1: 47.917%\n","| Epoch [268/1080] Iter[ 16/428]\t\tLoss: 2.7526 Acc@1: 52.799%\n","| Epoch [268/1080] Iter[ 31/428]\t\tLoss: 2.8916 Acc@1: 53.595%\n","| Epoch [268/1080] Iter[ 46/428]\t\tLoss: 3.1985 Acc@1: 53.963%\n","\n","| Validation Epoch #268\t\t\tLoss: 0.1875 Acc@1: 63.90%\n","\n","=> Training Epoch #269, LR=0.0565\n","| Epoch [269/1080] Iter[  1/428]\t\tLoss: 3.2130 Acc@1: 45.833%\n","| Epoch [269/1080] Iter[ 16/428]\t\tLoss: 3.0695 Acc@1: 52.148%\n","| Epoch [269/1080] Iter[ 31/428]\t\tLoss: 3.0688 Acc@1: 53.931%\n","| Epoch [269/1080] Iter[ 46/428]\t\tLoss: 2.9491 Acc@1: 54.846%\n","\n","| Validation Epoch #269\t\t\tLoss: 0.0469 Acc@1: 56.38%\n","\n","=> Training Epoch #270, LR=0.0565\n","| Epoch [270/1080] Iter[  1/428]\t\tLoss: 3.4813 Acc@1: 39.583%\n","| Epoch [270/1080] Iter[ 16/428]\t\tLoss: 2.8625 Acc@1: 53.385%\n","| Epoch [270/1080] Iter[ 31/428]\t\tLoss: 2.7641 Acc@1: 53.125%\n","| Epoch [270/1080] Iter[ 46/428]\t\tLoss: 2.8896 Acc@1: 53.736%\n","\n","| Validation Epoch #270\t\t\tLoss: 0.0003 Acc@1: 62.78%\n","\n","=> Training Epoch #271, LR=0.0565\n","| Epoch [271/1080] Iter[  1/428]\t\tLoss: 2.8635 Acc@1: 50.000%\n","| Epoch [271/1080] Iter[ 16/428]\t\tLoss: 2.9185 Acc@1: 54.427%\n","| Epoch [271/1080] Iter[ 31/428]\t\tLoss: 2.5689 Acc@1: 53.696%\n","| Epoch [271/1080] Iter[ 46/428]\t\tLoss: 2.8755 Acc@1: 53.646%\n","\n","| Validation Epoch #271\t\t\tLoss: 0.0230 Acc@1: 59.18%\n","\n","=> Training Epoch #272, LR=0.0565\n","| Epoch [272/1080] Iter[  1/428]\t\tLoss: 2.9069 Acc@1: 54.167%\n","| Epoch [272/1080] Iter[ 16/428]\t\tLoss: 2.6916 Acc@1: 55.013%\n","| Epoch [272/1080] Iter[ 31/428]\t\tLoss: 2.9828 Acc@1: 54.099%\n","| Epoch [272/1080] Iter[ 46/428]\t\tLoss: 2.9517 Acc@1: 53.578%\n","\n","| Validation Epoch #272\t\t\tLoss: 0.1849 Acc@1: 60.40%\n","\n","=> Training Epoch #273, LR=0.0564\n","| Epoch [273/1080] Iter[  1/428]\t\tLoss: 2.8317 Acc@1: 54.167%\n","| Epoch [273/1080] Iter[ 16/428]\t\tLoss: 2.7556 Acc@1: 54.167%\n","| Epoch [273/1080] Iter[ 31/428]\t\tLoss: 3.0360 Acc@1: 53.931%\n","| Epoch [273/1080] Iter[ 46/428]\t\tLoss: 2.9033 Acc@1: 53.623%\n","\n","| Validation Epoch #273\t\t\tLoss: 0.0331 Acc@1: 60.74%\n","\n","=> Training Epoch #274, LR=0.0564\n","| Epoch [274/1080] Iter[  1/428]\t\tLoss: 2.6433 Acc@1: 56.250%\n","| Epoch [274/1080] Iter[ 16/428]\t\tLoss: 3.1641 Acc@1: 52.148%\n","| Epoch [274/1080] Iter[ 31/428]\t\tLoss: 3.0365 Acc@1: 52.520%\n","| Epoch [274/1080] Iter[ 46/428]\t\tLoss: 2.7522 Acc@1: 53.306%\n","\n","| Validation Epoch #274\t\t\tLoss: 0.0005 Acc@1: 53.66%\n","\n","=> Training Epoch #275, LR=0.0564\n","| Epoch [275/1080] Iter[  1/428]\t\tLoss: 2.6652 Acc@1: 59.375%\n","| Epoch [275/1080] Iter[ 16/428]\t\tLoss: 3.1323 Acc@1: 52.539%\n","| Epoch [275/1080] Iter[ 31/428]\t\tLoss: 3.2365 Acc@1: 53.360%\n","| Epoch [275/1080] Iter[ 46/428]\t\tLoss: 3.0519 Acc@1: 53.804%\n","\n","| Validation Epoch #275\t\t\tLoss: 0.0002 Acc@1: 62.00%\n","\n","=> Training Epoch #276, LR=0.0564\n","| Epoch [276/1080] Iter[  1/428]\t\tLoss: 2.7120 Acc@1: 59.375%\n","| Epoch [276/1080] Iter[ 16/428]\t\tLoss: 2.8713 Acc@1: 53.776%\n","| Epoch [276/1080] Iter[ 31/428]\t\tLoss: 2.6361 Acc@1: 53.898%\n","| Epoch [276/1080] Iter[ 46/428]\t\tLoss: 2.7673 Acc@1: 53.963%\n","\n","| Validation Epoch #276\t\t\tLoss: 0.0902 Acc@1: 64.98%\n","\n","=> Training Epoch #277, LR=0.0563\n","| Epoch [277/1080] Iter[  1/428]\t\tLoss: 2.9098 Acc@1: 53.125%\n","| Epoch [277/1080] Iter[ 16/428]\t\tLoss: 2.7885 Acc@1: 54.036%\n","| Epoch [277/1080] Iter[ 31/428]\t\tLoss: 2.9658 Acc@1: 54.133%\n","| Epoch [277/1080] Iter[ 46/428]\t\tLoss: 2.6492 Acc@1: 53.918%\n","\n","| Validation Epoch #277\t\t\tLoss: 0.2227 Acc@1: 67.14%\n","\n","=> Training Epoch #278, LR=0.0563\n","| Epoch [278/1080] Iter[  1/428]\t\tLoss: 2.9892 Acc@1: 53.125%\n","| Epoch [278/1080] Iter[ 16/428]\t\tLoss: 3.0956 Acc@1: 53.841%\n","| Epoch [278/1080] Iter[ 31/428]\t\tLoss: 2.6482 Acc@1: 53.797%\n","| Epoch [278/1080] Iter[ 46/428]\t\tLoss: 2.8379 Acc@1: 53.714%\n","\n","| Validation Epoch #278\t\t\tLoss: 0.9617 Acc@1: 62.76%\n","\n","=> Training Epoch #279, LR=0.0563\n","| Epoch [279/1080] Iter[  1/428]\t\tLoss: 2.6751 Acc@1: 59.375%\n","| Epoch [279/1080] Iter[ 16/428]\t\tLoss: 2.7948 Acc@1: 54.427%\n","| Epoch [279/1080] Iter[ 31/428]\t\tLoss: 3.0568 Acc@1: 53.730%\n","| Epoch [279/1080] Iter[ 46/428]\t\tLoss: 2.9013 Acc@1: 53.510%\n","\n","| Validation Epoch #279\t\t\tLoss: 1.1088 Acc@1: 58.98%\n","\n","=> Training Epoch #280, LR=0.0563\n","| Epoch [280/1080] Iter[  1/428]\t\tLoss: 2.9090 Acc@1: 51.042%\n","| Epoch [280/1080] Iter[ 16/428]\t\tLoss: 3.1444 Acc@1: 54.362%\n","| Epoch [280/1080] Iter[ 31/428]\t\tLoss: 2.8743 Acc@1: 53.898%\n","| Epoch [280/1080] Iter[ 46/428]\t\tLoss: 3.0168 Acc@1: 53.510%\n","\n","| Validation Epoch #280\t\t\tLoss: 0.0929 Acc@1: 61.84%\n","\n","=> Training Epoch #281, LR=0.0562\n","| Epoch [281/1080] Iter[  1/428]\t\tLoss: 2.7593 Acc@1: 59.375%\n","| Epoch [281/1080] Iter[ 16/428]\t\tLoss: 2.9278 Acc@1: 55.534%\n","| Epoch [281/1080] Iter[ 31/428]\t\tLoss: 3.0947 Acc@1: 54.267%\n","| Epoch [281/1080] Iter[ 46/428]\t\tLoss: 3.1138 Acc@1: 54.370%\n","\n","| Validation Epoch #281\t\t\tLoss: 0.9657 Acc@1: 61.36%\n","\n","=> Training Epoch #282, LR=0.0562\n","| Epoch [282/1080] Iter[  1/428]\t\tLoss: 2.9382 Acc@1: 56.250%\n","| Epoch [282/1080] Iter[ 16/428]\t\tLoss: 2.7990 Acc@1: 53.255%\n","| Epoch [282/1080] Iter[ 31/428]\t\tLoss: 3.0063 Acc@1: 53.797%\n","| Epoch [282/1080] Iter[ 46/428]\t\tLoss: 2.8017 Acc@1: 53.963%\n","\n","| Validation Epoch #282\t\t\tLoss: 0.3503 Acc@1: 60.68%\n","\n","=> Training Epoch #283, LR=0.0562\n","| Epoch [283/1080] Iter[  1/428]\t\tLoss: 2.7296 Acc@1: 58.333%\n","| Epoch [283/1080] Iter[ 16/428]\t\tLoss: 2.7393 Acc@1: 53.516%\n","| Epoch [283/1080] Iter[ 31/428]\t\tLoss: 2.6995 Acc@1: 53.898%\n","| Epoch [283/1080] Iter[ 46/428]\t\tLoss: 2.7471 Acc@1: 54.370%\n","\n","| Validation Epoch #283\t\t\tLoss: 0.0038 Acc@1: 61.88%\n","\n","=> Training Epoch #284, LR=0.0562\n","| Epoch [284/1080] Iter[  1/428]\t\tLoss: 2.8233 Acc@1: 54.167%\n","| Epoch [284/1080] Iter[ 16/428]\t\tLoss: 2.8282 Acc@1: 53.906%\n","| Epoch [284/1080] Iter[ 31/428]\t\tLoss: 3.0140 Acc@1: 52.520%\n","| Epoch [284/1080] Iter[ 46/428]\t\tLoss: 3.0155 Acc@1: 53.012%\n","\n","| Validation Epoch #284\t\t\tLoss: 0.0666 Acc@1: 65.28%\n","\n","=> Training Epoch #285, LR=0.0561\n","| Epoch [285/1080] Iter[  1/428]\t\tLoss: 2.7975 Acc@1: 59.375%\n","| Epoch [285/1080] Iter[ 16/428]\t\tLoss: 2.9189 Acc@1: 55.664%\n","| Epoch [285/1080] Iter[ 31/428]\t\tLoss: 2.8029 Acc@1: 55.040%\n","| Epoch [285/1080] Iter[ 46/428]\t\tLoss: 2.8278 Acc@1: 54.755%\n","\n","| Validation Epoch #285\t\t\tLoss: 0.0738 Acc@1: 63.86%\n","\n","=> Training Epoch #286, LR=0.0561\n","| Epoch [286/1080] Iter[  1/428]\t\tLoss: 2.6191 Acc@1: 58.333%\n","| Epoch [286/1080] Iter[ 16/428]\t\tLoss: 2.7882 Acc@1: 53.385%\n","| Epoch [286/1080] Iter[ 31/428]\t\tLoss: 3.2132 Acc@1: 53.125%\n","| Epoch [286/1080] Iter[ 46/428]\t\tLoss: 2.4970 Acc@1: 53.533%\n","\n","| Validation Epoch #286\t\t\tLoss: 0.0007 Acc@1: 62.40%\n","\n","=> Training Epoch #287, LR=0.0561\n","| Epoch [287/1080] Iter[  1/428]\t\tLoss: 3.0043 Acc@1: 47.917%\n","| Epoch [287/1080] Iter[ 16/428]\t\tLoss: 2.9607 Acc@1: 53.841%\n","| Epoch [287/1080] Iter[ 31/428]\t\tLoss: 2.6000 Acc@1: 54.066%\n","| Epoch [287/1080] Iter[ 46/428]\t\tLoss: 2.8871 Acc@1: 53.306%\n","\n","| Validation Epoch #287\t\t\tLoss: 0.0132 Acc@1: 64.82%\n","\n","=> Training Epoch #288, LR=0.0560\n","| Epoch [288/1080] Iter[  1/428]\t\tLoss: 2.9415 Acc@1: 52.083%\n","| Epoch [288/1080] Iter[ 16/428]\t\tLoss: 2.9972 Acc@1: 54.753%\n","| Epoch [288/1080] Iter[ 31/428]\t\tLoss: 2.8418 Acc@1: 54.402%\n","| Epoch [288/1080] Iter[ 46/428]\t\tLoss: 2.7845 Acc@1: 54.303%\n","\n","| Validation Epoch #288\t\t\tLoss: 0.6342 Acc@1: 55.00%\n","\n","=> Training Epoch #289, LR=0.0560\n","| Epoch [289/1080] Iter[  1/428]\t\tLoss: 2.8247 Acc@1: 52.083%\n","| Epoch [289/1080] Iter[ 16/428]\t\tLoss: 3.0280 Acc@1: 52.344%\n","| Epoch [289/1080] Iter[ 31/428]\t\tLoss: 2.4994 Acc@1: 52.823%\n","| Epoch [289/1080] Iter[ 46/428]\t\tLoss: 2.8520 Acc@1: 52.740%\n","\n","| Validation Epoch #289\t\t\tLoss: 0.3837 Acc@1: 62.04%\n","\n","=> Training Epoch #290, LR=0.0560\n","| Epoch [290/1080] Iter[  1/428]\t\tLoss: 2.7687 Acc@1: 59.375%\n","| Epoch [290/1080] Iter[ 16/428]\t\tLoss: 3.0015 Acc@1: 56.576%\n","| Epoch [290/1080] Iter[ 31/428]\t\tLoss: 3.0936 Acc@1: 55.444%\n","| Epoch [290/1080] Iter[ 46/428]\t\tLoss: 3.2425 Acc@1: 54.461%\n","\n","| Validation Epoch #290\t\t\tLoss: 0.4253 Acc@1: 59.94%\n","\n","=> Training Epoch #291, LR=0.0560\n","| Epoch [291/1080] Iter[  1/428]\t\tLoss: 2.6898 Acc@1: 54.167%\n","| Epoch [291/1080] Iter[ 16/428]\t\tLoss: 2.9315 Acc@1: 52.799%\n","| Epoch [291/1080] Iter[ 31/428]\t\tLoss: 2.8186 Acc@1: 52.991%\n","| Epoch [291/1080] Iter[ 46/428]\t\tLoss: 2.7990 Acc@1: 52.604%\n","\n","| Validation Epoch #291\t\t\tLoss: 0.0493 Acc@1: 60.32%\n","\n","=> Training Epoch #292, LR=0.0559\n","| Epoch [292/1080] Iter[  1/428]\t\tLoss: 3.0298 Acc@1: 54.167%\n","| Epoch [292/1080] Iter[ 16/428]\t\tLoss: 2.8826 Acc@1: 55.339%\n","| Epoch [292/1080] Iter[ 31/428]\t\tLoss: 2.6961 Acc@1: 54.872%\n","| Epoch [292/1080] Iter[ 46/428]\t\tLoss: 2.8577 Acc@1: 54.257%\n","\n","| Validation Epoch #292\t\t\tLoss: 0.0279 Acc@1: 59.58%\n","\n","=> Training Epoch #293, LR=0.0559\n","| Epoch [293/1080] Iter[  1/428]\t\tLoss: 2.7765 Acc@1: 54.167%\n","| Epoch [293/1080] Iter[ 16/428]\t\tLoss: 3.0498 Acc@1: 54.232%\n","| Epoch [293/1080] Iter[ 31/428]\t\tLoss: 2.8387 Acc@1: 54.603%\n","| Epoch [293/1080] Iter[ 46/428]\t\tLoss: 2.8873 Acc@1: 54.620%\n","\n","| Validation Epoch #293\t\t\tLoss: 0.0471 Acc@1: 66.96%\n","\n","=> Training Epoch #294, LR=0.0559\n","| Epoch [294/1080] Iter[  1/428]\t\tLoss: 3.0508 Acc@1: 50.000%\n","| Epoch [294/1080] Iter[ 16/428]\t\tLoss: 3.2027 Acc@1: 52.930%\n","| Epoch [294/1080] Iter[ 31/428]\t\tLoss: 2.6952 Acc@1: 54.335%\n","| Epoch [294/1080] Iter[ 46/428]\t\tLoss: 3.0271 Acc@1: 54.733%\n","\n","| Validation Epoch #294\t\t\tLoss: 0.0613 Acc@1: 66.22%\n","\n","=> Training Epoch #295, LR=0.0558\n","| Epoch [295/1080] Iter[  1/428]\t\tLoss: 2.4310 Acc@1: 62.500%\n","| Epoch [295/1080] Iter[ 16/428]\t\tLoss: 2.7197 Acc@1: 54.818%\n","| Epoch [295/1080] Iter[ 31/428]\t\tLoss: 2.6559 Acc@1: 54.906%\n","| Epoch [295/1080] Iter[ 46/428]\t\tLoss: 2.8306 Acc@1: 54.189%\n","\n","| Validation Epoch #295\t\t\tLoss: 0.0177 Acc@1: 57.06%\n","\n","=> Training Epoch #296, LR=0.0558\n","| Epoch [296/1080] Iter[  1/428]\t\tLoss: 2.8105 Acc@1: 56.250%\n","| Epoch [296/1080] Iter[ 16/428]\t\tLoss: 2.7979 Acc@1: 52.083%\n","| Epoch [296/1080] Iter[ 31/428]\t\tLoss: 2.8384 Acc@1: 54.167%\n","| Epoch [296/1080] Iter[ 46/428]\t\tLoss: 2.7969 Acc@1: 54.484%\n","\n","| Validation Epoch #296\t\t\tLoss: 0.6285 Acc@1: 60.96%\n","\n","=> Training Epoch #297, LR=0.0558\n","| Epoch [297/1080] Iter[  1/428]\t\tLoss: 2.8433 Acc@1: 58.333%\n","| Epoch [297/1080] Iter[ 16/428]\t\tLoss: 2.4168 Acc@1: 56.055%\n","| Epoch [297/1080] Iter[ 31/428]\t\tLoss: 2.7542 Acc@1: 55.813%\n","| Epoch [297/1080] Iter[ 46/428]\t\tLoss: 2.7777 Acc@1: 54.280%\n","\n","| Validation Epoch #297\t\t\tLoss: 0.0776 Acc@1: 57.82%\n","\n","=> Training Epoch #298, LR=0.0558\n","| Epoch [298/1080] Iter[  1/428]\t\tLoss: 3.0164 Acc@1: 54.167%\n","| Epoch [298/1080] Iter[ 16/428]\t\tLoss: 2.8562 Acc@1: 53.516%\n","| Epoch [298/1080] Iter[ 31/428]\t\tLoss: 2.8075 Acc@1: 53.999%\n","| Epoch [298/1080] Iter[ 46/428]\t\tLoss: 2.8998 Acc@1: 53.827%\n","\n","| Validation Epoch #298\t\t\tLoss: 0.7174 Acc@1: 53.68%\n","\n","=> Training Epoch #299, LR=0.0557\n","| Epoch [299/1080] Iter[  1/428]\t\tLoss: 3.3046 Acc@1: 44.792%\n","| Epoch [299/1080] Iter[ 16/428]\t\tLoss: 2.8458 Acc@1: 55.469%\n","| Epoch [299/1080] Iter[ 31/428]\t\tLoss: 2.4313 Acc@1: 54.301%\n","| Epoch [299/1080] Iter[ 46/428]\t\tLoss: 2.7833 Acc@1: 53.827%\n","\n","| Validation Epoch #299\t\t\tLoss: 0.6254 Acc@1: 62.22%\n","\n","=> Training Epoch #300, LR=0.0557\n","| Epoch [300/1080] Iter[  1/428]\t\tLoss: 2.5572 Acc@1: 62.500%\n","| Epoch [300/1080] Iter[ 16/428]\t\tLoss: 3.1434 Acc@1: 54.297%\n","| Epoch [300/1080] Iter[ 31/428]\t\tLoss: 2.8531 Acc@1: 54.133%\n","| Epoch [300/1080] Iter[ 46/428]\t\tLoss: 2.7850 Acc@1: 53.963%\n","\n","| Validation Epoch #300\t\t\tLoss: 0.1763 Acc@1: 57.40%\n","\n","=> Training Epoch #301, LR=0.0557\n","| Epoch [301/1080] Iter[  1/428]\t\tLoss: 3.2207 Acc@1: 45.833%\n","| Epoch [301/1080] Iter[ 16/428]\t\tLoss: 2.6102 Acc@1: 55.729%\n","| Epoch [301/1080] Iter[ 31/428]\t\tLoss: 3.0161 Acc@1: 54.032%\n","| Epoch [301/1080] Iter[ 46/428]\t\tLoss: 2.8317 Acc@1: 53.986%\n","\n","| Validation Epoch #301\t\t\tLoss: 0.2905 Acc@1: 63.12%\n","\n","=> Training Epoch #302, LR=0.0557\n","| Epoch [302/1080] Iter[  1/428]\t\tLoss: 2.7948 Acc@1: 52.083%\n","| Epoch [302/1080] Iter[ 16/428]\t\tLoss: 2.6570 Acc@1: 53.581%\n","| Epoch [302/1080] Iter[ 31/428]\t\tLoss: 2.9111 Acc@1: 53.931%\n","| Epoch [302/1080] Iter[ 46/428]\t\tLoss: 2.6756 Acc@1: 53.487%\n","\n","| Validation Epoch #302\t\t\tLoss: 0.3288 Acc@1: 56.46%\n","\n","=> Training Epoch #303, LR=0.0556\n","| Epoch [303/1080] Iter[  1/428]\t\tLoss: 3.3287 Acc@1: 42.708%\n","| Epoch [303/1080] Iter[ 16/428]\t\tLoss: 2.8624 Acc@1: 52.474%\n","| Epoch [303/1080] Iter[ 31/428]\t\tLoss: 2.8968 Acc@1: 53.259%\n","| Epoch [303/1080] Iter[ 46/428]\t\tLoss: 3.0515 Acc@1: 53.193%\n","\n","| Validation Epoch #303\t\t\tLoss: 0.4440 Acc@1: 63.82%\n","\n","=> Training Epoch #304, LR=0.0556\n","| Epoch [304/1080] Iter[  1/428]\t\tLoss: 2.9763 Acc@1: 56.250%\n","| Epoch [304/1080] Iter[ 16/428]\t\tLoss: 2.9903 Acc@1: 53.451%\n","| Epoch [304/1080] Iter[ 31/428]\t\tLoss: 2.8925 Acc@1: 54.099%\n","| Epoch [304/1080] Iter[ 46/428]\t\tLoss: 2.9305 Acc@1: 54.235%\n","\n","| Validation Epoch #304\t\t\tLoss: 0.0633 Acc@1: 61.34%\n","\n","=> Training Epoch #305, LR=0.0556\n","| Epoch [305/1080] Iter[  1/428]\t\tLoss: 2.9471 Acc@1: 47.917%\n","| Epoch [305/1080] Iter[ 16/428]\t\tLoss: 2.8884 Acc@1: 55.664%\n","| Epoch [305/1080] Iter[ 31/428]\t\tLoss: 2.9739 Acc@1: 55.343%\n","| Epoch [305/1080] Iter[ 46/428]\t\tLoss: 2.9015 Acc@1: 54.167%\n","\n","| Validation Epoch #305\t\t\tLoss: 0.3037 Acc@1: 59.26%\n","\n","=> Training Epoch #306, LR=0.0555\n","| Epoch [306/1080] Iter[  1/428]\t\tLoss: 2.8079 Acc@1: 57.292%\n","| Epoch [306/1080] Iter[ 16/428]\t\tLoss: 2.8959 Acc@1: 55.469%\n","| Epoch [306/1080] Iter[ 31/428]\t\tLoss: 3.0995 Acc@1: 55.477%\n","| Epoch [306/1080] Iter[ 46/428]\t\tLoss: 3.4885 Acc@1: 54.620%\n","\n","| Validation Epoch #306\t\t\tLoss: 0.3482 Acc@1: 63.90%\n","\n","=> Training Epoch #307, LR=0.0555\n","| Epoch [307/1080] Iter[  1/428]\t\tLoss: 2.9226 Acc@1: 55.208%\n","| Epoch [307/1080] Iter[ 16/428]\t\tLoss: 3.1539 Acc@1: 53.125%\n","| Epoch [307/1080] Iter[ 31/428]\t\tLoss: 2.8337 Acc@1: 53.864%\n","| Epoch [307/1080] Iter[ 46/428]\t\tLoss: 2.7887 Acc@1: 53.193%\n","\n","| Validation Epoch #307\t\t\tLoss: 0.0525 Acc@1: 55.92%\n","\n","=> Training Epoch #308, LR=0.0555\n","| Epoch [308/1080] Iter[  1/428]\t\tLoss: 3.1391 Acc@1: 43.750%\n","| Epoch [308/1080] Iter[ 16/428]\t\tLoss: 2.9599 Acc@1: 52.995%\n","| Epoch [308/1080] Iter[ 31/428]\t\tLoss: 2.8782 Acc@1: 54.032%\n","| Epoch [308/1080] Iter[ 46/428]\t\tLoss: 2.9995 Acc@1: 53.895%\n","\n","| Validation Epoch #308\t\t\tLoss: 0.3136 Acc@1: 60.28%\n","\n","=> Training Epoch #309, LR=0.0554\n","| Epoch [309/1080] Iter[  1/428]\t\tLoss: 2.7961 Acc@1: 56.250%\n","| Epoch [309/1080] Iter[ 16/428]\t\tLoss: 3.0704 Acc@1: 55.013%\n","| Epoch [309/1080] Iter[ 31/428]\t\tLoss: 2.9194 Acc@1: 53.931%\n","| Epoch [309/1080] Iter[ 46/428]\t\tLoss: 2.7529 Acc@1: 54.348%\n","\n","| Validation Epoch #309\t\t\tLoss: 0.2570 Acc@1: 61.72%\n","\n","=> Training Epoch #310, LR=0.0554\n","| Epoch [310/1080] Iter[  1/428]\t\tLoss: 2.9953 Acc@1: 47.917%\n","| Epoch [310/1080] Iter[ 16/428]\t\tLoss: 2.9164 Acc@1: 54.622%\n","| Epoch [310/1080] Iter[ 31/428]\t\tLoss: 3.2349 Acc@1: 53.528%\n","| Epoch [310/1080] Iter[ 46/428]\t\tLoss: 2.7978 Acc@1: 53.057%\n","\n","| Validation Epoch #310\t\t\tLoss: 0.5811 Acc@1: 64.50%\n","\n","=> Training Epoch #311, LR=0.0554\n","| Epoch [311/1080] Iter[  1/428]\t\tLoss: 2.7479 Acc@1: 59.375%\n","| Epoch [311/1080] Iter[ 16/428]\t\tLoss: 3.3364 Acc@1: 52.214%\n","| Epoch [311/1080] Iter[ 31/428]\t\tLoss: 2.7214 Acc@1: 52.755%\n","| Epoch [311/1080] Iter[ 46/428]\t\tLoss: 2.8794 Acc@1: 53.057%\n","\n","| Validation Epoch #311\t\t\tLoss: 0.2366 Acc@1: 53.68%\n","\n","=> Training Epoch #312, LR=0.0554\n","| Epoch [312/1080] Iter[  1/428]\t\tLoss: 2.8862 Acc@1: 53.125%\n","| Epoch [312/1080] Iter[ 16/428]\t\tLoss: 3.0145 Acc@1: 54.297%\n","| Epoch [312/1080] Iter[ 31/428]\t\tLoss: 2.8362 Acc@1: 54.234%\n","| Epoch [312/1080] Iter[ 46/428]\t\tLoss: 2.7837 Acc@1: 53.940%\n","\n","| Validation Epoch #312\t\t\tLoss: 0.0936 Acc@1: 66.80%\n","\n","=> Training Epoch #313, LR=0.0553\n","| Epoch [313/1080] Iter[  1/428]\t\tLoss: 2.8478 Acc@1: 51.042%\n","| Epoch [313/1080] Iter[ 16/428]\t\tLoss: 3.0569 Acc@1: 54.297%\n","| Epoch [313/1080] Iter[ 31/428]\t\tLoss: 2.9136 Acc@1: 54.301%\n","| Epoch [313/1080] Iter[ 46/428]\t\tLoss: 3.0508 Acc@1: 54.167%\n","\n","| Validation Epoch #313\t\t\tLoss: 0.2797 Acc@1: 65.08%\n","\n","=> Training Epoch #314, LR=0.0553\n","| Epoch [314/1080] Iter[  1/428]\t\tLoss: 2.8346 Acc@1: 54.167%\n","| Epoch [314/1080] Iter[ 16/428]\t\tLoss: 3.0308 Acc@1: 55.078%\n","| Epoch [314/1080] Iter[ 31/428]\t\tLoss: 2.8747 Acc@1: 54.503%\n","| Epoch [314/1080] Iter[ 46/428]\t\tLoss: 3.0440 Acc@1: 53.963%\n","\n","| Validation Epoch #314\t\t\tLoss: 0.0043 Acc@1: 62.34%\n","\n","=> Training Epoch #315, LR=0.0553\n","| Epoch [315/1080] Iter[  1/428]\t\tLoss: 2.7568 Acc@1: 58.333%\n","| Epoch [315/1080] Iter[ 16/428]\t\tLoss: 3.1635 Acc@1: 54.427%\n","| Epoch [315/1080] Iter[ 31/428]\t\tLoss: 2.5984 Acc@1: 54.234%\n","| Epoch [315/1080] Iter[ 46/428]\t\tLoss: 2.8669 Acc@1: 53.940%\n","\n","| Validation Epoch #315\t\t\tLoss: 0.7596 Acc@1: 56.66%\n","\n","=> Training Epoch #316, LR=0.0552\n","| Epoch [316/1080] Iter[  1/428]\t\tLoss: 2.6663 Acc@1: 58.333%\n","| Epoch [316/1080] Iter[ 16/428]\t\tLoss: 2.6437 Acc@1: 54.557%\n","| Epoch [316/1080] Iter[ 31/428]\t\tLoss: 2.8133 Acc@1: 54.469%\n","| Epoch [316/1080] Iter[ 46/428]\t\tLoss: 2.9722 Acc@1: 54.438%\n","\n","| Validation Epoch #316\t\t\tLoss: 0.0270 Acc@1: 63.42%\n","\n","=> Training Epoch #317, LR=0.0552\n","| Epoch [317/1080] Iter[  1/428]\t\tLoss: 2.5329 Acc@1: 59.375%\n","| Epoch [317/1080] Iter[ 16/428]\t\tLoss: 3.2116 Acc@1: 53.711%\n","| Epoch [317/1080] Iter[ 31/428]\t\tLoss: 3.2419 Acc@1: 53.663%\n","| Epoch [317/1080] Iter[ 46/428]\t\tLoss: 2.8672 Acc@1: 53.578%\n","\n","| Validation Epoch #317\t\t\tLoss: 0.4254 Acc@1: 58.30%\n","\n","=> Training Epoch #318, LR=0.0552\n","| Epoch [318/1080] Iter[  1/428]\t\tLoss: 2.6067 Acc@1: 61.458%\n","| Epoch [318/1080] Iter[ 16/428]\t\tLoss: 3.0229 Acc@1: 54.753%\n","| Epoch [318/1080] Iter[ 31/428]\t\tLoss: 2.7054 Acc@1: 54.772%\n","| Epoch [318/1080] Iter[ 46/428]\t\tLoss: 2.9408 Acc@1: 53.736%\n","\n","| Validation Epoch #318\t\t\tLoss: 0.3132 Acc@1: 58.02%\n","\n","=> Training Epoch #319, LR=0.0552\n","| Epoch [319/1080] Iter[  1/428]\t\tLoss: 2.9493 Acc@1: 48.958%\n","| Epoch [319/1080] Iter[ 16/428]\t\tLoss: 2.7980 Acc@1: 54.883%\n","| Epoch [319/1080] Iter[ 31/428]\t\tLoss: 3.0159 Acc@1: 53.495%\n","| Epoch [319/1080] Iter[ 46/428]\t\tLoss: 2.9864 Acc@1: 53.261%\n","\n","| Validation Epoch #319\t\t\tLoss: 0.3399 Acc@1: 59.24%\n","\n","=> Training Epoch #320, LR=0.0551\n","| Epoch [320/1080] Iter[  1/428]\t\tLoss: 2.7625 Acc@1: 57.292%\n","| Epoch [320/1080] Iter[ 16/428]\t\tLoss: 2.9562 Acc@1: 54.883%\n","| Epoch [320/1080] Iter[ 31/428]\t\tLoss: 3.0356 Acc@1: 54.570%\n","| Epoch [320/1080] Iter[ 46/428]\t\tLoss: 2.7060 Acc@1: 54.484%\n","\n","| Validation Epoch #320\t\t\tLoss: 1.5174 Acc@1: 62.36%\n","\n","=> Training Epoch #321, LR=0.0551\n","| Epoch [321/1080] Iter[  1/428]\t\tLoss: 2.8194 Acc@1: 53.125%\n","| Epoch [321/1080] Iter[ 16/428]\t\tLoss: 2.8602 Acc@1: 54.622%\n","| Epoch [321/1080] Iter[ 31/428]\t\tLoss: 2.9889 Acc@1: 54.099%\n","| Epoch [321/1080] Iter[ 46/428]\t\tLoss: 2.9574 Acc@1: 53.850%\n","\n","| Validation Epoch #321\t\t\tLoss: 0.3154 Acc@1: 64.92%\n","\n","=> Training Epoch #322, LR=0.0551\n","| Epoch [322/1080] Iter[  1/428]\t\tLoss: 2.7495 Acc@1: 56.250%\n","| Epoch [322/1080] Iter[ 16/428]\t\tLoss: 3.0785 Acc@1: 54.427%\n","| Epoch [322/1080] Iter[ 31/428]\t\tLoss: 3.0134 Acc@1: 54.234%\n","| Epoch [322/1080] Iter[ 46/428]\t\tLoss: 3.0156 Acc@1: 54.076%\n","\n","| Validation Epoch #322\t\t\tLoss: 1.3196 Acc@1: 62.72%\n","\n","=> Training Epoch #323, LR=0.0550\n","| Epoch [323/1080] Iter[  1/428]\t\tLoss: 2.7723 Acc@1: 56.250%\n","| Epoch [323/1080] Iter[ 16/428]\t\tLoss: 2.8887 Acc@1: 55.143%\n","| Epoch [323/1080] Iter[ 31/428]\t\tLoss: 3.0059 Acc@1: 54.704%\n","| Epoch [323/1080] Iter[ 46/428]\t\tLoss: 2.7602 Acc@1: 54.620%\n","\n","| Validation Epoch #323\t\t\tLoss: 0.0484 Acc@1: 58.10%\n","\n","=> Training Epoch #324, LR=0.0550\n","| Epoch [324/1080] Iter[  1/428]\t\tLoss: 3.1816 Acc@1: 50.000%\n","| Epoch [324/1080] Iter[ 16/428]\t\tLoss: 2.8892 Acc@1: 53.906%\n","| Epoch [324/1080] Iter[ 31/428]\t\tLoss: 3.0529 Acc@1: 54.167%\n","| Epoch [324/1080] Iter[ 46/428]\t\tLoss: 2.8850 Acc@1: 53.351%\n","\n","| Validation Epoch #324\t\t\tLoss: 0.0209 Acc@1: 61.68%\n","\n","=> Training Epoch #325, LR=0.0550\n","| Epoch [325/1080] Iter[  1/428]\t\tLoss: 2.9132 Acc@1: 56.250%\n","| Epoch [325/1080] Iter[ 16/428]\t\tLoss: 2.9182 Acc@1: 54.167%\n","| Epoch [325/1080] Iter[ 31/428]\t\tLoss: 3.1472 Acc@1: 53.562%\n","| Epoch [325/1080] Iter[ 46/428]\t\tLoss: 2.7303 Acc@1: 54.461%\n","\n","| Validation Epoch #325\t\t\tLoss: 0.7296 Acc@1: 61.58%\n","\n","=> Training Epoch #326, LR=0.0549\n","| Epoch [326/1080] Iter[  1/428]\t\tLoss: 2.8700 Acc@1: 50.000%\n","| Epoch [326/1080] Iter[ 16/428]\t\tLoss: 2.9108 Acc@1: 54.036%\n","| Epoch [326/1080] Iter[ 31/428]\t\tLoss: 2.9189 Acc@1: 53.864%\n","| Epoch [326/1080] Iter[ 46/428]\t\tLoss: 2.7664 Acc@1: 54.303%\n","\n","| Validation Epoch #326\t\t\tLoss: 0.1956 Acc@1: 58.92%\n","\n","=> Training Epoch #327, LR=0.0549\n","| Epoch [327/1080] Iter[  1/428]\t\tLoss: 2.7463 Acc@1: 56.250%\n","| Epoch [327/1080] Iter[ 16/428]\t\tLoss: 3.0255 Acc@1: 55.273%\n","| Epoch [327/1080] Iter[ 31/428]\t\tLoss: 2.6256 Acc@1: 54.839%\n","| Epoch [327/1080] Iter[ 46/428]\t\tLoss: 2.7350 Acc@1: 54.099%\n","\n","| Validation Epoch #327\t\t\tLoss: 0.7345 Acc@1: 63.52%\n","\n","=> Training Epoch #328, LR=0.0549\n","| Epoch [328/1080] Iter[  1/428]\t\tLoss: 2.6285 Acc@1: 60.417%\n","| Epoch [328/1080] Iter[ 16/428]\t\tLoss: 2.8959 Acc@1: 54.753%\n","| Epoch [328/1080] Iter[ 31/428]\t\tLoss: 2.6459 Acc@1: 54.402%\n","| Epoch [328/1080] Iter[ 46/428]\t\tLoss: 3.1112 Acc@1: 53.601%\n","\n","| Validation Epoch #328\t\t\tLoss: 0.2348 Acc@1: 60.50%\n","\n","=> Training Epoch #329, LR=0.0548\n","| Epoch [329/1080] Iter[  1/428]\t\tLoss: 2.6787 Acc@1: 56.250%\n","| Epoch [329/1080] Iter[ 16/428]\t\tLoss: 2.6585 Acc@1: 51.953%\n","| Epoch [329/1080] Iter[ 31/428]\t\tLoss: 3.0694 Acc@1: 52.487%\n","| Epoch [329/1080] Iter[ 46/428]\t\tLoss: 2.8978 Acc@1: 52.740%\n","\n","| Validation Epoch #329\t\t\tLoss: 0.3768 Acc@1: 57.90%\n","\n","=> Training Epoch #330, LR=0.0548\n","| Epoch [330/1080] Iter[  1/428]\t\tLoss: 3.2012 Acc@1: 51.042%\n","| Epoch [330/1080] Iter[ 16/428]\t\tLoss: 2.5705 Acc@1: 53.776%\n","| Epoch [330/1080] Iter[ 31/428]\t\tLoss: 2.8029 Acc@1: 54.032%\n","| Epoch [330/1080] Iter[ 46/428]\t\tLoss: 2.8871 Acc@1: 54.710%\n","\n","| Validation Epoch #330\t\t\tLoss: 0.1207 Acc@1: 61.02%\n","\n","=> Training Epoch #331, LR=0.0548\n","| Epoch [331/1080] Iter[  1/428]\t\tLoss: 2.7014 Acc@1: 60.417%\n","| Epoch [331/1080] Iter[ 16/428]\t\tLoss: 2.6541 Acc@1: 55.729%\n","| Epoch [331/1080] Iter[ 31/428]\t\tLoss: 2.8417 Acc@1: 54.973%\n","| Epoch [331/1080] Iter[ 46/428]\t\tLoss: 2.6642 Acc@1: 54.370%\n","\n","| Validation Epoch #331\t\t\tLoss: 0.2919 Acc@1: 63.08%\n","\n","=> Training Epoch #332, LR=0.0548\n","| Epoch [332/1080] Iter[  1/428]\t\tLoss: 2.8039 Acc@1: 53.125%\n","| Epoch [332/1080] Iter[ 16/428]\t\tLoss: 3.1108 Acc@1: 53.320%\n","| Epoch [332/1080] Iter[ 31/428]\t\tLoss: 2.9835 Acc@1: 53.192%\n","| Epoch [332/1080] Iter[ 46/428]\t\tLoss: 2.8784 Acc@1: 52.989%\n","\n","| Validation Epoch #332\t\t\tLoss: 1.0835 Acc@1: 59.46%\n","\n","=> Training Epoch #333, LR=0.0547\n","| Epoch [333/1080] Iter[  1/428]\t\tLoss: 2.7729 Acc@1: 56.250%\n","| Epoch [333/1080] Iter[ 16/428]\t\tLoss: 2.8238 Acc@1: 54.492%\n","| Epoch [333/1080] Iter[ 31/428]\t\tLoss: 2.7553 Acc@1: 54.570%\n","| Epoch [333/1080] Iter[ 46/428]\t\tLoss: 2.9135 Acc@1: 54.053%\n","\n","| Validation Epoch #333\t\t\tLoss: 0.1374 Acc@1: 50.58%\n","\n","=> Training Epoch #334, LR=0.0547\n","| Epoch [334/1080] Iter[  1/428]\t\tLoss: 2.8798 Acc@1: 54.167%\n","| Epoch [334/1080] Iter[ 16/428]\t\tLoss: 2.6900 Acc@1: 52.539%\n","| Epoch [334/1080] Iter[ 31/428]\t\tLoss: 2.9840 Acc@1: 52.520%\n","| Epoch [334/1080] Iter[ 46/428]\t\tLoss: 3.0577 Acc@1: 52.514%\n","\n","| Validation Epoch #334\t\t\tLoss: 0.2288 Acc@1: 60.46%\n","\n","=> Training Epoch #335, LR=0.0547\n","| Epoch [335/1080] Iter[  1/428]\t\tLoss: 2.7325 Acc@1: 56.250%\n","| Epoch [335/1080] Iter[ 16/428]\t\tLoss: 2.7403 Acc@1: 55.664%\n","| Epoch [335/1080] Iter[ 31/428]\t\tLoss: 2.5523 Acc@1: 54.704%\n","| Epoch [335/1080] Iter[ 46/428]\t\tLoss: 2.5485 Acc@1: 54.529%\n","\n","| Validation Epoch #335\t\t\tLoss: 1.1139 Acc@1: 63.82%\n","\n","=> Training Epoch #336, LR=0.0546\n","| Epoch [336/1080] Iter[  1/428]\t\tLoss: 2.9415 Acc@1: 48.958%\n","| Epoch [336/1080] Iter[ 16/428]\t\tLoss: 3.1279 Acc@1: 55.599%\n","| Epoch [336/1080] Iter[ 31/428]\t\tLoss: 2.9800 Acc@1: 54.469%\n","| Epoch [336/1080] Iter[ 46/428]\t\tLoss: 2.9473 Acc@1: 54.416%\n","\n","| Validation Epoch #336\t\t\tLoss: 0.1030 Acc@1: 63.42%\n","\n","=> Training Epoch #337, LR=0.0546\n","| Epoch [337/1080] Iter[  1/428]\t\tLoss: 2.8288 Acc@1: 57.292%\n","| Epoch [337/1080] Iter[ 16/428]\t\tLoss: 2.8824 Acc@1: 54.883%\n","| Epoch [337/1080] Iter[ 31/428]\t\tLoss: 3.0244 Acc@1: 54.570%\n","| Epoch [337/1080] Iter[ 46/428]\t\tLoss: 2.7555 Acc@1: 54.280%\n","\n","| Validation Epoch #337\t\t\tLoss: 0.2970 Acc@1: 65.52%\n","\n","=> Training Epoch #338, LR=0.0546\n","| Epoch [338/1080] Iter[  1/428]\t\tLoss: 2.6543 Acc@1: 63.542%\n","| Epoch [338/1080] Iter[ 16/428]\t\tLoss: 3.1179 Acc@1: 53.971%\n","| Epoch [338/1080] Iter[ 31/428]\t\tLoss: 3.0605 Acc@1: 54.267%\n","| Epoch [338/1080] Iter[ 46/428]\t\tLoss: 2.8895 Acc@1: 54.461%\n","\n","| Validation Epoch #338\t\t\tLoss: 1.1037 Acc@1: 59.62%\n","\n","=> Training Epoch #339, LR=0.0545\n","| Epoch [339/1080] Iter[  1/428]\t\tLoss: 2.6069 Acc@1: 62.500%\n","| Epoch [339/1080] Iter[ 16/428]\t\tLoss: 2.6738 Acc@1: 55.078%\n","| Epoch [339/1080] Iter[ 31/428]\t\tLoss: 2.7840 Acc@1: 54.738%\n","| Epoch [339/1080] Iter[ 46/428]\t\tLoss: 2.6786 Acc@1: 54.461%\n","\n","| Validation Epoch #339\t\t\tLoss: 0.0051 Acc@1: 62.78%\n","\n","=> Training Epoch #340, LR=0.0545\n","| Epoch [340/1080] Iter[  1/428]\t\tLoss: 2.7980 Acc@1: 55.208%\n","| Epoch [340/1080] Iter[ 16/428]\t\tLoss: 2.6573 Acc@1: 55.143%\n","| Epoch [340/1080] Iter[ 31/428]\t\tLoss: 2.7779 Acc@1: 55.074%\n","| Epoch [340/1080] Iter[ 46/428]\t\tLoss: 2.9520 Acc@1: 54.597%\n","\n","| Validation Epoch #340\t\t\tLoss: 0.1706 Acc@1: 59.18%\n","\n","=> Training Epoch #341, LR=0.0545\n","| Epoch [341/1080] Iter[  1/428]\t\tLoss: 3.1060 Acc@1: 51.042%\n","| Epoch [341/1080] Iter[ 16/428]\t\tLoss: 2.9693 Acc@1: 53.385%\n","| Epoch [341/1080] Iter[ 31/428]\t\tLoss: 2.7861 Acc@1: 54.066%\n","| Epoch [341/1080] Iter[ 46/428]\t\tLoss: 2.8848 Acc@1: 53.918%\n","\n","| Validation Epoch #341\t\t\tLoss: 0.0688 Acc@1: 58.00%\n","\n","=> Training Epoch #342, LR=0.0544\n","| Epoch [342/1080] Iter[  1/428]\t\tLoss: 2.7312 Acc@1: 61.458%\n","| Epoch [342/1080] Iter[ 16/428]\t\tLoss: 3.0752 Acc@1: 54.688%\n","| Epoch [342/1080] Iter[ 31/428]\t\tLoss: 3.0290 Acc@1: 54.435%\n","| Epoch [342/1080] Iter[ 46/428]\t\tLoss: 2.9763 Acc@1: 54.144%\n","\n","| Validation Epoch #342\t\t\tLoss: 0.2478 Acc@1: 62.64%\n","\n","=> Training Epoch #343, LR=0.0544\n","| Epoch [343/1080] Iter[  1/428]\t\tLoss: 3.0848 Acc@1: 47.917%\n","| Epoch [343/1080] Iter[ 16/428]\t\tLoss: 3.1119 Acc@1: 54.818%\n","| Epoch [343/1080] Iter[ 31/428]\t\tLoss: 2.7510 Acc@1: 54.335%\n","| Epoch [343/1080] Iter[ 46/428]\t\tLoss: 2.9384 Acc@1: 54.076%\n","\n","| Validation Epoch #343\t\t\tLoss: 0.2268 Acc@1: 61.96%\n","\n","=> Training Epoch #344, LR=0.0544\n","| Epoch [344/1080] Iter[  1/428]\t\tLoss: 2.6243 Acc@1: 62.500%\n","| Epoch [344/1080] Iter[ 16/428]\t\tLoss: 3.1260 Acc@1: 54.622%\n","| Epoch [344/1080] Iter[ 31/428]\t\tLoss: 2.8740 Acc@1: 54.167%\n","| Epoch [344/1080] Iter[ 46/428]\t\tLoss: 2.9428 Acc@1: 54.099%\n","\n","| Validation Epoch #344\t\t\tLoss: 0.1022 Acc@1: 62.60%\n","\n","=> Training Epoch #345, LR=0.0543\n","| Epoch [345/1080] Iter[  1/428]\t\tLoss: 2.9724 Acc@1: 52.083%\n","| Epoch [345/1080] Iter[ 16/428]\t\tLoss: 3.1374 Acc@1: 54.492%\n","| Epoch [345/1080] Iter[ 31/428]\t\tLoss: 2.7735 Acc@1: 54.167%\n","| Epoch [345/1080] Iter[ 46/428]\t\tLoss: 3.0007 Acc@1: 54.257%\n","\n","| Validation Epoch #345\t\t\tLoss: 0.0475 Acc@1: 66.18%\n","\n","=> Training Epoch #346, LR=0.0543\n","| Epoch [346/1080] Iter[  1/428]\t\tLoss: 2.8594 Acc@1: 54.167%\n","| Epoch [346/1080] Iter[ 16/428]\t\tLoss: 3.0351 Acc@1: 54.753%\n","| Epoch [346/1080] Iter[ 31/428]\t\tLoss: 2.9174 Acc@1: 54.738%\n","| Epoch [346/1080] Iter[ 46/428]\t\tLoss: 2.9652 Acc@1: 53.850%\n","\n","| Validation Epoch #346\t\t\tLoss: 0.1040 Acc@1: 60.28%\n","\n","=> Training Epoch #347, LR=0.0543\n","| Epoch [347/1080] Iter[  1/428]\t\tLoss: 2.8054 Acc@1: 53.125%\n","| Epoch [347/1080] Iter[ 16/428]\t\tLoss: 2.7259 Acc@1: 54.232%\n","| Epoch [347/1080] Iter[ 31/428]\t\tLoss: 3.0262 Acc@1: 53.125%\n","| Epoch [347/1080] Iter[ 46/428]\t\tLoss: 2.6151 Acc@1: 53.691%\n","\n","| Validation Epoch #347\t\t\tLoss: 0.1189 Acc@1: 63.24%\n","\n","=> Training Epoch #348, LR=0.0542\n","| Epoch [348/1080] Iter[  1/428]\t\tLoss: 3.3365 Acc@1: 42.708%\n","| Epoch [348/1080] Iter[ 16/428]\t\tLoss: 2.9706 Acc@1: 54.883%\n","| Epoch [348/1080] Iter[ 31/428]\t\tLoss: 2.7204 Acc@1: 54.402%\n","| Epoch [348/1080] Iter[ 46/428]\t\tLoss: 2.9056 Acc@1: 54.303%\n","\n","| Validation Epoch #348\t\t\tLoss: 0.0432 Acc@1: 64.40%\n","\n","=> Training Epoch #349, LR=0.0542\n","| Epoch [349/1080] Iter[  1/428]\t\tLoss: 2.6907 Acc@1: 63.542%\n","| Epoch [349/1080] Iter[ 16/428]\t\tLoss: 3.1111 Acc@1: 54.948%\n","| Epoch [349/1080] Iter[ 31/428]\t\tLoss: 2.9141 Acc@1: 55.074%\n","| Epoch [349/1080] Iter[ 46/428]\t\tLoss: 2.7555 Acc@1: 54.733%\n","\n","| Validation Epoch #349\t\t\tLoss: 0.0201 Acc@1: 61.36%\n","\n","=> Training Epoch #350, LR=0.0542\n","| Epoch [350/1080] Iter[  1/428]\t\tLoss: 2.8298 Acc@1: 57.292%\n","| Epoch [350/1080] Iter[ 16/428]\t\tLoss: 2.8947 Acc@1: 54.232%\n","| Epoch [350/1080] Iter[ 31/428]\t\tLoss: 2.7638 Acc@1: 54.738%\n","| Epoch [350/1080] Iter[ 46/428]\t\tLoss: 3.1867 Acc@1: 54.438%\n","\n","| Validation Epoch #350\t\t\tLoss: 0.0076 Acc@1: 57.48%\n","\n","=> Training Epoch #351, LR=0.0541\n","| Epoch [351/1080] Iter[  1/428]\t\tLoss: 3.3615 Acc@1: 46.875%\n","| Epoch [351/1080] Iter[ 16/428]\t\tLoss: 2.9866 Acc@1: 53.451%\n","| Epoch [351/1080] Iter[ 31/428]\t\tLoss: 2.9268 Acc@1: 54.032%\n","| Epoch [351/1080] Iter[ 46/428]\t\tLoss: 2.8474 Acc@1: 53.759%\n","\n","| Validation Epoch #351\t\t\tLoss: 0.0004 Acc@1: 59.02%\n","\n","=> Training Epoch #352, LR=0.0541\n","| Epoch [352/1080] Iter[  1/428]\t\tLoss: 3.2755 Acc@1: 43.750%\n","| Epoch [352/1080] Iter[ 16/428]\t\tLoss: 2.9620 Acc@1: 52.930%\n","| Epoch [352/1080] Iter[ 31/428]\t\tLoss: 3.2396 Acc@1: 53.427%\n","| Epoch [352/1080] Iter[ 46/428]\t\tLoss: 3.0510 Acc@1: 53.691%\n","\n","| Validation Epoch #352\t\t\tLoss: 0.7592 Acc@1: 58.30%\n","\n","=> Training Epoch #353, LR=0.0541\n","| Epoch [353/1080] Iter[  1/428]\t\tLoss: 2.8638 Acc@1: 51.042%\n","| Epoch [353/1080] Iter[ 16/428]\t\tLoss: 2.5979 Acc@1: 53.385%\n","| Epoch [353/1080] Iter[ 31/428]\t\tLoss: 3.0102 Acc@1: 52.923%\n","| Epoch [353/1080] Iter[ 46/428]\t\tLoss: 2.6781 Acc@1: 53.442%\n","\n","| Validation Epoch #353\t\t\tLoss: 0.0046 Acc@1: 50.54%\n","\n","=> Training Epoch #354, LR=0.0540\n","| Epoch [354/1080] Iter[  1/428]\t\tLoss: 2.9887 Acc@1: 53.125%\n","| Epoch [354/1080] Iter[ 16/428]\t\tLoss: 3.1957 Acc@1: 53.385%\n","| Epoch [354/1080] Iter[ 31/428]\t\tLoss: 2.8927 Acc@1: 53.360%\n","| Epoch [354/1080] Iter[ 46/428]\t\tLoss: 2.6758 Acc@1: 53.601%\n","\n","| Validation Epoch #354\t\t\tLoss: 0.0629 Acc@1: 62.76%\n","\n","=> Training Epoch #355, LR=0.0540\n","| Epoch [355/1080] Iter[  1/428]\t\tLoss: 2.8320 Acc@1: 54.167%\n","| Epoch [355/1080] Iter[ 16/428]\t\tLoss: 2.9632 Acc@1: 54.883%\n","| Epoch [355/1080] Iter[ 31/428]\t\tLoss: 2.9728 Acc@1: 53.965%\n","| Epoch [355/1080] Iter[ 46/428]\t\tLoss: 2.6700 Acc@1: 53.691%\n","\n","| Validation Epoch #355\t\t\tLoss: 0.8858 Acc@1: 56.04%\n","\n","=> Training Epoch #356, LR=0.0540\n","| Epoch [356/1080] Iter[  1/428]\t\tLoss: 2.5882 Acc@1: 57.292%\n","| Epoch [356/1080] Iter[ 16/428]\t\tLoss: 2.7026 Acc@1: 52.734%\n","| Epoch [356/1080] Iter[ 31/428]\t\tLoss: 2.9785 Acc@1: 53.528%\n","| Epoch [356/1080] Iter[ 46/428]\t\tLoss: 2.9885 Acc@1: 53.759%\n","\n","| Validation Epoch #356\t\t\tLoss: 0.0237 Acc@1: 60.62%\n","\n","=> Training Epoch #357, LR=0.0539\n","| Epoch [357/1080] Iter[  1/428]\t\tLoss: 2.5349 Acc@1: 63.542%\n","| Epoch [357/1080] Iter[ 16/428]\t\tLoss: 2.7834 Acc@1: 54.688%\n","| Epoch [357/1080] Iter[ 31/428]\t\tLoss: 3.0967 Acc@1: 54.099%\n","| Epoch [357/1080] Iter[ 46/428]\t\tLoss: 2.8429 Acc@1: 54.121%\n","\n","| Validation Epoch #357\t\t\tLoss: 0.3426 Acc@1: 63.96%\n","\n","=> Training Epoch #358, LR=0.0539\n","| Epoch [358/1080] Iter[  1/428]\t\tLoss: 3.1192 Acc@1: 51.042%\n","| Epoch [358/1080] Iter[ 16/428]\t\tLoss: 3.0803 Acc@1: 54.427%\n","| Epoch [358/1080] Iter[ 31/428]\t\tLoss: 2.9764 Acc@1: 53.259%\n","| Epoch [358/1080] Iter[ 46/428]\t\tLoss: 2.5640 Acc@1: 53.397%\n","\n","| Validation Epoch #358\t\t\tLoss: 1.1816 Acc@1: 59.60%\n","\n","=> Training Epoch #359, LR=0.0539\n","| Epoch [359/1080] Iter[  1/428]\t\tLoss: 2.8138 Acc@1: 58.333%\n","| Epoch [359/1080] Iter[ 16/428]\t\tLoss: 3.0879 Acc@1: 55.664%\n","| Epoch [359/1080] Iter[ 31/428]\t\tLoss: 2.9983 Acc@1: 55.242%\n","| Epoch [359/1080] Iter[ 46/428]\t\tLoss: 3.0818 Acc@1: 54.801%\n","\n","| Validation Epoch #359\t\t\tLoss: 0.1592 Acc@1: 64.36%\n","| New Samples 26658\n","\n","=> Training Epoch #360, LR=0.0538\n","| Epoch [360/1080] Iter[  1/463]\t\tLoss: 2.6711 Acc@1: 58.333%\n","| Epoch [360/1080] Iter[ 16/463]\t\tLoss: 2.5405 Acc@1: 54.232%\n","| Epoch [360/1080] Iter[ 31/463]\t\tLoss: 2.8798 Acc@1: 53.831%\n","| Epoch [360/1080] Iter[ 46/463]\t\tLoss: 3.1511 Acc@1: 53.804%\n","\n","| Validation Epoch #360\t\t\tLoss: 0.2167 Acc@1: 61.34%\n","\n","=> Training Epoch #361, LR=0.0538\n","| Epoch [361/1080] Iter[  1/463]\t\tLoss: 3.0302 Acc@1: 50.000%\n","| Epoch [361/1080] Iter[ 16/463]\t\tLoss: 2.8015 Acc@1: 54.297%\n","| Epoch [361/1080] Iter[ 31/463]\t\tLoss: 2.8591 Acc@1: 53.965%\n","| Epoch [361/1080] Iter[ 46/463]\t\tLoss: 3.0367 Acc@1: 53.284%\n","\n","| Validation Epoch #361\t\t\tLoss: 0.3221 Acc@1: 60.38%\n","\n","=> Training Epoch #362, LR=0.0538\n","| Epoch [362/1080] Iter[  1/463]\t\tLoss: 2.8651 Acc@1: 54.167%\n","| Epoch [362/1080] Iter[ 16/463]\t\tLoss: 2.7914 Acc@1: 54.362%\n","| Epoch [362/1080] Iter[ 31/463]\t\tLoss: 2.9329 Acc@1: 54.234%\n","| Epoch [362/1080] Iter[ 46/463]\t\tLoss: 2.9350 Acc@1: 53.759%\n","\n","| Validation Epoch #362\t\t\tLoss: 0.3608 Acc@1: 61.84%\n","\n","=> Training Epoch #363, LR=0.0537\n","| Epoch [363/1080] Iter[  1/463]\t\tLoss: 2.6652 Acc@1: 60.417%\n","| Epoch [363/1080] Iter[ 16/463]\t\tLoss: 2.3625 Acc@1: 53.776%\n","| Epoch [363/1080] Iter[ 31/463]\t\tLoss: 2.4605 Acc@1: 53.898%\n","| Epoch [363/1080] Iter[ 46/463]\t\tLoss: 2.4992 Acc@1: 53.872%\n","\n","| Validation Epoch #363\t\t\tLoss: 0.3945 Acc@1: 64.96%\n","\n","=> Training Epoch #364, LR=0.0537\n","| Epoch [364/1080] Iter[  1/463]\t\tLoss: 3.0232 Acc@1: 47.917%\n","| Epoch [364/1080] Iter[ 16/463]\t\tLoss: 2.9375 Acc@1: 54.557%\n","| Epoch [364/1080] Iter[ 31/463]\t\tLoss: 3.0038 Acc@1: 54.368%\n","| Epoch [364/1080] Iter[ 46/463]\t\tLoss: 2.9461 Acc@1: 54.438%\n","\n","| Validation Epoch #364\t\t\tLoss: 0.0575 Acc@1: 60.52%\n","\n","=> Training Epoch #365, LR=0.0537\n","| Epoch [365/1080] Iter[  1/463]\t\tLoss: 2.5731 Acc@1: 65.625%\n","| Epoch [365/1080] Iter[ 16/463]\t\tLoss: 2.8376 Acc@1: 55.859%\n","| Epoch [365/1080] Iter[ 31/463]\t\tLoss: 2.7534 Acc@1: 54.839%\n","| Epoch [365/1080] Iter[ 46/463]\t\tLoss: 3.0370 Acc@1: 54.053%\n","\n","| Validation Epoch #365\t\t\tLoss: 0.0015 Acc@1: 60.42%\n","\n","=> Training Epoch #366, LR=0.0536\n","| Epoch [366/1080] Iter[  1/463]\t\tLoss: 2.8980 Acc@1: 57.292%\n","| Epoch [366/1080] Iter[ 16/463]\t\tLoss: 2.8642 Acc@1: 54.232%\n","| Epoch [366/1080] Iter[ 31/463]\t\tLoss: 3.1053 Acc@1: 54.167%\n","| Epoch [366/1080] Iter[ 46/463]\t\tLoss: 2.6907 Acc@1: 53.691%\n","\n","| Validation Epoch #366\t\t\tLoss: 0.1620 Acc@1: 66.18%\n","\n","=> Training Epoch #367, LR=0.0536\n","| Epoch [367/1080] Iter[  1/463]\t\tLoss: 2.9321 Acc@1: 53.125%\n","| Epoch [367/1080] Iter[ 16/463]\t\tLoss: 2.4895 Acc@1: 52.995%\n","| Epoch [367/1080] Iter[ 31/463]\t\tLoss: 2.9047 Acc@1: 53.259%\n","| Epoch [367/1080] Iter[ 46/463]\t\tLoss: 2.7297 Acc@1: 53.442%\n","\n","| Validation Epoch #367\t\t\tLoss: 0.0097 Acc@1: 67.40%\n","\n","=> Training Epoch #368, LR=0.0536\n","| Epoch [368/1080] Iter[  1/463]\t\tLoss: 2.7335 Acc@1: 61.458%\n","| Epoch [368/1080] Iter[ 16/463]\t\tLoss: 3.1619 Acc@1: 53.971%\n","| Epoch [368/1080] Iter[ 31/463]\t\tLoss: 2.8917 Acc@1: 54.267%\n","| Epoch [368/1080] Iter[ 46/463]\t\tLoss: 3.1033 Acc@1: 54.257%\n","\n","| Validation Epoch #368\t\t\tLoss: 0.0299 Acc@1: 64.86%\n","\n","=> Training Epoch #369, LR=0.0535\n","| Epoch [369/1080] Iter[  1/463]\t\tLoss: 2.6694 Acc@1: 58.333%\n","| Epoch [369/1080] Iter[ 16/463]\t\tLoss: 2.8924 Acc@1: 54.818%\n","| Epoch [369/1080] Iter[ 31/463]\t\tLoss: 2.7389 Acc@1: 54.906%\n","| Epoch [369/1080] Iter[ 46/463]\t\tLoss: 2.9945 Acc@1: 54.438%\n","\n","| Validation Epoch #369\t\t\tLoss: 0.1344 Acc@1: 60.74%\n","\n","=> Training Epoch #370, LR=0.0535\n","| Epoch [370/1080] Iter[  1/463]\t\tLoss: 2.8467 Acc@1: 59.375%\n","| Epoch [370/1080] Iter[ 16/463]\t\tLoss: 2.6395 Acc@1: 55.859%\n","| Epoch [370/1080] Iter[ 31/463]\t\tLoss: 3.0946 Acc@1: 55.007%\n","| Epoch [370/1080] Iter[ 46/463]\t\tLoss: 2.9692 Acc@1: 54.438%\n","\n","| Validation Epoch #370\t\t\tLoss: 0.6075 Acc@1: 62.14%\n","\n","=> Training Epoch #371, LR=0.0535\n","| Epoch [371/1080] Iter[  1/463]\t\tLoss: 2.7058 Acc@1: 58.333%\n","| Epoch [371/1080] Iter[ 16/463]\t\tLoss: 2.9252 Acc@1: 54.167%\n","| Epoch [371/1080] Iter[ 31/463]\t\tLoss: 2.5810 Acc@1: 54.368%\n","| Epoch [371/1080] Iter[ 46/463]\t\tLoss: 2.9648 Acc@1: 53.216%\n","\n","| Validation Epoch #371\t\t\tLoss: 0.0665 Acc@1: 58.12%\n","\n","=> Training Epoch #372, LR=0.0534\n","| Epoch [372/1080] Iter[  1/463]\t\tLoss: 2.7277 Acc@1: 60.417%\n","| Epoch [372/1080] Iter[ 16/463]\t\tLoss: 3.0004 Acc@1: 54.688%\n","| Epoch [372/1080] Iter[ 31/463]\t\tLoss: 2.6533 Acc@1: 54.872%\n","| Epoch [372/1080] Iter[ 46/463]\t\tLoss: 2.8913 Acc@1: 54.031%\n","\n","| Validation Epoch #372\t\t\tLoss: 0.0184 Acc@1: 56.92%\n","\n","=> Training Epoch #373, LR=0.0534\n","| Epoch [373/1080] Iter[  1/463]\t\tLoss: 2.8580 Acc@1: 55.208%\n","| Epoch [373/1080] Iter[ 16/463]\t\tLoss: 2.8208 Acc@1: 56.706%\n","| Epoch [373/1080] Iter[ 31/463]\t\tLoss: 3.2082 Acc@1: 55.679%\n","| Epoch [373/1080] Iter[ 46/463]\t\tLoss: 2.7931 Acc@1: 54.846%\n","\n","| Validation Epoch #373\t\t\tLoss: 0.0025 Acc@1: 62.72%\n","\n","=> Training Epoch #374, LR=0.0534\n","| Epoch [374/1080] Iter[  1/463]\t\tLoss: 3.0665 Acc@1: 51.042%\n","| Epoch [374/1080] Iter[ 16/463]\t\tLoss: 2.4366 Acc@1: 54.102%\n","| Epoch [374/1080] Iter[ 31/463]\t\tLoss: 2.8968 Acc@1: 53.931%\n","| Epoch [374/1080] Iter[ 46/463]\t\tLoss: 2.9523 Acc@1: 53.850%\n","\n","| Validation Epoch #374\t\t\tLoss: 0.0050 Acc@1: 61.76%\n","\n","=> Training Epoch #375, LR=0.0533\n","| Epoch [375/1080] Iter[  1/463]\t\tLoss: 2.8620 Acc@1: 51.042%\n","| Epoch [375/1080] Iter[ 16/463]\t\tLoss: 2.7324 Acc@1: 53.320%\n","| Epoch [375/1080] Iter[ 31/463]\t\tLoss: 2.8894 Acc@1: 52.789%\n","| Epoch [375/1080] Iter[ 46/463]\t\tLoss: 2.6570 Acc@1: 53.668%\n","\n","| Validation Epoch #375\t\t\tLoss: 0.0932 Acc@1: 64.02%\n","\n","=> Training Epoch #376, LR=0.0533\n","| Epoch [376/1080] Iter[  1/463]\t\tLoss: 2.6986 Acc@1: 57.292%\n","| Epoch [376/1080] Iter[ 16/463]\t\tLoss: 2.6241 Acc@1: 56.771%\n","| Epoch [376/1080] Iter[ 31/463]\t\tLoss: 2.8582 Acc@1: 54.973%\n","| Epoch [376/1080] Iter[ 46/463]\t\tLoss: 3.0268 Acc@1: 54.121%\n","\n","| Validation Epoch #376\t\t\tLoss: 0.1034 Acc@1: 61.52%\n","\n","=> Training Epoch #377, LR=0.0533\n","| Epoch [377/1080] Iter[  1/463]\t\tLoss: 2.7271 Acc@1: 55.208%\n","| Epoch [377/1080] Iter[ 16/463]\t\tLoss: 3.0622 Acc@1: 52.799%\n","| Epoch [377/1080] Iter[ 31/463]\t\tLoss: 2.6233 Acc@1: 53.427%\n","| Epoch [377/1080] Iter[ 46/463]\t\tLoss: 2.8038 Acc@1: 53.102%\n","\n","| Validation Epoch #377\t\t\tLoss: 0.1118 Acc@1: 63.52%\n","\n","=> Training Epoch #378, LR=0.0532\n","| Epoch [378/1080] Iter[  1/463]\t\tLoss: 3.0835 Acc@1: 54.167%\n","| Epoch [378/1080] Iter[ 16/463]\t\tLoss: 2.4496 Acc@1: 54.818%\n","| Epoch [378/1080] Iter[ 31/463]\t\tLoss: 2.9041 Acc@1: 53.730%\n","| Epoch [378/1080] Iter[ 46/463]\t\tLoss: 3.3702 Acc@1: 53.351%\n","\n","| Validation Epoch #378\t\t\tLoss: 1.2268 Acc@1: 61.52%\n","\n","=> Training Epoch #379, LR=0.0532\n","| Epoch [379/1080] Iter[  1/463]\t\tLoss: 2.8433 Acc@1: 53.125%\n","| Epoch [379/1080] Iter[ 16/463]\t\tLoss: 2.7854 Acc@1: 55.208%\n","| Epoch [379/1080] Iter[ 31/463]\t\tLoss: 2.7916 Acc@1: 54.704%\n","| Epoch [379/1080] Iter[ 46/463]\t\tLoss: 2.7039 Acc@1: 54.370%\n","\n","| Validation Epoch #379\t\t\tLoss: 0.3344 Acc@1: 57.88%\n","\n","=> Training Epoch #380, LR=0.0532\n","| Epoch [380/1080] Iter[  1/463]\t\tLoss: 2.8743 Acc@1: 52.083%\n","| Epoch [380/1080] Iter[ 16/463]\t\tLoss: 2.8506 Acc@1: 52.214%\n","| Epoch [380/1080] Iter[ 31/463]\t\tLoss: 2.7728 Acc@1: 53.226%\n","| Epoch [380/1080] Iter[ 46/463]\t\tLoss: 2.9354 Acc@1: 53.374%\n","\n","| Validation Epoch #380\t\t\tLoss: 0.0493 Acc@1: 59.74%\n","\n","=> Training Epoch #381, LR=0.0531\n","| Epoch [381/1080] Iter[  1/463]\t\tLoss: 3.0540 Acc@1: 50.000%\n","| Epoch [381/1080] Iter[ 16/463]\t\tLoss: 2.5916 Acc@1: 54.557%\n","| Epoch [381/1080] Iter[ 31/463]\t\tLoss: 2.9206 Acc@1: 54.133%\n","| Epoch [381/1080] Iter[ 46/463]\t\tLoss: 3.0091 Acc@1: 52.921%\n","\n","| Validation Epoch #381\t\t\tLoss: 0.0060 Acc@1: 57.46%\n","\n","=> Training Epoch #382, LR=0.0531\n","| Epoch [382/1080] Iter[  1/463]\t\tLoss: 3.4224 Acc@1: 46.875%\n","| Epoch [382/1080] Iter[ 16/463]\t\tLoss: 3.1316 Acc@1: 51.562%\n","| Epoch [382/1080] Iter[ 31/463]\t\tLoss: 2.9895 Acc@1: 52.285%\n","| Epoch [382/1080] Iter[ 46/463]\t\tLoss: 2.8036 Acc@1: 52.332%\n","\n","| Validation Epoch #382\t\t\tLoss: 1.6902 Acc@1: 46.76%\n","\n","=> Training Epoch #383, LR=0.0530\n","| Epoch [383/1080] Iter[  1/463]\t\tLoss: 2.9345 Acc@1: 54.167%\n","| Epoch [383/1080] Iter[ 16/463]\t\tLoss: 2.9475 Acc@1: 54.167%\n","| Epoch [383/1080] Iter[ 31/463]\t\tLoss: 2.8882 Acc@1: 53.730%\n","| Epoch [383/1080] Iter[ 46/463]\t\tLoss: 2.7944 Acc@1: 53.578%\n","\n","| Validation Epoch #383\t\t\tLoss: 0.0633 Acc@1: 62.86%\n","\n","=> Training Epoch #384, LR=0.0530\n","| Epoch [384/1080] Iter[  1/463]\t\tLoss: 2.8442 Acc@1: 50.000%\n","| Epoch [384/1080] Iter[ 16/463]\t\tLoss: 2.9720 Acc@1: 53.906%\n","| Epoch [384/1080] Iter[ 31/463]\t\tLoss: 2.6572 Acc@1: 54.301%\n","| Epoch [384/1080] Iter[ 46/463]\t\tLoss: 2.7160 Acc@1: 54.053%\n","\n","| Validation Epoch #384\t\t\tLoss: 0.2181 Acc@1: 59.48%\n","\n","=> Training Epoch #385, LR=0.0530\n","| Epoch [385/1080] Iter[  1/463]\t\tLoss: 2.7376 Acc@1: 60.417%\n","| Epoch [385/1080] Iter[ 16/463]\t\tLoss: 2.9777 Acc@1: 55.794%\n","| Epoch [385/1080] Iter[ 31/463]\t\tLoss: 2.9336 Acc@1: 55.343%\n","| Epoch [385/1080] Iter[ 46/463]\t\tLoss: 2.7378 Acc@1: 54.597%\n","\n","| Validation Epoch #385\t\t\tLoss: 0.0025 Acc@1: 59.38%\n","\n","=> Training Epoch #386, LR=0.0529\n","| Epoch [386/1080] Iter[  1/463]\t\tLoss: 2.9952 Acc@1: 50.000%\n","| Epoch [386/1080] Iter[ 16/463]\t\tLoss: 2.7793 Acc@1: 55.469%\n","| Epoch [386/1080] Iter[ 31/463]\t\tLoss: 2.8557 Acc@1: 55.007%\n","| Epoch [386/1080] Iter[ 46/463]\t\tLoss: 2.9517 Acc@1: 54.869%\n","\n","| Validation Epoch #386\t\t\tLoss: 0.0111 Acc@1: 61.36%\n","\n","=> Training Epoch #387, LR=0.0529\n","| Epoch [387/1080] Iter[  1/463]\t\tLoss: 3.0371 Acc@1: 51.042%\n","| Epoch [387/1080] Iter[ 16/463]\t\tLoss: 2.8599 Acc@1: 53.516%\n","| Epoch [387/1080] Iter[ 31/463]\t\tLoss: 2.9307 Acc@1: 53.562%\n","| Epoch [387/1080] Iter[ 46/463]\t\tLoss: 2.4368 Acc@1: 54.076%\n","\n","| Validation Epoch #387\t\t\tLoss: 0.0135 Acc@1: 66.56%\n","\n","=> Training Epoch #388, LR=0.0529\n","| Epoch [388/1080] Iter[  1/463]\t\tLoss: 2.7888 Acc@1: 58.333%\n","| Epoch [388/1080] Iter[ 16/463]\t\tLoss: 2.9602 Acc@1: 53.060%\n","| Epoch [388/1080] Iter[ 31/463]\t\tLoss: 2.7814 Acc@1: 53.629%\n","| Epoch [388/1080] Iter[ 46/463]\t\tLoss: 2.7324 Acc@1: 53.510%\n","\n","| Validation Epoch #388\t\t\tLoss: 0.1959 Acc@1: 65.64%\n","\n","=> Training Epoch #389, LR=0.0528\n","| Epoch [389/1080] Iter[  1/463]\t\tLoss: 2.8049 Acc@1: 57.292%\n","| Epoch [389/1080] Iter[ 16/463]\t\tLoss: 2.8277 Acc@1: 54.036%\n","| Epoch [389/1080] Iter[ 31/463]\t\tLoss: 2.9963 Acc@1: 53.730%\n","| Epoch [389/1080] Iter[ 46/463]\t\tLoss: 2.9106 Acc@1: 53.714%\n","\n","| Validation Epoch #389\t\t\tLoss: 0.0254 Acc@1: 63.68%\n","\n","=> Training Epoch #390, LR=0.0528\n","| Epoch [390/1080] Iter[  1/463]\t\tLoss: 3.2924 Acc@1: 45.833%\n","| Epoch [390/1080] Iter[ 16/463]\t\tLoss: 2.9824 Acc@1: 51.823%\n","| Epoch [390/1080] Iter[ 31/463]\t\tLoss: 2.8510 Acc@1: 52.856%\n","| Epoch [390/1080] Iter[ 46/463]\t\tLoss: 3.1214 Acc@1: 52.785%\n","\n","| Validation Epoch #390\t\t\tLoss: 0.0201 Acc@1: 66.38%\n","\n","=> Training Epoch #391, LR=0.0528\n","| Epoch [391/1080] Iter[  1/463]\t\tLoss: 2.8665 Acc@1: 58.333%\n","| Epoch [391/1080] Iter[ 16/463]\t\tLoss: 2.6827 Acc@1: 55.078%\n","| Epoch [391/1080] Iter[ 31/463]\t\tLoss: 2.9255 Acc@1: 54.167%\n","| Epoch [391/1080] Iter[ 46/463]\t\tLoss: 3.0107 Acc@1: 53.895%\n","\n","| Validation Epoch #391\t\t\tLoss: 0.8827 Acc@1: 57.78%\n","\n","=> Training Epoch #392, LR=0.0527\n","| Epoch [392/1080] Iter[  1/463]\t\tLoss: 2.8896 Acc@1: 53.125%\n","| Epoch [392/1080] Iter[ 16/463]\t\tLoss: 2.9268 Acc@1: 53.971%\n","| Epoch [392/1080] Iter[ 31/463]\t\tLoss: 2.8415 Acc@1: 54.570%\n","| Epoch [392/1080] Iter[ 46/463]\t\tLoss: 2.7728 Acc@1: 53.963%\n","\n","| Validation Epoch #392\t\t\tLoss: 0.3959 Acc@1: 68.06%\n","| Saving Best model...\t\t\tTop1 = 68.06%\n","\n","=> Training Epoch #393, LR=0.0527\n","| Epoch [393/1080] Iter[  1/463]\t\tLoss: 2.7737 Acc@1: 59.375%\n","| Epoch [393/1080] Iter[ 16/463]\t\tLoss: 3.0134 Acc@1: 55.013%\n","| Epoch [393/1080] Iter[ 31/463]\t\tLoss: 2.9438 Acc@1: 53.898%\n","| Epoch [393/1080] Iter[ 46/463]\t\tLoss: 3.1931 Acc@1: 53.895%\n","\n","| Validation Epoch #393\t\t\tLoss: 0.2433 Acc@1: 58.62%\n","\n","=> Training Epoch #394, LR=0.0527\n","| Epoch [394/1080] Iter[  1/463]\t\tLoss: 2.8205 Acc@1: 57.292%\n","| Epoch [394/1080] Iter[ 16/463]\t\tLoss: 2.7463 Acc@1: 54.492%\n","| Epoch [394/1080] Iter[ 31/463]\t\tLoss: 2.7843 Acc@1: 53.898%\n","| Epoch [394/1080] Iter[ 46/463]\t\tLoss: 2.7867 Acc@1: 53.827%\n","\n","| Validation Epoch #394\t\t\tLoss: 0.2036 Acc@1: 64.26%\n","\n","=> Training Epoch #395, LR=0.0526\n","| Epoch [395/1080] Iter[  1/463]\t\tLoss: 2.9358 Acc@1: 53.125%\n","| Epoch [395/1080] Iter[ 16/463]\t\tLoss: 2.7293 Acc@1: 53.776%\n","| Epoch [395/1080] Iter[ 31/463]\t\tLoss: 2.8054 Acc@1: 53.293%\n","| Epoch [395/1080] Iter[ 46/463]\t\tLoss: 2.9241 Acc@1: 53.170%\n","\n","| Validation Epoch #395\t\t\tLoss: 0.0005 Acc@1: 62.34%\n","\n","=> Training Epoch #396, LR=0.0526\n","| Epoch [396/1080] Iter[  1/463]\t\tLoss: 3.0723 Acc@1: 48.958%\n","| Epoch [396/1080] Iter[ 16/463]\t\tLoss: 3.0966 Acc@1: 54.297%\n","| Epoch [396/1080] Iter[ 31/463]\t\tLoss: 2.8766 Acc@1: 53.864%\n","| Epoch [396/1080] Iter[ 46/463]\t\tLoss: 2.7275 Acc@1: 53.782%\n","\n","| Validation Epoch #396\t\t\tLoss: 0.0139 Acc@1: 63.32%\n","\n","=> Training Epoch #397, LR=0.0525\n","| Epoch [397/1080] Iter[  1/463]\t\tLoss: 3.1347 Acc@1: 44.792%\n","| Epoch [397/1080] Iter[ 16/463]\t\tLoss: 2.7961 Acc@1: 53.190%\n","| Epoch [397/1080] Iter[ 31/463]\t\tLoss: 2.9158 Acc@1: 54.335%\n","| Epoch [397/1080] Iter[ 46/463]\t\tLoss: 3.1965 Acc@1: 54.053%\n","\n","| Validation Epoch #397\t\t\tLoss: 0.2824 Acc@1: 65.38%\n","\n","=> Training Epoch #398, LR=0.0525\n","| Epoch [398/1080] Iter[  1/463]\t\tLoss: 2.8216 Acc@1: 55.208%\n","| Epoch [398/1080] Iter[ 16/463]\t\tLoss: 3.0140 Acc@1: 53.385%\n","| Epoch [398/1080] Iter[ 31/463]\t\tLoss: 3.0814 Acc@1: 53.831%\n","| Epoch [398/1080] Iter[ 46/463]\t\tLoss: 2.7988 Acc@1: 53.759%\n","\n","| Validation Epoch #398\t\t\tLoss: 0.0413 Acc@1: 66.50%\n","\n","=> Training Epoch #399, LR=0.0525\n","| Epoch [399/1080] Iter[  1/463]\t\tLoss: 2.5961 Acc@1: 58.333%\n","| Epoch [399/1080] Iter[ 16/463]\t\tLoss: 2.6849 Acc@1: 55.013%\n","| Epoch [399/1080] Iter[ 31/463]\t\tLoss: 2.9415 Acc@1: 54.267%\n","| Epoch [399/1080] Iter[ 46/463]\t\tLoss: 3.1496 Acc@1: 53.351%\n","\n","| Validation Epoch #399\t\t\tLoss: 0.0412 Acc@1: 55.56%\n","\n","=> Training Epoch #400, LR=0.0524\n","| Epoch [400/1080] Iter[  1/463]\t\tLoss: 3.0561 Acc@1: 50.000%\n","| Epoch [400/1080] Iter[ 16/463]\t\tLoss: 3.1226 Acc@1: 53.190%\n","| Epoch [400/1080] Iter[ 31/463]\t\tLoss: 2.8148 Acc@1: 54.503%\n","| Epoch [400/1080] Iter[ 46/463]\t\tLoss: 2.9939 Acc@1: 53.804%\n","\n","| Validation Epoch #400\t\t\tLoss: 0.1006 Acc@1: 65.26%\n","\n","=> Training Epoch #401, LR=0.0524\n","| Epoch [401/1080] Iter[  1/463]\t\tLoss: 3.0235 Acc@1: 50.000%\n","| Epoch [401/1080] Iter[ 16/463]\t\tLoss: 2.7665 Acc@1: 55.534%\n","| Epoch [401/1080] Iter[ 31/463]\t\tLoss: 2.9419 Acc@1: 55.343%\n","| Epoch [401/1080] Iter[ 46/463]\t\tLoss: 2.8875 Acc@1: 54.416%\n","\n","| Validation Epoch #401\t\t\tLoss: 0.1316 Acc@1: 62.86%\n","\n","=> Training Epoch #402, LR=0.0524\n","| Epoch [402/1080] Iter[  1/463]\t\tLoss: 3.0121 Acc@1: 51.042%\n","| Epoch [402/1080] Iter[ 16/463]\t\tLoss: 3.1309 Acc@1: 53.776%\n","| Epoch [402/1080] Iter[ 31/463]\t\tLoss: 3.1260 Acc@1: 53.898%\n","| Epoch [402/1080] Iter[ 46/463]\t\tLoss: 2.6800 Acc@1: 54.167%\n","\n","| Validation Epoch #402\t\t\tLoss: 0.0978 Acc@1: 61.18%\n","\n","=> Training Epoch #403, LR=0.0523\n","| Epoch [403/1080] Iter[  1/463]\t\tLoss: 2.8942 Acc@1: 48.958%\n","| Epoch [403/1080] Iter[ 16/463]\t\tLoss: 3.0948 Acc@1: 53.906%\n","| Epoch [403/1080] Iter[ 31/463]\t\tLoss: 3.3562 Acc@1: 53.931%\n","| Epoch [403/1080] Iter[ 46/463]\t\tLoss: 2.9061 Acc@1: 54.235%\n","\n","| Validation Epoch #403\t\t\tLoss: 0.6242 Acc@1: 59.60%\n","\n","=> Training Epoch #404, LR=0.0523\n","| Epoch [404/1080] Iter[  1/463]\t\tLoss: 2.6405 Acc@1: 55.208%\n","| Epoch [404/1080] Iter[ 16/463]\t\tLoss: 2.7051 Acc@1: 55.599%\n","| Epoch [404/1080] Iter[ 31/463]\t\tLoss: 3.0642 Acc@1: 55.242%\n","| Epoch [404/1080] Iter[ 46/463]\t\tLoss: 2.7852 Acc@1: 54.891%\n","\n","| Validation Epoch #404\t\t\tLoss: 0.5553 Acc@1: 64.76%\n","\n","=> Training Epoch #405, LR=0.0522\n","| Epoch [405/1080] Iter[  1/463]\t\tLoss: 2.7262 Acc@1: 58.333%\n","| Epoch [405/1080] Iter[ 16/463]\t\tLoss: 2.7449 Acc@1: 53.776%\n","| Epoch [405/1080] Iter[ 31/463]\t\tLoss: 2.8030 Acc@1: 54.335%\n","| Epoch [405/1080] Iter[ 46/463]\t\tLoss: 3.1599 Acc@1: 53.782%\n","\n","| Validation Epoch #405\t\t\tLoss: 1.4211 Acc@1: 55.42%\n","\n","=> Training Epoch #406, LR=0.0522\n","| Epoch [406/1080] Iter[  1/463]\t\tLoss: 3.1334 Acc@1: 50.000%\n","| Epoch [406/1080] Iter[ 16/463]\t\tLoss: 2.9950 Acc@1: 52.865%\n","| Epoch [406/1080] Iter[ 31/463]\t\tLoss: 3.1284 Acc@1: 53.427%\n","| Epoch [406/1080] Iter[ 46/463]\t\tLoss: 3.0322 Acc@1: 53.102%\n","\n","| Validation Epoch #406\t\t\tLoss: 0.6455 Acc@1: 65.36%\n","\n","=> Training Epoch #407, LR=0.0522\n","| Epoch [407/1080] Iter[  1/463]\t\tLoss: 2.7742 Acc@1: 52.083%\n","| Epoch [407/1080] Iter[ 16/463]\t\tLoss: 2.9561 Acc@1: 55.013%\n","| Epoch [407/1080] Iter[ 31/463]\t\tLoss: 2.9598 Acc@1: 54.839%\n","| Epoch [407/1080] Iter[ 46/463]\t\tLoss: 3.3762 Acc@1: 54.484%\n","\n","| Validation Epoch #407\t\t\tLoss: 0.0094 Acc@1: 62.54%\n","\n","=> Training Epoch #408, LR=0.0521\n","| Epoch [408/1080] Iter[  1/463]\t\tLoss: 2.8473 Acc@1: 56.250%\n","| Epoch [408/1080] Iter[ 16/463]\t\tLoss: 3.1049 Acc@1: 54.427%\n","| Epoch [408/1080] Iter[ 31/463]\t\tLoss: 2.9296 Acc@1: 55.242%\n","| Epoch [408/1080] Iter[ 46/463]\t\tLoss: 3.2493 Acc@1: 54.325%\n","\n","| Validation Epoch #408\t\t\tLoss: 0.8001 Acc@1: 64.72%\n","\n","=> Training Epoch #409, LR=0.0521\n","| Epoch [409/1080] Iter[  1/463]\t\tLoss: 2.7563 Acc@1: 56.250%\n","| Epoch [409/1080] Iter[ 16/463]\t\tLoss: 2.9399 Acc@1: 53.060%\n","| Epoch [409/1080] Iter[ 31/463]\t\tLoss: 2.9280 Acc@1: 53.360%\n","| Epoch [409/1080] Iter[ 46/463]\t\tLoss: 3.0889 Acc@1: 53.533%\n","\n","| Validation Epoch #409\t\t\tLoss: 0.9384 Acc@1: 58.22%\n","\n","=> Training Epoch #410, LR=0.0521\n","| Epoch [410/1080] Iter[  1/463]\t\tLoss: 2.9063 Acc@1: 57.292%\n","| Epoch [410/1080] Iter[ 16/463]\t\tLoss: 2.7933 Acc@1: 54.818%\n","| Epoch [410/1080] Iter[ 31/463]\t\tLoss: 2.7470 Acc@1: 54.032%\n","| Epoch [410/1080] Iter[ 46/463]\t\tLoss: 2.9470 Acc@1: 53.759%\n","\n","| Validation Epoch #410\t\t\tLoss: 0.0095 Acc@1: 57.54%\n","\n","=> Training Epoch #411, LR=0.0520\n","| Epoch [411/1080] Iter[  1/463]\t\tLoss: 3.0147 Acc@1: 55.208%\n","| Epoch [411/1080] Iter[ 16/463]\t\tLoss: 2.7705 Acc@1: 52.930%\n","| Epoch [411/1080] Iter[ 31/463]\t\tLoss: 2.8817 Acc@1: 53.763%\n","| Epoch [411/1080] Iter[ 46/463]\t\tLoss: 2.8304 Acc@1: 53.555%\n","\n","| Validation Epoch #411\t\t\tLoss: 0.4391 Acc@1: 61.22%\n","\n","=> Training Epoch #412, LR=0.0520\n","| Epoch [412/1080] Iter[  1/463]\t\tLoss: 2.7082 Acc@1: 55.208%\n","| Epoch [412/1080] Iter[ 16/463]\t\tLoss: 2.9045 Acc@1: 56.380%\n","| Epoch [412/1080] Iter[ 31/463]\t\tLoss: 2.9870 Acc@1: 55.712%\n","| Epoch [412/1080] Iter[ 46/463]\t\tLoss: 2.8079 Acc@1: 54.801%\n","\n","| Validation Epoch #412\t\t\tLoss: 0.7420 Acc@1: 59.22%\n","\n","=> Training Epoch #413, LR=0.0519\n","| Epoch [413/1080] Iter[  1/463]\t\tLoss: 2.7488 Acc@1: 55.208%\n","| Epoch [413/1080] Iter[ 16/463]\t\tLoss: 2.8703 Acc@1: 54.883%\n","| Epoch [413/1080] Iter[ 31/463]\t\tLoss: 2.7362 Acc@1: 54.301%\n","| Epoch [413/1080] Iter[ 46/463]\t\tLoss: 3.1041 Acc@1: 53.782%\n","\n","| Validation Epoch #413\t\t\tLoss: 0.2473 Acc@1: 61.04%\n","\n","=> Training Epoch #414, LR=0.0519\n","| Epoch [414/1080] Iter[  1/463]\t\tLoss: 2.7584 Acc@1: 55.208%\n","| Epoch [414/1080] Iter[ 16/463]\t\tLoss: 2.5568 Acc@1: 54.622%\n","| Epoch [414/1080] Iter[ 31/463]\t\tLoss: 3.0696 Acc@1: 53.159%\n","| Epoch [414/1080] Iter[ 46/463]\t\tLoss: 3.0507 Acc@1: 53.736%\n","\n","| Validation Epoch #414\t\t\tLoss: 0.1592 Acc@1: 62.80%\n","\n","=> Training Epoch #415, LR=0.0519\n","| Epoch [415/1080] Iter[  1/463]\t\tLoss: 2.9026 Acc@1: 56.250%\n","| Epoch [415/1080] Iter[ 16/463]\t\tLoss: 2.9764 Acc@1: 53.646%\n","| Epoch [415/1080] Iter[ 31/463]\t\tLoss: 2.6703 Acc@1: 53.831%\n","| Epoch [415/1080] Iter[ 46/463]\t\tLoss: 2.8980 Acc@1: 53.533%\n","\n","| Validation Epoch #415\t\t\tLoss: 0.0072 Acc@1: 63.94%\n","\n","=> Training Epoch #416, LR=0.0518\n","| Epoch [416/1080] Iter[  1/463]\t\tLoss: 3.0951 Acc@1: 48.958%\n","| Epoch [416/1080] Iter[ 16/463]\t\tLoss: 3.2088 Acc@1: 55.794%\n","| Epoch [416/1080] Iter[ 31/463]\t\tLoss: 2.9371 Acc@1: 53.427%\n","| Epoch [416/1080] Iter[ 46/463]\t\tLoss: 2.7314 Acc@1: 53.374%\n","\n","| Validation Epoch #416\t\t\tLoss: 0.0717 Acc@1: 63.94%\n","\n","=> Training Epoch #417, LR=0.0518\n","| Epoch [417/1080] Iter[  1/463]\t\tLoss: 2.9629 Acc@1: 53.125%\n","| Epoch [417/1080] Iter[ 16/463]\t\tLoss: 3.0673 Acc@1: 54.622%\n","| Epoch [417/1080] Iter[ 31/463]\t\tLoss: 2.6917 Acc@1: 54.301%\n","| Epoch [417/1080] Iter[ 46/463]\t\tLoss: 2.8430 Acc@1: 53.125%\n","\n","| Validation Epoch #417\t\t\tLoss: 0.0101 Acc@1: 66.82%\n","\n","=> Training Epoch #418, LR=0.0517\n","| Epoch [418/1080] Iter[  1/463]\t\tLoss: 3.0761 Acc@1: 51.042%\n","| Epoch [418/1080] Iter[ 16/463]\t\tLoss: 2.8256 Acc@1: 53.320%\n","| Epoch [418/1080] Iter[ 31/463]\t\tLoss: 2.6483 Acc@1: 53.629%\n","| Epoch [418/1080] Iter[ 46/463]\t\tLoss: 2.6890 Acc@1: 53.170%\n","\n","| Validation Epoch #418\t\t\tLoss: 0.7795 Acc@1: 62.08%\n","\n","=> Training Epoch #419, LR=0.0517\n","| Epoch [419/1080] Iter[  1/463]\t\tLoss: 2.8588 Acc@1: 54.167%\n","| Epoch [419/1080] Iter[ 16/463]\t\tLoss: 2.8112 Acc@1: 55.404%\n","| Epoch [419/1080] Iter[ 31/463]\t\tLoss: 2.7987 Acc@1: 55.040%\n","| Epoch [419/1080] Iter[ 46/463]\t\tLoss: 2.7156 Acc@1: 54.529%\n","\n","| Validation Epoch #419\t\t\tLoss: 0.4797 Acc@1: 59.14%\n","\n","=> Training Epoch #420, LR=0.0517\n","| Epoch [420/1080] Iter[  1/463]\t\tLoss: 2.6263 Acc@1: 56.250%\n","| Epoch [420/1080] Iter[ 16/463]\t\tLoss: 2.7829 Acc@1: 54.753%\n","| Epoch [420/1080] Iter[ 31/463]\t\tLoss: 2.7418 Acc@1: 54.637%\n","| Epoch [420/1080] Iter[ 46/463]\t\tLoss: 3.0209 Acc@1: 53.986%\n","\n","| Validation Epoch #420\t\t\tLoss: 0.0603 Acc@1: 64.32%\n","\n","=> Training Epoch #421, LR=0.0516\n","| Epoch [421/1080] Iter[  1/463]\t\tLoss: 2.9122 Acc@1: 53.125%\n","| Epoch [421/1080] Iter[ 16/463]\t\tLoss: 2.8503 Acc@1: 53.971%\n","| Epoch [421/1080] Iter[ 31/463]\t\tLoss: 3.0515 Acc@1: 53.965%\n","| Epoch [421/1080] Iter[ 46/463]\t\tLoss: 2.8112 Acc@1: 54.144%\n","\n","| Validation Epoch #421\t\t\tLoss: 0.0170 Acc@1: 57.88%\n","\n","=> Training Epoch #422, LR=0.0516\n","| Epoch [422/1080] Iter[  1/463]\t\tLoss: 2.6783 Acc@1: 55.208%\n","| Epoch [422/1080] Iter[ 16/463]\t\tLoss: 2.9469 Acc@1: 54.688%\n","| Epoch [422/1080] Iter[ 31/463]\t\tLoss: 2.8024 Acc@1: 53.495%\n","| Epoch [422/1080] Iter[ 46/463]\t\tLoss: 2.9994 Acc@1: 53.759%\n","\n","| Validation Epoch #422\t\t\tLoss: 0.1420 Acc@1: 58.10%\n","\n","=> Training Epoch #423, LR=0.0516\n","| Epoch [423/1080] Iter[  1/463]\t\tLoss: 2.7983 Acc@1: 58.333%\n","| Epoch [423/1080] Iter[ 16/463]\t\tLoss: 2.8891 Acc@1: 54.036%\n","| Epoch [423/1080] Iter[ 31/463]\t\tLoss: 3.1329 Acc@1: 52.655%\n","| Epoch [423/1080] Iter[ 46/463]\t\tLoss: 2.9523 Acc@1: 52.944%\n","\n","| Validation Epoch #423\t\t\tLoss: 0.1727 Acc@1: 63.10%\n","\n","=> Training Epoch #424, LR=0.0515\n","| Epoch [424/1080] Iter[  1/463]\t\tLoss: 2.8934 Acc@1: 51.042%\n","| Epoch [424/1080] Iter[ 16/463]\t\tLoss: 2.9044 Acc@1: 52.995%\n","| Epoch [424/1080] Iter[ 31/463]\t\tLoss: 2.5159 Acc@1: 53.125%\n","| Epoch [424/1080] Iter[ 46/463]\t\tLoss: 2.8130 Acc@1: 54.144%\n","\n","| Validation Epoch #424\t\t\tLoss: 0.0289 Acc@1: 58.88%\n","\n","=> Training Epoch #425, LR=0.0515\n","| Epoch [425/1080] Iter[  1/463]\t\tLoss: 2.7373 Acc@1: 58.333%\n","| Epoch [425/1080] Iter[ 16/463]\t\tLoss: 2.3791 Acc@1: 55.794%\n","| Epoch [425/1080] Iter[ 31/463]\t\tLoss: 3.1079 Acc@1: 54.267%\n","| Epoch [425/1080] Iter[ 46/463]\t\tLoss: 2.7674 Acc@1: 54.008%\n","\n","| Validation Epoch #425\t\t\tLoss: 0.0691 Acc@1: 62.94%\n","\n","=> Training Epoch #426, LR=0.0514\n","| Epoch [426/1080] Iter[  1/463]\t\tLoss: 2.9959 Acc@1: 48.958%\n","| Epoch [426/1080] Iter[ 16/463]\t\tLoss: 2.7630 Acc@1: 53.776%\n","| Epoch [426/1080] Iter[ 31/463]\t\tLoss: 2.9920 Acc@1: 54.234%\n","| Epoch [426/1080] Iter[ 46/463]\t\tLoss: 2.7190 Acc@1: 53.804%\n","\n","| Validation Epoch #426\t\t\tLoss: 0.0453 Acc@1: 64.42%\n","\n","=> Training Epoch #427, LR=0.0514\n","| Epoch [427/1080] Iter[  1/463]\t\tLoss: 2.7480 Acc@1: 56.250%\n","| Epoch [427/1080] Iter[ 16/463]\t\tLoss: 2.8434 Acc@1: 54.688%\n","| Epoch [427/1080] Iter[ 31/463]\t\tLoss: 3.0175 Acc@1: 54.200%\n","| Epoch [427/1080] Iter[ 46/463]\t\tLoss: 2.7945 Acc@1: 54.574%\n","\n","| Validation Epoch #427\t\t\tLoss: 0.0737 Acc@1: 66.00%\n","\n","=> Training Epoch #428, LR=0.0514\n","| Epoch [428/1080] Iter[  1/463]\t\tLoss: 2.8473 Acc@1: 53.125%\n","| Epoch [428/1080] Iter[ 16/463]\t\tLoss: 2.4818 Acc@1: 55.664%\n","| Epoch [428/1080] Iter[ 31/463]\t\tLoss: 2.8029 Acc@1: 54.301%\n","| Epoch [428/1080] Iter[ 46/463]\t\tLoss: 3.0313 Acc@1: 53.601%\n","\n","| Validation Epoch #428\t\t\tLoss: 0.0555 Acc@1: 64.88%\n","\n","=> Training Epoch #429, LR=0.0513\n","| Epoch [429/1080] Iter[  1/463]\t\tLoss: 2.7607 Acc@1: 52.083%\n","| Epoch [429/1080] Iter[ 16/463]\t\tLoss: 2.7112 Acc@1: 53.711%\n","| Epoch [429/1080] Iter[ 31/463]\t\tLoss: 2.8337 Acc@1: 53.730%\n","| Epoch [429/1080] Iter[ 46/463]\t\tLoss: 2.7668 Acc@1: 54.008%\n","\n","| Validation Epoch #429\t\t\tLoss: 0.0180 Acc@1: 64.98%\n","\n","=> Training Epoch #430, LR=0.0513\n","| Epoch [430/1080] Iter[  1/463]\t\tLoss: 2.8641 Acc@1: 56.250%\n","| Epoch [430/1080] Iter[ 16/463]\t\tLoss: 2.8354 Acc@1: 53.646%\n","| Epoch [430/1080] Iter[ 31/463]\t\tLoss: 2.9974 Acc@1: 53.394%\n","| Epoch [430/1080] Iter[ 46/463]\t\tLoss: 2.7683 Acc@1: 53.555%\n","\n","| Validation Epoch #430\t\t\tLoss: 0.2134 Acc@1: 60.06%\n","\n","=> Training Epoch #431, LR=0.0512\n","| Epoch [431/1080] Iter[  1/463]\t\tLoss: 2.9975 Acc@1: 48.958%\n","| Epoch [431/1080] Iter[ 16/463]\t\tLoss: 2.8692 Acc@1: 53.971%\n","| Epoch [431/1080] Iter[ 31/463]\t\tLoss: 3.0274 Acc@1: 53.327%\n","| Epoch [431/1080] Iter[ 46/463]\t\tLoss: 2.8628 Acc@1: 53.736%\n","\n","| Validation Epoch #431\t\t\tLoss: 0.0370 Acc@1: 63.08%\n","\n","=> Training Epoch #432, LR=0.0512\n","| Epoch [432/1080] Iter[  1/463]\t\tLoss: 3.4415 Acc@1: 43.750%\n","| Epoch [432/1080] Iter[ 16/463]\t\tLoss: 2.7173 Acc@1: 52.930%\n","| Epoch [432/1080] Iter[ 31/463]\t\tLoss: 2.8410 Acc@1: 53.259%\n","| Epoch [432/1080] Iter[ 46/463]\t\tLoss: 2.8648 Acc@1: 53.601%\n","\n","| Validation Epoch #432\t\t\tLoss: 0.6253 Acc@1: 60.08%\n","\n","=> Training Epoch #433, LR=0.0512\n","| Epoch [433/1080] Iter[  1/463]\t\tLoss: 3.0283 Acc@1: 48.958%\n","| Epoch [433/1080] Iter[ 16/463]\t\tLoss: 2.8252 Acc@1: 55.534%\n","| Epoch [433/1080] Iter[ 31/463]\t\tLoss: 2.6990 Acc@1: 55.578%\n","| Epoch [433/1080] Iter[ 46/463]\t\tLoss: 3.0655 Acc@1: 55.276%\n","\n","| Validation Epoch #433\t\t\tLoss: 0.1100 Acc@1: 60.30%\n","\n","=> Training Epoch #434, LR=0.0511\n","| Epoch [434/1080] Iter[  1/463]\t\tLoss: 2.9061 Acc@1: 55.208%\n","| Epoch [434/1080] Iter[ 16/463]\t\tLoss: 2.7855 Acc@1: 54.492%\n","| Epoch [434/1080] Iter[ 31/463]\t\tLoss: 3.1907 Acc@1: 53.931%\n","| Epoch [434/1080] Iter[ 46/463]\t\tLoss: 2.9301 Acc@1: 53.714%\n","\n","| Validation Epoch #434\t\t\tLoss: 0.0531 Acc@1: 61.92%\n","\n","=> Training Epoch #435, LR=0.0511\n","| Epoch [435/1080] Iter[  1/463]\t\tLoss: 2.8042 Acc@1: 56.250%\n","| Epoch [435/1080] Iter[ 16/463]\t\tLoss: 2.7404 Acc@1: 54.818%\n","| Epoch [435/1080] Iter[ 31/463]\t\tLoss: 2.9672 Acc@1: 53.831%\n","| Epoch [435/1080] Iter[ 46/463]\t\tLoss: 2.9262 Acc@1: 54.484%\n","\n","| Validation Epoch #435\t\t\tLoss: 0.5462 Acc@1: 59.38%\n","\n","=> Training Epoch #436, LR=0.0510\n","| Epoch [436/1080] Iter[  1/463]\t\tLoss: 2.5159 Acc@1: 60.417%\n","| Epoch [436/1080] Iter[ 16/463]\t\tLoss: 2.7797 Acc@1: 54.688%\n","| Epoch [436/1080] Iter[ 31/463]\t\tLoss: 2.9526 Acc@1: 53.931%\n","| Epoch [436/1080] Iter[ 46/463]\t\tLoss: 2.9983 Acc@1: 54.076%\n","\n","| Validation Epoch #436\t\t\tLoss: 0.2678 Acc@1: 59.72%\n","\n","=> Training Epoch #437, LR=0.0510\n","| Epoch [437/1080] Iter[  1/463]\t\tLoss: 3.2748 Acc@1: 43.750%\n","| Epoch [437/1080] Iter[ 16/463]\t\tLoss: 2.7991 Acc@1: 53.516%\n","| Epoch [437/1080] Iter[ 31/463]\t\tLoss: 2.6637 Acc@1: 53.125%\n","| Epoch [437/1080] Iter[ 46/463]\t\tLoss: 2.8216 Acc@1: 53.306%\n","\n","| Validation Epoch #437\t\t\tLoss: 0.0321 Acc@1: 62.42%\n","\n","=> Training Epoch #438, LR=0.0510\n","| Epoch [438/1080] Iter[  1/463]\t\tLoss: 2.8357 Acc@1: 56.250%\n","| Epoch [438/1080] Iter[ 16/463]\t\tLoss: 3.0711 Acc@1: 53.646%\n","| Epoch [438/1080] Iter[ 31/463]\t\tLoss: 2.8814 Acc@1: 53.629%\n","| Epoch [438/1080] Iter[ 46/463]\t\tLoss: 2.8439 Acc@1: 54.212%\n","\n","| Validation Epoch #438\t\t\tLoss: 0.4517 Acc@1: 57.90%\n","\n","=> Training Epoch #439, LR=0.0509\n","| Epoch [439/1080] Iter[  1/463]\t\tLoss: 2.9113 Acc@1: 52.083%\n","| Epoch [439/1080] Iter[ 16/463]\t\tLoss: 2.7547 Acc@1: 53.711%\n","| Epoch [439/1080] Iter[ 31/463]\t\tLoss: 2.8451 Acc@1: 54.234%\n","| Epoch [439/1080] Iter[ 46/463]\t\tLoss: 2.8726 Acc@1: 54.303%\n","\n","| Validation Epoch #439\t\t\tLoss: 0.0095 Acc@1: 58.16%\n","\n","=> Training Epoch #440, LR=0.0509\n","| Epoch [440/1080] Iter[  1/463]\t\tLoss: 2.4803 Acc@1: 58.333%\n","| Epoch [440/1080] Iter[ 16/463]\t\tLoss: 2.6704 Acc@1: 55.990%\n","| Epoch [440/1080] Iter[ 31/463]\t\tLoss: 2.6057 Acc@1: 53.595%\n","| Epoch [440/1080] Iter[ 46/463]\t\tLoss: 2.7306 Acc@1: 54.370%\n","\n","| Validation Epoch #440\t\t\tLoss: 0.0168 Acc@1: 62.88%\n","\n","=> Training Epoch #441, LR=0.0508\n","| Epoch [441/1080] Iter[  1/463]\t\tLoss: 2.6495 Acc@1: 59.375%\n","| Epoch [441/1080] Iter[ 16/463]\t\tLoss: 2.9722 Acc@1: 56.185%\n","| Epoch [441/1080] Iter[ 31/463]\t\tLoss: 2.9028 Acc@1: 54.301%\n","| Epoch [441/1080] Iter[ 46/463]\t\tLoss: 3.0997 Acc@1: 53.668%\n","\n","| Validation Epoch #441\t\t\tLoss: 0.0725 Acc@1: 60.86%\n","\n","=> Training Epoch #442, LR=0.0508\n","| Epoch [442/1080] Iter[  1/463]\t\tLoss: 2.6678 Acc@1: 59.375%\n","| Epoch [442/1080] Iter[ 16/463]\t\tLoss: 2.6671 Acc@1: 54.232%\n","| Epoch [442/1080] Iter[ 31/463]\t\tLoss: 2.8273 Acc@1: 53.797%\n","| Epoch [442/1080] Iter[ 46/463]\t\tLoss: 2.8260 Acc@1: 53.510%\n","\n","| Validation Epoch #442\t\t\tLoss: 0.0897 Acc@1: 62.22%\n","\n","=> Training Epoch #443, LR=0.0508\n","| Epoch [443/1080] Iter[  1/463]\t\tLoss: 2.9190 Acc@1: 51.042%\n","| Epoch [443/1080] Iter[ 16/463]\t\tLoss: 2.5237 Acc@1: 53.451%\n","| Epoch [443/1080] Iter[ 31/463]\t\tLoss: 2.6990 Acc@1: 53.629%\n","| Epoch [443/1080] Iter[ 46/463]\t\tLoss: 2.8878 Acc@1: 53.782%\n","\n","| Validation Epoch #443\t\t\tLoss: 0.0442 Acc@1: 57.02%\n","\n","=> Training Epoch #444, LR=0.0507\n","| Epoch [444/1080] Iter[  1/463]\t\tLoss: 2.5348 Acc@1: 64.583%\n","| Epoch [444/1080] Iter[ 16/463]\t\tLoss: 2.8842 Acc@1: 55.208%\n","| Epoch [444/1080] Iter[ 31/463]\t\tLoss: 2.9788 Acc@1: 53.999%\n","| Epoch [444/1080] Iter[ 46/463]\t\tLoss: 2.8605 Acc@1: 53.487%\n","\n","| Validation Epoch #444\t\t\tLoss: 0.2620 Acc@1: 66.86%\n","\n","=> Training Epoch #445, LR=0.0507\n","| Epoch [445/1080] Iter[  1/463]\t\tLoss: 2.8318 Acc@1: 59.375%\n","| Epoch [445/1080] Iter[ 16/463]\t\tLoss: 2.8070 Acc@1: 54.036%\n","| Epoch [445/1080] Iter[ 31/463]\t\tLoss: 2.9610 Acc@1: 54.603%\n","| Epoch [445/1080] Iter[ 46/463]\t\tLoss: 2.8529 Acc@1: 54.076%\n","\n","| Validation Epoch #445\t\t\tLoss: 0.4013 Acc@1: 65.96%\n","\n","=> Training Epoch #446, LR=0.0506\n","| Epoch [446/1080] Iter[  1/463]\t\tLoss: 2.8483 Acc@1: 47.917%\n","| Epoch [446/1080] Iter[ 16/463]\t\tLoss: 3.1481 Acc@1: 55.273%\n","| Epoch [446/1080] Iter[ 31/463]\t\tLoss: 2.8919 Acc@1: 53.864%\n","| Epoch [446/1080] Iter[ 46/463]\t\tLoss: 2.9879 Acc@1: 54.280%\n","\n","| Validation Epoch #446\t\t\tLoss: 0.6175 Acc@1: 64.14%\n","\n","=> Training Epoch #447, LR=0.0506\n","| Epoch [447/1080] Iter[  1/463]\t\tLoss: 2.6134 Acc@1: 57.292%\n","| Epoch [447/1080] Iter[ 16/463]\t\tLoss: 2.9926 Acc@1: 53.451%\n","| Epoch [447/1080] Iter[ 31/463]\t\tLoss: 2.8263 Acc@1: 53.629%\n","| Epoch [447/1080] Iter[ 46/463]\t\tLoss: 3.1853 Acc@1: 53.623%\n","\n","| Validation Epoch #447\t\t\tLoss: 0.1366 Acc@1: 65.26%\n","\n","=> Training Epoch #448, LR=0.0506\n","| Epoch [448/1080] Iter[  1/463]\t\tLoss: 2.7157 Acc@1: 54.167%\n","| Epoch [448/1080] Iter[ 16/463]\t\tLoss: 2.8264 Acc@1: 54.492%\n","| Epoch [448/1080] Iter[ 31/463]\t\tLoss: 3.1305 Acc@1: 54.671%\n","| Epoch [448/1080] Iter[ 46/463]\t\tLoss: 2.6465 Acc@1: 54.688%\n","\n","| Validation Epoch #448\t\t\tLoss: 0.4636 Acc@1: 61.94%\n","\n","=> Training Epoch #449, LR=0.0505\n","| Epoch [449/1080] Iter[  1/463]\t\tLoss: 2.8463 Acc@1: 55.208%\n","| Epoch [449/1080] Iter[ 16/463]\t\tLoss: 2.8933 Acc@1: 55.143%\n","| Epoch [449/1080] Iter[ 31/463]\t\tLoss: 3.0518 Acc@1: 55.007%\n","| Epoch [449/1080] Iter[ 46/463]\t\tLoss: 3.0237 Acc@1: 54.529%\n","\n","| Validation Epoch #449\t\t\tLoss: 0.5394 Acc@1: 66.66%\n","\n","=> Training Epoch #450, LR=0.0505\n","| Epoch [450/1080] Iter[  1/463]\t\tLoss: 2.9541 Acc@1: 51.042%\n","| Epoch [450/1080] Iter[ 16/463]\t\tLoss: 2.7980 Acc@1: 54.883%\n","| Epoch [450/1080] Iter[ 31/463]\t\tLoss: 2.6897 Acc@1: 54.570%\n","| Epoch [450/1080] Iter[ 46/463]\t\tLoss: 2.9066 Acc@1: 54.189%\n","\n","| Validation Epoch #450\t\t\tLoss: 0.0772 Acc@1: 65.98%\n","\n","=> Training Epoch #451, LR=0.0504\n","| Epoch [451/1080] Iter[  1/463]\t\tLoss: 2.8422 Acc@1: 54.167%\n","| Epoch [451/1080] Iter[ 16/463]\t\tLoss: 2.8975 Acc@1: 54.688%\n","| Epoch [451/1080] Iter[ 31/463]\t\tLoss: 2.5886 Acc@1: 54.536%\n","| Epoch [451/1080] Iter[ 46/463]\t\tLoss: 3.2778 Acc@1: 53.895%\n","\n","| Validation Epoch #451\t\t\tLoss: 0.2733 Acc@1: 63.34%\n","\n","=> Training Epoch #452, LR=0.0504\n","| Epoch [452/1080] Iter[  1/463]\t\tLoss: 3.0303 Acc@1: 54.167%\n","| Epoch [452/1080] Iter[ 16/463]\t\tLoss: 2.9146 Acc@1: 54.557%\n","| Epoch [452/1080] Iter[ 31/463]\t\tLoss: 3.2056 Acc@1: 54.503%\n","| Epoch [452/1080] Iter[ 46/463]\t\tLoss: 2.9622 Acc@1: 53.533%\n","\n","| Validation Epoch #452\t\t\tLoss: 0.0288 Acc@1: 63.78%\n","\n","=> Training Epoch #453, LR=0.0503\n","| Epoch [453/1080] Iter[  1/463]\t\tLoss: 2.8385 Acc@1: 56.250%\n","| Epoch [453/1080] Iter[ 16/463]\t\tLoss: 2.7374 Acc@1: 55.469%\n","| Epoch [453/1080] Iter[ 31/463]\t\tLoss: 2.7723 Acc@1: 54.603%\n","| Epoch [453/1080] Iter[ 46/463]\t\tLoss: 2.9459 Acc@1: 54.461%\n","\n","| Validation Epoch #453\t\t\tLoss: 0.0149 Acc@1: 63.50%\n","\n","=> Training Epoch #454, LR=0.0503\n","| Epoch [454/1080] Iter[  1/463]\t\tLoss: 2.7128 Acc@1: 57.292%\n","| Epoch [454/1080] Iter[ 16/463]\t\tLoss: 2.7630 Acc@1: 56.185%\n","| Epoch [454/1080] Iter[ 31/463]\t\tLoss: 2.7277 Acc@1: 54.503%\n","| Epoch [454/1080] Iter[ 46/463]\t\tLoss: 2.8316 Acc@1: 54.461%\n","\n","| Validation Epoch #454\t\t\tLoss: 0.2488 Acc@1: 66.10%\n","\n","=> Training Epoch #455, LR=0.0503\n","| Epoch [455/1080] Iter[  1/463]\t\tLoss: 2.8697 Acc@1: 54.167%\n","| Epoch [455/1080] Iter[ 16/463]\t\tLoss: 2.9292 Acc@1: 54.427%\n","| Epoch [455/1080] Iter[ 31/463]\t\tLoss: 2.8864 Acc@1: 53.360%\n","| Epoch [455/1080] Iter[ 46/463]\t\tLoss: 2.6456 Acc@1: 54.008%\n","\n","| Validation Epoch #455\t\t\tLoss: 0.0099 Acc@1: 66.72%\n","\n","=> Training Epoch #456, LR=0.0502\n","| Epoch [456/1080] Iter[  1/463]\t\tLoss: 2.4462 Acc@1: 60.417%\n","| Epoch [456/1080] Iter[ 16/463]\t\tLoss: 2.9198 Acc@1: 54.557%\n","| Epoch [456/1080] Iter[ 31/463]\t\tLoss: 2.5404 Acc@1: 55.175%\n","| Epoch [456/1080] Iter[ 46/463]\t\tLoss: 3.1049 Acc@1: 54.189%\n","\n","| Validation Epoch #456\t\t\tLoss: 0.0248 Acc@1: 67.78%\n","\n","=> Training Epoch #457, LR=0.0502\n","| Epoch [457/1080] Iter[  1/463]\t\tLoss: 2.6907 Acc@1: 59.375%\n","| Epoch [457/1080] Iter[ 16/463]\t\tLoss: 2.5919 Acc@1: 54.753%\n","| Epoch [457/1080] Iter[ 31/463]\t\tLoss: 2.7445 Acc@1: 54.872%\n","| Epoch [457/1080] Iter[ 46/463]\t\tLoss: 2.7530 Acc@1: 55.072%\n","\n","| Validation Epoch #457\t\t\tLoss: 0.5681 Acc@1: 61.62%\n","\n","=> Training Epoch #458, LR=0.0501\n","| Epoch [458/1080] Iter[  1/463]\t\tLoss: 2.7132 Acc@1: 58.333%\n","| Epoch [458/1080] Iter[ 16/463]\t\tLoss: 2.7698 Acc@1: 55.013%\n","| Epoch [458/1080] Iter[ 31/463]\t\tLoss: 3.0091 Acc@1: 54.301%\n","| Epoch [458/1080] Iter[ 46/463]\t\tLoss: 2.9727 Acc@1: 53.714%\n","\n","| Validation Epoch #458\t\t\tLoss: 0.3053 Acc@1: 61.34%\n","\n","=> Training Epoch #459, LR=0.0501\n","| Epoch [459/1080] Iter[  1/463]\t\tLoss: 3.2020 Acc@1: 54.167%\n","| Epoch [459/1080] Iter[ 16/463]\t\tLoss: 3.0342 Acc@1: 55.208%\n","| Epoch [459/1080] Iter[ 31/463]\t\tLoss: 2.9148 Acc@1: 55.309%\n","| Epoch [459/1080] Iter[ 46/463]\t\tLoss: 2.8736 Acc@1: 54.484%\n","\n","| Validation Epoch #459\t\t\tLoss: 0.6995 Acc@1: 61.82%\n","\n","=> Training Epoch #460, LR=0.0501\n","| Epoch [460/1080] Iter[  1/463]\t\tLoss: 3.0273 Acc@1: 53.125%\n","| Epoch [460/1080] Iter[ 16/463]\t\tLoss: 3.0303 Acc@1: 54.622%\n","| Epoch [460/1080] Iter[ 31/463]\t\tLoss: 2.9779 Acc@1: 54.906%\n","| Epoch [460/1080] Iter[ 46/463]\t\tLoss: 2.8224 Acc@1: 54.099%\n","\n","| Validation Epoch #460\t\t\tLoss: 0.0497 Acc@1: 62.92%\n","\n","=> Training Epoch #461, LR=0.0500\n","| Epoch [461/1080] Iter[  1/463]\t\tLoss: 2.4599 Acc@1: 61.458%\n","| Epoch [461/1080] Iter[ 16/463]\t\tLoss: 2.7671 Acc@1: 55.990%\n","| Epoch [461/1080] Iter[ 31/463]\t\tLoss: 2.8931 Acc@1: 54.335%\n","| Epoch [461/1080] Iter[ 46/463]\t\tLoss: 2.9259 Acc@1: 54.212%\n","\n","| Validation Epoch #461\t\t\tLoss: 1.2142 Acc@1: 61.26%\n","\n","=> Training Epoch #462, LR=0.0500\n","| Epoch [462/1080] Iter[  1/463]\t\tLoss: 2.8232 Acc@1: 53.125%\n","| Epoch [462/1080] Iter[ 16/463]\t\tLoss: 2.4981 Acc@1: 55.924%\n","| Epoch [462/1080] Iter[ 31/463]\t\tLoss: 2.9963 Acc@1: 54.368%\n","| Epoch [462/1080] Iter[ 46/463]\t\tLoss: 2.9527 Acc@1: 54.484%\n","\n","| Validation Epoch #462\t\t\tLoss: 0.3460 Acc@1: 59.00%\n","\n","=> Training Epoch #463, LR=0.0499\n","| Epoch [463/1080] Iter[  1/463]\t\tLoss: 2.7505 Acc@1: 54.167%\n","| Epoch [463/1080] Iter[ 16/463]\t\tLoss: 3.1609 Acc@1: 52.930%\n","| Epoch [463/1080] Iter[ 31/463]\t\tLoss: 3.1352 Acc@1: 53.159%\n","| Epoch [463/1080] Iter[ 46/463]\t\tLoss: 2.9637 Acc@1: 52.717%\n","\n","| Validation Epoch #463\t\t\tLoss: 0.0529 Acc@1: 58.68%\n","\n","=> Training Epoch #464, LR=0.0499\n","| Epoch [464/1080] Iter[  1/463]\t\tLoss: 3.0008 Acc@1: 58.333%\n","| Epoch [464/1080] Iter[ 16/463]\t\tLoss: 3.0148 Acc@1: 53.581%\n","| Epoch [464/1080] Iter[ 31/463]\t\tLoss: 2.9780 Acc@1: 53.394%\n","| Epoch [464/1080] Iter[ 46/463]\t\tLoss: 3.2127 Acc@1: 53.623%\n","\n","| Validation Epoch #464\t\t\tLoss: 0.0350 Acc@1: 59.36%\n","\n","=> Training Epoch #465, LR=0.0498\n","| Epoch [465/1080] Iter[  1/463]\t\tLoss: 3.0166 Acc@1: 54.167%\n","| Epoch [465/1080] Iter[ 16/463]\t\tLoss: 2.6997 Acc@1: 54.688%\n","| Epoch [465/1080] Iter[ 31/463]\t\tLoss: 2.7826 Acc@1: 53.461%\n","| Epoch [465/1080] Iter[ 46/463]\t\tLoss: 2.8143 Acc@1: 53.963%\n","\n","| Validation Epoch #465\t\t\tLoss: 0.0064 Acc@1: 59.76%\n","\n","=> Training Epoch #466, LR=0.0498\n","| Epoch [466/1080] Iter[  1/463]\t\tLoss: 2.9345 Acc@1: 56.250%\n","| Epoch [466/1080] Iter[ 16/463]\t\tLoss: 2.9828 Acc@1: 55.990%\n","| Epoch [466/1080] Iter[ 31/463]\t\tLoss: 3.2427 Acc@1: 54.671%\n","| Epoch [466/1080] Iter[ 46/463]\t\tLoss: 3.0026 Acc@1: 53.918%\n","\n","| Validation Epoch #466\t\t\tLoss: 0.0027 Acc@1: 59.34%\n","\n","=> Training Epoch #467, LR=0.0498\n","| Epoch [467/1080] Iter[  1/463]\t\tLoss: 3.0723 Acc@1: 51.042%\n","| Epoch [467/1080] Iter[ 16/463]\t\tLoss: 2.9301 Acc@1: 53.060%\n","| Epoch [467/1080] Iter[ 31/463]\t\tLoss: 2.7913 Acc@1: 53.495%\n","| Epoch [467/1080] Iter[ 46/463]\t\tLoss: 2.8447 Acc@1: 53.351%\n","\n","| Validation Epoch #467\t\t\tLoss: 0.1189 Acc@1: 63.14%\n","\n","=> Training Epoch #468, LR=0.0497\n","| Epoch [468/1080] Iter[  1/463]\t\tLoss: 2.8975 Acc@1: 53.125%\n","| Epoch [468/1080] Iter[ 16/463]\t\tLoss: 2.7608 Acc@1: 53.646%\n","| Epoch [468/1080] Iter[ 31/463]\t\tLoss: 3.0610 Acc@1: 53.629%\n","| Epoch [468/1080] Iter[ 46/463]\t\tLoss: 2.8267 Acc@1: 53.578%\n","\n","| Validation Epoch #468\t\t\tLoss: 1.3405 Acc@1: 60.76%\n","\n","=> Training Epoch #469, LR=0.0497\n","| Epoch [469/1080] Iter[  1/463]\t\tLoss: 2.8680 Acc@1: 56.250%\n","| Epoch [469/1080] Iter[ 16/463]\t\tLoss: 2.7419 Acc@1: 55.599%\n","| Epoch [469/1080] Iter[ 31/463]\t\tLoss: 3.1957 Acc@1: 55.175%\n","| Epoch [469/1080] Iter[ 46/463]\t\tLoss: 3.0381 Acc@1: 54.303%\n","\n","| Validation Epoch #469\t\t\tLoss: 0.3570 Acc@1: 62.18%\n","\n","=> Training Epoch #470, LR=0.0496\n","| Epoch [470/1080] Iter[  1/463]\t\tLoss: 2.7339 Acc@1: 64.583%\n","| Epoch [470/1080] Iter[ 16/463]\t\tLoss: 2.9730 Acc@1: 54.557%\n","| Epoch [470/1080] Iter[ 31/463]\t\tLoss: 2.8372 Acc@1: 54.167%\n","| Epoch [470/1080] Iter[ 46/463]\t\tLoss: 2.7444 Acc@1: 54.212%\n","\n","| Validation Epoch #470\t\t\tLoss: 0.5462 Acc@1: 59.90%\n","\n","=> Training Epoch #471, LR=0.0496\n","| Epoch [471/1080] Iter[  1/463]\t\tLoss: 3.0815 Acc@1: 53.125%\n","| Epoch [471/1080] Iter[ 16/463]\t\tLoss: 2.6623 Acc@1: 53.255%\n","| Epoch [471/1080] Iter[ 31/463]\t\tLoss: 3.0173 Acc@1: 53.159%\n","| Epoch [471/1080] Iter[ 46/463]\t\tLoss: 2.8386 Acc@1: 54.053%\n","\n","| Validation Epoch #471\t\t\tLoss: 0.3876 Acc@1: 63.66%\n","\n","=> Training Epoch #472, LR=0.0495\n","| Epoch [472/1080] Iter[  1/463]\t\tLoss: 2.5465 Acc@1: 59.375%\n","| Epoch [472/1080] Iter[ 16/463]\t\tLoss: 3.0627 Acc@1: 53.320%\n","| Epoch [472/1080] Iter[ 31/463]\t\tLoss: 2.8939 Acc@1: 54.099%\n","| Epoch [472/1080] Iter[ 46/463]\t\tLoss: 3.0532 Acc@1: 54.484%\n","\n","| Validation Epoch #472\t\t\tLoss: 0.0065 Acc@1: 63.56%\n","\n","=> Training Epoch #473, LR=0.0495\n","| Epoch [473/1080] Iter[  1/463]\t\tLoss: 2.8838 Acc@1: 56.250%\n","| Epoch [473/1080] Iter[ 16/463]\t\tLoss: 2.8466 Acc@1: 53.841%\n","| Epoch [473/1080] Iter[ 31/463]\t\tLoss: 2.8513 Acc@1: 53.797%\n","| Epoch [473/1080] Iter[ 46/463]\t\tLoss: 3.1146 Acc@1: 53.442%\n","\n","| Validation Epoch #473\t\t\tLoss: 0.0271 Acc@1: 67.72%\n","\n","=> Training Epoch #474, LR=0.0495\n","| Epoch [474/1080] Iter[  1/463]\t\tLoss: 2.9294 Acc@1: 56.250%\n","| Epoch [474/1080] Iter[ 16/463]\t\tLoss: 3.1347 Acc@1: 55.729%\n","| Epoch [474/1080] Iter[ 31/463]\t\tLoss: 2.8979 Acc@1: 54.570%\n","| Epoch [474/1080] Iter[ 46/463]\t\tLoss: 2.9662 Acc@1: 54.053%\n","\n","| Validation Epoch #474\t\t\tLoss: 0.2497 Acc@1: 58.36%\n","\n","=> Training Epoch #475, LR=0.0494\n","| Epoch [475/1080] Iter[  1/463]\t\tLoss: 2.8266 Acc@1: 57.292%\n","| Epoch [475/1080] Iter[ 16/463]\t\tLoss: 3.1982 Acc@1: 53.516%\n","| Epoch [475/1080] Iter[ 31/463]\t\tLoss: 3.1930 Acc@1: 53.091%\n","| Epoch [475/1080] Iter[ 46/463]\t\tLoss: 2.7927 Acc@1: 53.193%\n","\n","| Validation Epoch #475\t\t\tLoss: 0.0606 Acc@1: 60.60%\n","\n","=> Training Epoch #476, LR=0.0494\n","| Epoch [476/1080] Iter[  1/463]\t\tLoss: 3.0399 Acc@1: 51.042%\n","| Epoch [476/1080] Iter[ 16/463]\t\tLoss: 3.1373 Acc@1: 54.232%\n","| Epoch [476/1080] Iter[ 31/463]\t\tLoss: 2.8471 Acc@1: 55.007%\n","| Epoch [476/1080] Iter[ 46/463]\t\tLoss: 2.8694 Acc@1: 54.869%\n","\n","| Validation Epoch #476\t\t\tLoss: 0.0462 Acc@1: 61.60%\n","\n","=> Training Epoch #477, LR=0.0493\n","| Epoch [477/1080] Iter[  1/463]\t\tLoss: 2.6183 Acc@1: 64.583%\n","| Epoch [477/1080] Iter[ 16/463]\t\tLoss: 2.7642 Acc@1: 56.510%\n","| Epoch [477/1080] Iter[ 31/463]\t\tLoss: 2.4867 Acc@1: 55.208%\n","| Epoch [477/1080] Iter[ 46/463]\t\tLoss: 2.8703 Acc@1: 54.506%\n","\n","| Validation Epoch #477\t\t\tLoss: 0.4381 Acc@1: 57.48%\n","\n","=> Training Epoch #478, LR=0.0493\n","| Epoch [478/1080] Iter[  1/463]\t\tLoss: 2.7719 Acc@1: 60.417%\n","| Epoch [478/1080] Iter[ 16/463]\t\tLoss: 2.6194 Acc@1: 54.232%\n","| Epoch [478/1080] Iter[ 31/463]\t\tLoss: 3.0772 Acc@1: 55.007%\n","| Epoch [478/1080] Iter[ 46/463]\t\tLoss: 3.0192 Acc@1: 54.869%\n","\n","| Validation Epoch #478\t\t\tLoss: 0.0146 Acc@1: 62.32%\n","\n","=> Training Epoch #479, LR=0.0492\n","| Epoch [479/1080] Iter[  1/463]\t\tLoss: 2.8892 Acc@1: 56.250%\n","| Epoch [479/1080] Iter[ 16/463]\t\tLoss: 2.8728 Acc@1: 54.818%\n","| Epoch [479/1080] Iter[ 31/463]\t\tLoss: 2.7499 Acc@1: 54.133%\n","| Epoch [479/1080] Iter[ 46/463]\t\tLoss: 2.9400 Acc@1: 54.370%\n","\n","| Validation Epoch #479\t\t\tLoss: 0.0010 Acc@1: 59.30%\n","| New Samples 30049\n","\n","=> Training Epoch #480, LR=0.0492\n","| Epoch [480/1080] Iter[  1/516]\t\tLoss: 3.0510 Acc@1: 50.000%\n","| Epoch [480/1080] Iter[ 16/516]\t\tLoss: 2.8371 Acc@1: 55.273%\n","| Epoch [480/1080] Iter[ 31/516]\t\tLoss: 3.0186 Acc@1: 54.637%\n","| Epoch [480/1080] Iter[ 46/516]\t\tLoss: 2.9089 Acc@1: 54.506%\n","\n","| Validation Epoch #480\t\t\tLoss: 0.0856 Acc@1: 59.06%\n","\n","=> Training Epoch #481, LR=0.0491\n","| Epoch [481/1080] Iter[  1/516]\t\tLoss: 2.7321 Acc@1: 53.125%\n","| Epoch [481/1080] Iter[ 16/516]\t\tLoss: 3.0172 Acc@1: 53.906%\n","| Epoch [481/1080] Iter[ 31/516]\t\tLoss: 2.8775 Acc@1: 53.965%\n","| Epoch [481/1080] Iter[ 46/516]\t\tLoss: 2.9322 Acc@1: 54.461%\n","\n","| Validation Epoch #481\t\t\tLoss: 0.3495 Acc@1: 62.86%\n","\n","=> Training Epoch #482, LR=0.0491\n","| Epoch [482/1080] Iter[  1/516]\t\tLoss: 2.7337 Acc@1: 57.292%\n","| Epoch [482/1080] Iter[ 16/516]\t\tLoss: 2.8090 Acc@1: 56.250%\n","| Epoch [482/1080] Iter[ 31/516]\t\tLoss: 3.1986 Acc@1: 55.007%\n","| Epoch [482/1080] Iter[ 46/516]\t\tLoss: 3.0447 Acc@1: 54.167%\n","\n","| Validation Epoch #482\t\t\tLoss: 0.1449 Acc@1: 66.00%\n","\n","=> Training Epoch #483, LR=0.0491\n","| Epoch [483/1080] Iter[  1/516]\t\tLoss: 2.8147 Acc@1: 56.250%\n","| Epoch [483/1080] Iter[ 16/516]\t\tLoss: 2.7320 Acc@1: 54.622%\n","| Epoch [483/1080] Iter[ 31/516]\t\tLoss: 2.7980 Acc@1: 54.200%\n","| Epoch [483/1080] Iter[ 46/516]\t\tLoss: 3.3052 Acc@1: 53.442%\n","\n","| Validation Epoch #483\t\t\tLoss: 0.0346 Acc@1: 64.94%\n","\n","=> Training Epoch #484, LR=0.0490\n","| Epoch [484/1080] Iter[  1/516]\t\tLoss: 2.9364 Acc@1: 53.125%\n","| Epoch [484/1080] Iter[ 16/516]\t\tLoss: 2.6603 Acc@1: 54.883%\n","| Epoch [484/1080] Iter[ 31/516]\t\tLoss: 2.9638 Acc@1: 54.805%\n","| Epoch [484/1080] Iter[ 46/516]\t\tLoss: 2.9282 Acc@1: 54.121%\n","\n","| Validation Epoch #484\t\t\tLoss: 0.4048 Acc@1: 65.80%\n","\n","=> Training Epoch #485, LR=0.0490\n","| Epoch [485/1080] Iter[  1/516]\t\tLoss: 2.9500 Acc@1: 53.125%\n","| Epoch [485/1080] Iter[ 16/516]\t\tLoss: 3.1103 Acc@1: 53.841%\n","| Epoch [485/1080] Iter[ 31/516]\t\tLoss: 2.6838 Acc@1: 52.789%\n","| Epoch [485/1080] Iter[ 46/516]\t\tLoss: 2.9107 Acc@1: 53.306%\n","\n","| Validation Epoch #485\t\t\tLoss: 0.0115 Acc@1: 61.78%\n","\n","=> Training Epoch #486, LR=0.0489\n","| Epoch [486/1080] Iter[  1/516]\t\tLoss: 2.4369 Acc@1: 64.583%\n","| Epoch [486/1080] Iter[ 16/516]\t\tLoss: 3.1072 Acc@1: 53.776%\n","| Epoch [486/1080] Iter[ 31/516]\t\tLoss: 2.4370 Acc@1: 54.536%\n","| Epoch [486/1080] Iter[ 46/516]\t\tLoss: 2.9131 Acc@1: 53.668%\n","\n","| Validation Epoch #486\t\t\tLoss: 0.0232 Acc@1: 66.54%\n","\n","=> Training Epoch #487, LR=0.0489\n","| Epoch [487/1080] Iter[  1/516]\t\tLoss: 3.0830 Acc@1: 44.792%\n","| Epoch [487/1080] Iter[ 16/516]\t\tLoss: 2.8352 Acc@1: 53.581%\n","| Epoch [487/1080] Iter[ 31/516]\t\tLoss: 2.7564 Acc@1: 53.394%\n","| Epoch [487/1080] Iter[ 46/516]\t\tLoss: 2.9481 Acc@1: 53.578%\n","\n","| Validation Epoch #487\t\t\tLoss: 0.7019 Acc@1: 60.28%\n","\n","=> Training Epoch #488, LR=0.0488\n","| Epoch [488/1080] Iter[  1/516]\t\tLoss: 2.9248 Acc@1: 53.125%\n","| Epoch [488/1080] Iter[ 16/516]\t\tLoss: 2.8444 Acc@1: 53.646%\n","| Epoch [488/1080] Iter[ 31/516]\t\tLoss: 2.4656 Acc@1: 54.536%\n","| Epoch [488/1080] Iter[ 46/516]\t\tLoss: 3.0461 Acc@1: 53.895%\n","\n","| Validation Epoch #488\t\t\tLoss: 1.0848 Acc@1: 61.64%\n","\n","=> Training Epoch #489, LR=0.0488\n","| Epoch [489/1080] Iter[  1/516]\t\tLoss: 3.1118 Acc@1: 51.042%\n","| Epoch [489/1080] Iter[ 16/516]\t\tLoss: 2.7024 Acc@1: 53.451%\n","| Epoch [489/1080] Iter[ 31/516]\t\tLoss: 2.9090 Acc@1: 53.999%\n","| Epoch [489/1080] Iter[ 46/516]\t\tLoss: 3.0698 Acc@1: 53.601%\n","\n","| Validation Epoch #489\t\t\tLoss: 0.1544 Acc@1: 69.02%\n","| Saving Best model...\t\t\tTop1 = 69.02%\n","\n","=> Training Epoch #490, LR=0.0488\n","| Epoch [490/1080] Iter[  1/516]\t\tLoss: 2.7365 Acc@1: 57.292%\n","| Epoch [490/1080] Iter[ 16/516]\t\tLoss: 2.7810 Acc@1: 53.776%\n","| Epoch [490/1080] Iter[ 31/516]\t\tLoss: 2.7617 Acc@1: 53.763%\n","| Epoch [490/1080] Iter[ 46/516]\t\tLoss: 2.6208 Acc@1: 54.257%\n","\n","| Validation Epoch #490\t\t\tLoss: 0.0321 Acc@1: 66.52%\n","\n","=> Training Epoch #491, LR=0.0487\n","| Epoch [491/1080] Iter[  1/516]\t\tLoss: 2.8004 Acc@1: 54.167%\n","| Epoch [491/1080] Iter[ 16/516]\t\tLoss: 2.9875 Acc@1: 55.469%\n","| Epoch [491/1080] Iter[ 31/516]\t\tLoss: 2.7974 Acc@1: 55.141%\n","| Epoch [491/1080] Iter[ 46/516]\t\tLoss: 3.0387 Acc@1: 54.008%\n","\n","| Validation Epoch #491\t\t\tLoss: 0.1819 Acc@1: 63.00%\n","\n","=> Training Epoch #492, LR=0.0487\n","| Epoch [492/1080] Iter[  1/516]\t\tLoss: 2.6204 Acc@1: 59.375%\n","| Epoch [492/1080] Iter[ 16/516]\t\tLoss: 2.6862 Acc@1: 55.273%\n","| Epoch [492/1080] Iter[ 31/516]\t\tLoss: 3.1246 Acc@1: 54.772%\n","| Epoch [492/1080] Iter[ 46/516]\t\tLoss: 2.6940 Acc@1: 54.552%\n","\n","| Validation Epoch #492\t\t\tLoss: 0.0364 Acc@1: 65.88%\n","\n","=> Training Epoch #493, LR=0.0486\n","| Epoch [493/1080] Iter[  1/516]\t\tLoss: 2.9067 Acc@1: 53.125%\n","| Epoch [493/1080] Iter[ 16/516]\t\tLoss: 2.8939 Acc@1: 55.208%\n","| Epoch [493/1080] Iter[ 31/516]\t\tLoss: 3.0421 Acc@1: 55.007%\n","| Epoch [493/1080] Iter[ 46/516]\t\tLoss: 2.8767 Acc@1: 54.801%\n","\n","| Validation Epoch #493\t\t\tLoss: 0.4027 Acc@1: 61.46%\n","\n","=> Training Epoch #494, LR=0.0486\n","| Epoch [494/1080] Iter[  1/516]\t\tLoss: 3.2033 Acc@1: 44.792%\n","| Epoch [494/1080] Iter[ 16/516]\t\tLoss: 2.8671 Acc@1: 55.143%\n","| Epoch [494/1080] Iter[ 31/516]\t\tLoss: 2.8669 Acc@1: 54.402%\n","| Epoch [494/1080] Iter[ 46/516]\t\tLoss: 3.0955 Acc@1: 54.393%\n","\n","| Validation Epoch #494\t\t\tLoss: 0.7250 Acc@1: 65.36%\n","\n","=> Training Epoch #495, LR=0.0485\n","| Epoch [495/1080] Iter[  1/516]\t\tLoss: 3.0679 Acc@1: 50.000%\n","| Epoch [495/1080] Iter[ 16/516]\t\tLoss: 2.7546 Acc@1: 55.859%\n","| Epoch [495/1080] Iter[ 31/516]\t\tLoss: 2.9163 Acc@1: 55.074%\n","| Epoch [495/1080] Iter[ 46/516]\t\tLoss: 3.0502 Acc@1: 53.918%\n","\n","| Validation Epoch #495\t\t\tLoss: 0.6743 Acc@1: 64.52%\n","\n","=> Training Epoch #496, LR=0.0485\n","| Epoch [496/1080] Iter[  1/516]\t\tLoss: 2.6593 Acc@1: 58.333%\n","| Epoch [496/1080] Iter[ 16/516]\t\tLoss: 3.1798 Acc@1: 54.688%\n","| Epoch [496/1080] Iter[ 31/516]\t\tLoss: 3.2248 Acc@1: 53.763%\n","| Epoch [496/1080] Iter[ 46/516]\t\tLoss: 3.0569 Acc@1: 53.374%\n","\n","| Validation Epoch #496\t\t\tLoss: 0.1759 Acc@1: 58.40%\n","\n","=> Training Epoch #497, LR=0.0484\n","| Epoch [497/1080] Iter[  1/516]\t\tLoss: 2.7838 Acc@1: 55.208%\n","| Epoch [497/1080] Iter[ 16/516]\t\tLoss: 2.8949 Acc@1: 54.102%\n","| Epoch [497/1080] Iter[ 31/516]\t\tLoss: 2.9792 Acc@1: 54.167%\n","| Epoch [497/1080] Iter[ 46/516]\t\tLoss: 2.7140 Acc@1: 53.827%\n","\n","| Validation Epoch #497\t\t\tLoss: 0.3706 Acc@1: 66.34%\n","\n","=> Training Epoch #498, LR=0.0484\n","| Epoch [498/1080] Iter[  1/516]\t\tLoss: 2.8491 Acc@1: 52.083%\n","| Epoch [498/1080] Iter[ 16/516]\t\tLoss: 2.9245 Acc@1: 54.232%\n","| Epoch [498/1080] Iter[ 31/516]\t\tLoss: 2.9708 Acc@1: 54.335%\n","| Epoch [498/1080] Iter[ 46/516]\t\tLoss: 3.2109 Acc@1: 53.736%\n","\n","| Validation Epoch #498\t\t\tLoss: 0.3840 Acc@1: 66.28%\n","\n","=> Training Epoch #499, LR=0.0483\n","| Epoch [499/1080] Iter[  1/516]\t\tLoss: 2.4852 Acc@1: 66.667%\n","| Epoch [499/1080] Iter[ 16/516]\t\tLoss: 2.7041 Acc@1: 54.557%\n","| Epoch [499/1080] Iter[ 31/516]\t\tLoss: 2.7301 Acc@1: 54.469%\n","| Epoch [499/1080] Iter[ 46/516]\t\tLoss: 3.0236 Acc@1: 54.212%\n","\n","| Validation Epoch #499\t\t\tLoss: 0.1001 Acc@1: 64.60%\n","\n","=> Training Epoch #500, LR=0.0483\n","| Epoch [500/1080] Iter[  1/516]\t\tLoss: 3.0503 Acc@1: 51.042%\n","| Epoch [500/1080] Iter[ 16/516]\t\tLoss: 3.0160 Acc@1: 54.232%\n","| Epoch [500/1080] Iter[ 31/516]\t\tLoss: 2.7620 Acc@1: 53.058%\n","| Epoch [500/1080] Iter[ 46/516]\t\tLoss: 2.4586 Acc@1: 53.759%\n","\n","| Validation Epoch #500\t\t\tLoss: 1.0774 Acc@1: 58.90%\n","\n","=> Training Epoch #501, LR=0.0483\n","| Epoch [501/1080] Iter[  1/516]\t\tLoss: 2.7172 Acc@1: 57.292%\n","| Epoch [501/1080] Iter[ 16/516]\t\tLoss: 2.9944 Acc@1: 51.823%\n","| Epoch [501/1080] Iter[ 31/516]\t\tLoss: 3.1754 Acc@1: 53.024%\n","| Epoch [501/1080] Iter[ 46/516]\t\tLoss: 3.1881 Acc@1: 53.216%\n","\n","| Validation Epoch #501\t\t\tLoss: 1.7406 Acc@1: 56.28%\n","\n","=> Training Epoch #502, LR=0.0482\n","| Epoch [502/1080] Iter[  1/516]\t\tLoss: 3.0414 Acc@1: 51.042%\n","| Epoch [502/1080] Iter[ 16/516]\t\tLoss: 3.0441 Acc@1: 53.581%\n","| Epoch [502/1080] Iter[ 31/516]\t\tLoss: 2.7947 Acc@1: 54.099%\n","| Epoch [502/1080] Iter[ 46/516]\t\tLoss: 2.9762 Acc@1: 53.872%\n","\n","| Validation Epoch #502\t\t\tLoss: 0.0267 Acc@1: 67.14%\n","\n","=> Training Epoch #503, LR=0.0482\n","| Epoch [503/1080] Iter[  1/516]\t\tLoss: 3.2149 Acc@1: 51.042%\n","| Epoch [503/1080] Iter[ 16/516]\t\tLoss: 2.9239 Acc@1: 55.273%\n","| Epoch [503/1080] Iter[ 31/516]\t\tLoss: 2.8197 Acc@1: 54.805%\n","| Epoch [503/1080] Iter[ 46/516]\t\tLoss: 3.0344 Acc@1: 54.325%\n","\n","| Validation Epoch #503\t\t\tLoss: 0.0153 Acc@1: 64.08%\n","\n","=> Training Epoch #504, LR=0.0481\n","| Epoch [504/1080] Iter[  1/516]\t\tLoss: 3.1470 Acc@1: 47.917%\n","| Epoch [504/1080] Iter[ 16/516]\t\tLoss: 2.6556 Acc@1: 54.622%\n","| Epoch [504/1080] Iter[ 31/516]\t\tLoss: 2.9028 Acc@1: 53.159%\n","| Epoch [504/1080] Iter[ 46/516]\t\tLoss: 2.8104 Acc@1: 53.442%\n","\n","| Validation Epoch #504\t\t\tLoss: 0.1553 Acc@1: 53.14%\n","\n","=> Training Epoch #505, LR=0.0481\n","| Epoch [505/1080] Iter[  1/516]\t\tLoss: 2.7753 Acc@1: 59.375%\n","| Epoch [505/1080] Iter[ 16/516]\t\tLoss: 2.7595 Acc@1: 54.427%\n","| Epoch [505/1080] Iter[ 31/516]\t\tLoss: 3.1959 Acc@1: 54.032%\n","| Epoch [505/1080] Iter[ 46/516]\t\tLoss: 3.0572 Acc@1: 54.031%\n","\n","| Validation Epoch #505\t\t\tLoss: 0.2474 Acc@1: 61.98%\n","\n","=> Training Epoch #506, LR=0.0480\n","| Epoch [506/1080] Iter[  1/516]\t\tLoss: 2.8283 Acc@1: 55.208%\n","| Epoch [506/1080] Iter[ 16/516]\t\tLoss: 2.4721 Acc@1: 54.557%\n","| Epoch [506/1080] Iter[ 31/516]\t\tLoss: 2.9166 Acc@1: 54.906%\n","| Epoch [506/1080] Iter[ 46/516]\t\tLoss: 3.0119 Acc@1: 54.121%\n","\n","| Validation Epoch #506\t\t\tLoss: 0.0216 Acc@1: 64.96%\n","\n","=> Training Epoch #507, LR=0.0480\n","| Epoch [507/1080] Iter[  1/516]\t\tLoss: 3.2277 Acc@1: 47.917%\n","| Epoch [507/1080] Iter[ 16/516]\t\tLoss: 3.0142 Acc@1: 54.232%\n","| Epoch [507/1080] Iter[ 31/516]\t\tLoss: 3.3620 Acc@1: 53.965%\n","| Epoch [507/1080] Iter[ 46/516]\t\tLoss: 3.3468 Acc@1: 53.487%\n","\n","| Validation Epoch #507\t\t\tLoss: 0.0652 Acc@1: 63.98%\n","\n","=> Training Epoch #508, LR=0.0479\n","| Epoch [508/1080] Iter[  1/516]\t\tLoss: 2.9830 Acc@1: 51.042%\n","| Epoch [508/1080] Iter[ 16/516]\t\tLoss: 2.7241 Acc@1: 54.818%\n","| Epoch [508/1080] Iter[ 31/516]\t\tLoss: 2.7323 Acc@1: 54.872%\n","| Epoch [508/1080] Iter[ 46/516]\t\tLoss: 2.7836 Acc@1: 55.050%\n","\n","| Validation Epoch #508\t\t\tLoss: 0.0072 Acc@1: 63.86%\n","\n","=> Training Epoch #509, LR=0.0479\n","| Epoch [509/1080] Iter[  1/516]\t\tLoss: 2.9176 Acc@1: 54.167%\n","| Epoch [509/1080] Iter[ 16/516]\t\tLoss: 2.9628 Acc@1: 54.297%\n","| Epoch [509/1080] Iter[ 31/516]\t\tLoss: 2.8824 Acc@1: 54.200%\n","| Epoch [509/1080] Iter[ 46/516]\t\tLoss: 2.7158 Acc@1: 53.646%\n","\n","| Validation Epoch #509\t\t\tLoss: 0.4078 Acc@1: 61.58%\n","\n","=> Training Epoch #510, LR=0.0478\n","| Epoch [510/1080] Iter[  1/516]\t\tLoss: 2.7344 Acc@1: 58.333%\n","| Epoch [510/1080] Iter[ 16/516]\t\tLoss: 2.7719 Acc@1: 53.841%\n","| Epoch [510/1080] Iter[ 31/516]\t\tLoss: 2.8562 Acc@1: 53.461%\n","| Epoch [510/1080] Iter[ 46/516]\t\tLoss: 2.6736 Acc@1: 53.623%\n","\n","| Validation Epoch #510\t\t\tLoss: 0.1261 Acc@1: 57.62%\n","\n","=> Training Epoch #511, LR=0.0478\n","| Epoch [511/1080] Iter[  1/516]\t\tLoss: 2.8636 Acc@1: 57.292%\n","| Epoch [511/1080] Iter[ 16/516]\t\tLoss: 2.8488 Acc@1: 55.794%\n","| Epoch [511/1080] Iter[ 31/516]\t\tLoss: 2.8564 Acc@1: 54.704%\n","| Epoch [511/1080] Iter[ 46/516]\t\tLoss: 2.7152 Acc@1: 53.850%\n","\n","| Validation Epoch #511\t\t\tLoss: 0.3196 Acc@1: 62.76%\n","\n","=> Training Epoch #512, LR=0.0478\n","| Epoch [512/1080] Iter[  1/516]\t\tLoss: 3.1137 Acc@1: 45.833%\n","| Epoch [512/1080] Iter[ 16/516]\t\tLoss: 2.7071 Acc@1: 54.232%\n","| Epoch [512/1080] Iter[ 31/516]\t\tLoss: 2.8737 Acc@1: 54.200%\n","| Epoch [512/1080] Iter[ 46/516]\t\tLoss: 3.0760 Acc@1: 54.121%\n","\n","| Validation Epoch #512\t\t\tLoss: 0.3251 Acc@1: 65.64%\n","\n","=> Training Epoch #513, LR=0.0477\n","| Epoch [513/1080] Iter[  1/516]\t\tLoss: 2.5862 Acc@1: 61.458%\n","| Epoch [513/1080] Iter[ 16/516]\t\tLoss: 2.7385 Acc@1: 54.688%\n","| Epoch [513/1080] Iter[ 31/516]\t\tLoss: 2.8353 Acc@1: 54.469%\n","| Epoch [513/1080] Iter[ 46/516]\t\tLoss: 3.0367 Acc@1: 54.393%\n","\n","| Validation Epoch #513\t\t\tLoss: 0.3368 Acc@1: 63.12%\n","\n","=> Training Epoch #514, LR=0.0477\n","| Epoch [514/1080] Iter[  1/516]\t\tLoss: 2.8360 Acc@1: 54.167%\n","| Epoch [514/1080] Iter[ 16/516]\t\tLoss: 2.9249 Acc@1: 52.214%\n","| Epoch [514/1080] Iter[ 31/516]\t\tLoss: 2.6419 Acc@1: 53.024%\n","| Epoch [514/1080] Iter[ 46/516]\t\tLoss: 3.0190 Acc@1: 53.284%\n","\n","| Validation Epoch #514\t\t\tLoss: 0.4101 Acc@1: 66.96%\n","\n","=> Training Epoch #515, LR=0.0476\n","| Epoch [515/1080] Iter[  1/516]\t\tLoss: 3.0554 Acc@1: 52.083%\n","| Epoch [515/1080] Iter[ 16/516]\t\tLoss: 2.8257 Acc@1: 53.776%\n","| Epoch [515/1080] Iter[ 31/516]\t\tLoss: 3.0443 Acc@1: 53.562%\n","| Epoch [515/1080] Iter[ 46/516]\t\tLoss: 2.8660 Acc@1: 53.691%\n","\n","| Validation Epoch #515\t\t\tLoss: 0.0237 Acc@1: 59.06%\n","\n","=> Training Epoch #516, LR=0.0476\n","| Epoch [516/1080] Iter[  1/516]\t\tLoss: 3.1650 Acc@1: 53.125%\n","| Epoch [516/1080] Iter[ 16/516]\t\tLoss: 2.4028 Acc@1: 53.971%\n","| Epoch [516/1080] Iter[ 31/516]\t\tLoss: 2.8263 Acc@1: 53.696%\n","| Epoch [516/1080] Iter[ 46/516]\t\tLoss: 2.8752 Acc@1: 53.623%\n","\n","| Validation Epoch #516\t\t\tLoss: 0.5770 Acc@1: 61.96%\n","\n","=> Training Epoch #517, LR=0.0475\n","| Epoch [517/1080] Iter[  1/516]\t\tLoss: 3.2502 Acc@1: 44.792%\n","| Epoch [517/1080] Iter[ 16/516]\t\tLoss: 3.0331 Acc@1: 54.492%\n","| Epoch [517/1080] Iter[ 31/516]\t\tLoss: 2.8697 Acc@1: 53.226%\n","| Epoch [517/1080] Iter[ 46/516]\t\tLoss: 2.8687 Acc@1: 53.623%\n","\n","| Validation Epoch #517\t\t\tLoss: 0.3109 Acc@1: 63.58%\n","\n","=> Training Epoch #518, LR=0.0475\n","| Epoch [518/1080] Iter[  1/516]\t\tLoss: 2.6900 Acc@1: 64.583%\n","| Epoch [518/1080] Iter[ 16/516]\t\tLoss: 3.0289 Acc@1: 57.878%\n","| Epoch [518/1080] Iter[ 31/516]\t\tLoss: 2.8003 Acc@1: 55.208%\n","| Epoch [518/1080] Iter[ 46/516]\t\tLoss: 2.8374 Acc@1: 54.484%\n","\n","| Validation Epoch #518\t\t\tLoss: 0.1366 Acc@1: 62.40%\n","\n","=> Training Epoch #519, LR=0.0474\n","| Epoch [519/1080] Iter[  1/516]\t\tLoss: 2.9572 Acc@1: 54.167%\n","| Epoch [519/1080] Iter[ 16/516]\t\tLoss: 2.9171 Acc@1: 54.818%\n","| Epoch [519/1080] Iter[ 31/516]\t\tLoss: 3.2560 Acc@1: 53.696%\n","| Epoch [519/1080] Iter[ 46/516]\t\tLoss: 2.5470 Acc@1: 53.555%\n","\n","| Validation Epoch #519\t\t\tLoss: 2.5629 Acc@1: 58.74%\n","\n","=> Training Epoch #520, LR=0.0474\n","| Epoch [520/1080] Iter[  1/516]\t\tLoss: 2.9856 Acc@1: 50.000%\n","| Epoch [520/1080] Iter[ 16/516]\t\tLoss: 3.0460 Acc@1: 52.018%\n","| Epoch [520/1080] Iter[ 31/516]\t\tLoss: 2.7816 Acc@1: 53.999%\n","| Epoch [520/1080] Iter[ 46/516]\t\tLoss: 2.8794 Acc@1: 53.329%\n","\n","| Validation Epoch #520\t\t\tLoss: 0.0040 Acc@1: 61.34%\n","\n","=> Training Epoch #521, LR=0.0473\n","| Epoch [521/1080] Iter[  1/516]\t\tLoss: 3.0996 Acc@1: 50.000%\n","| Epoch [521/1080] Iter[ 16/516]\t\tLoss: 2.8993 Acc@1: 52.865%\n","| Epoch [521/1080] Iter[ 31/516]\t\tLoss: 2.9879 Acc@1: 53.763%\n","| Epoch [521/1080] Iter[ 46/516]\t\tLoss: 2.7559 Acc@1: 54.257%\n","\n","| Validation Epoch #521\t\t\tLoss: 0.0130 Acc@1: 64.24%\n","\n","=> Training Epoch #522, LR=0.0473\n","| Epoch [522/1080] Iter[  1/516]\t\tLoss: 2.9878 Acc@1: 52.083%\n","| Epoch [522/1080] Iter[ 16/516]\t\tLoss: 2.8665 Acc@1: 56.250%\n","| Epoch [522/1080] Iter[ 31/516]\t\tLoss: 3.1383 Acc@1: 54.402%\n","| Epoch [522/1080] Iter[ 46/516]\t\tLoss: 2.9327 Acc@1: 53.736%\n","\n","| Validation Epoch #522\t\t\tLoss: 0.0177 Acc@1: 64.48%\n","\n","=> Training Epoch #523, LR=0.0472\n","| Epoch [523/1080] Iter[  1/516]\t\tLoss: 2.6345 Acc@1: 61.458%\n","| Epoch [523/1080] Iter[ 16/516]\t\tLoss: 2.8835 Acc@1: 53.320%\n","| Epoch [523/1080] Iter[ 31/516]\t\tLoss: 2.9980 Acc@1: 53.965%\n","| Epoch [523/1080] Iter[ 46/516]\t\tLoss: 3.0159 Acc@1: 53.578%\n","\n","| Validation Epoch #523\t\t\tLoss: 0.2141 Acc@1: 64.34%\n","\n","=> Training Epoch #524, LR=0.0472\n","| Epoch [524/1080] Iter[  1/516]\t\tLoss: 2.9342 Acc@1: 53.125%\n","| Epoch [524/1080] Iter[ 16/516]\t\tLoss: 3.0961 Acc@1: 54.688%\n","| Epoch [524/1080] Iter[ 31/516]\t\tLoss: 2.7936 Acc@1: 54.402%\n","| Epoch [524/1080] Iter[ 46/516]\t\tLoss: 2.6908 Acc@1: 54.076%\n","\n","| Validation Epoch #524\t\t\tLoss: 0.0661 Acc@1: 60.68%\n","\n","=> Training Epoch #525, LR=0.0471\n","| Epoch [525/1080] Iter[  1/516]\t\tLoss: 3.2042 Acc@1: 47.917%\n","| Epoch [525/1080] Iter[ 16/516]\t\tLoss: 2.7801 Acc@1: 54.297%\n","| Epoch [525/1080] Iter[ 31/516]\t\tLoss: 3.0184 Acc@1: 54.234%\n","| Epoch [525/1080] Iter[ 46/516]\t\tLoss: 3.3722 Acc@1: 53.940%\n","\n","| Validation Epoch #525\t\t\tLoss: 0.4069 Acc@1: 59.46%\n","\n","=> Training Epoch #526, LR=0.0471\n","| Epoch [526/1080] Iter[  1/516]\t\tLoss: 2.7745 Acc@1: 58.333%\n","| Epoch [526/1080] Iter[ 16/516]\t\tLoss: 2.9411 Acc@1: 54.557%\n","| Epoch [526/1080] Iter[ 31/516]\t\tLoss: 2.7760 Acc@1: 54.704%\n","| Epoch [526/1080] Iter[ 46/516]\t\tLoss: 2.9821 Acc@1: 53.714%\n","\n","| Validation Epoch #526\t\t\tLoss: 0.2884 Acc@1: 65.10%\n","\n","=> Training Epoch #527, LR=0.0471\n","| Epoch [527/1080] Iter[  1/516]\t\tLoss: 3.2590 Acc@1: 44.792%\n","| Epoch [527/1080] Iter[ 16/516]\t\tLoss: 2.5648 Acc@1: 55.404%\n","| Epoch [527/1080] Iter[ 31/516]\t\tLoss: 3.0123 Acc@1: 54.603%\n","| Epoch [527/1080] Iter[ 46/516]\t\tLoss: 2.9910 Acc@1: 53.714%\n","\n","| Validation Epoch #527\t\t\tLoss: 0.0394 Acc@1: 61.42%\n","\n","=> Training Epoch #528, LR=0.0470\n","| Epoch [528/1080] Iter[  1/516]\t\tLoss: 3.0801 Acc@1: 46.875%\n","| Epoch [528/1080] Iter[ 16/516]\t\tLoss: 3.0143 Acc@1: 54.427%\n","| Epoch [528/1080] Iter[ 31/516]\t\tLoss: 2.6867 Acc@1: 54.234%\n","| Epoch [528/1080] Iter[ 46/516]\t\tLoss: 2.8853 Acc@1: 53.668%\n","\n","| Validation Epoch #528\t\t\tLoss: 0.1159 Acc@1: 56.60%\n","\n","=> Training Epoch #529, LR=0.0470\n","| Epoch [529/1080] Iter[  1/516]\t\tLoss: 2.9292 Acc@1: 57.292%\n","| Epoch [529/1080] Iter[ 16/516]\t\tLoss: 3.0057 Acc@1: 54.167%\n","| Epoch [529/1080] Iter[ 31/516]\t\tLoss: 2.5231 Acc@1: 53.763%\n","| Epoch [529/1080] Iter[ 46/516]\t\tLoss: 2.9329 Acc@1: 52.559%\n","\n","| Validation Epoch #529\t\t\tLoss: 0.1420 Acc@1: 65.72%\n","\n","=> Training Epoch #530, LR=0.0469\n","| Epoch [530/1080] Iter[  1/516]\t\tLoss: 2.7820 Acc@1: 58.333%\n","| Epoch [530/1080] Iter[ 16/516]\t\tLoss: 3.0707 Acc@1: 53.711%\n","| Epoch [530/1080] Iter[ 31/516]\t\tLoss: 3.0480 Acc@1: 53.797%\n","| Epoch [530/1080] Iter[ 46/516]\t\tLoss: 3.2577 Acc@1: 53.351%\n","\n","| Validation Epoch #530\t\t\tLoss: 0.0059 Acc@1: 66.96%\n","\n","=> Training Epoch #531, LR=0.0469\n","| Epoch [531/1080] Iter[  1/516]\t\tLoss: 2.7943 Acc@1: 59.375%\n","| Epoch [531/1080] Iter[ 16/516]\t\tLoss: 2.8308 Acc@1: 54.753%\n","| Epoch [531/1080] Iter[ 31/516]\t\tLoss: 2.6984 Acc@1: 54.301%\n","| Epoch [531/1080] Iter[ 46/516]\t\tLoss: 2.8449 Acc@1: 53.918%\n","\n","| Validation Epoch #531\t\t\tLoss: 0.0323 Acc@1: 64.30%\n","\n","=> Training Epoch #532, LR=0.0468\n","| Epoch [532/1080] Iter[  1/516]\t\tLoss: 2.8270 Acc@1: 56.250%\n","| Epoch [532/1080] Iter[ 16/516]\t\tLoss: 3.0736 Acc@1: 56.185%\n","| Epoch [532/1080] Iter[ 31/516]\t\tLoss: 3.2639 Acc@1: 54.570%\n","| Epoch [532/1080] Iter[ 46/516]\t\tLoss: 3.0375 Acc@1: 53.827%\n","\n","| Validation Epoch #532\t\t\tLoss: 0.1525 Acc@1: 64.94%\n","\n","=> Training Epoch #533, LR=0.0468\n","| Epoch [533/1080] Iter[  1/516]\t\tLoss: 2.7333 Acc@1: 61.458%\n","| Epoch [533/1080] Iter[ 16/516]\t\tLoss: 3.0772 Acc@1: 50.716%\n","| Epoch [533/1080] Iter[ 31/516]\t\tLoss: 2.9481 Acc@1: 52.151%\n","| Epoch [533/1080] Iter[ 46/516]\t\tLoss: 3.0692 Acc@1: 52.287%\n","\n","| Validation Epoch #533\t\t\tLoss: 0.1727 Acc@1: 53.60%\n","\n","=> Training Epoch #534, LR=0.0467\n","| Epoch [534/1080] Iter[  1/516]\t\tLoss: 2.8534 Acc@1: 57.292%\n","| Epoch [534/1080] Iter[ 16/516]\t\tLoss: 2.7324 Acc@1: 54.232%\n","| Epoch [534/1080] Iter[ 31/516]\t\tLoss: 2.8827 Acc@1: 53.663%\n","| Epoch [534/1080] Iter[ 46/516]\t\tLoss: 3.0230 Acc@1: 53.329%\n","\n","| Validation Epoch #534\t\t\tLoss: 0.0046 Acc@1: 60.98%\n","\n","=> Training Epoch #535, LR=0.0467\n","| Epoch [535/1080] Iter[  1/516]\t\tLoss: 2.6972 Acc@1: 57.292%\n","| Epoch [535/1080] Iter[ 16/516]\t\tLoss: 2.7678 Acc@1: 54.753%\n","| Epoch [535/1080] Iter[ 31/516]\t\tLoss: 2.6517 Acc@1: 54.032%\n","| Epoch [535/1080] Iter[ 46/516]\t\tLoss: 3.1152 Acc@1: 53.804%\n","\n","| Validation Epoch #535\t\t\tLoss: 0.4799 Acc@1: 62.42%\n","\n","=> Training Epoch #536, LR=0.0466\n","| Epoch [536/1080] Iter[  1/516]\t\tLoss: 2.7830 Acc@1: 53.125%\n","| Epoch [536/1080] Iter[ 16/516]\t\tLoss: 3.0983 Acc@1: 54.232%\n","| Epoch [536/1080] Iter[ 31/516]\t\tLoss: 2.8839 Acc@1: 53.730%\n","| Epoch [536/1080] Iter[ 46/516]\t\tLoss: 2.7980 Acc@1: 53.668%\n","\n","| Validation Epoch #536\t\t\tLoss: 0.0820 Acc@1: 62.30%\n","\n","=> Training Epoch #537, LR=0.0466\n","| Epoch [537/1080] Iter[  1/516]\t\tLoss: 2.7451 Acc@1: 59.375%\n","| Epoch [537/1080] Iter[ 16/516]\t\tLoss: 3.0292 Acc@1: 54.948%\n","| Epoch [537/1080] Iter[ 31/516]\t\tLoss: 3.2949 Acc@1: 53.831%\n","| Epoch [537/1080] Iter[ 46/516]\t\tLoss: 2.9265 Acc@1: 54.099%\n","\n","| Validation Epoch #537\t\t\tLoss: 0.2802 Acc@1: 66.72%\n","\n","=> Training Epoch #538, LR=0.0465\n","| Epoch [538/1080] Iter[  1/516]\t\tLoss: 2.7800 Acc@1: 57.292%\n","| Epoch [538/1080] Iter[ 16/516]\t\tLoss: 3.2732 Acc@1: 53.971%\n","| Epoch [538/1080] Iter[ 31/516]\t\tLoss: 3.1710 Acc@1: 54.267%\n","| Epoch [538/1080] Iter[ 46/516]\t\tLoss: 2.8075 Acc@1: 53.646%\n","\n","| Validation Epoch #538\t\t\tLoss: 0.3637 Acc@1: 61.16%\n","\n","=> Training Epoch #539, LR=0.0465\n","| Epoch [539/1080] Iter[  1/516]\t\tLoss: 2.8709 Acc@1: 57.292%\n","| Epoch [539/1080] Iter[ 16/516]\t\tLoss: 2.9986 Acc@1: 55.599%\n","| Epoch [539/1080] Iter[ 31/516]\t\tLoss: 2.9637 Acc@1: 54.469%\n","| Epoch [539/1080] Iter[ 46/516]\t\tLoss: 2.9610 Acc@1: 53.759%\n","\n","| Validation Epoch #539\t\t\tLoss: 0.4705 Acc@1: 56.54%\n","\n","=> Training Epoch #540, LR=0.0464\n","| Epoch [540/1080] Iter[  1/516]\t\tLoss: 2.8063 Acc@1: 58.333%\n","| Epoch [540/1080] Iter[ 16/516]\t\tLoss: 3.2523 Acc@1: 53.255%\n","| Epoch [540/1080] Iter[ 31/516]\t\tLoss: 2.7868 Acc@1: 52.688%\n","| Epoch [540/1080] Iter[ 46/516]\t\tLoss: 3.0139 Acc@1: 53.148%\n","\n","| Validation Epoch #540\t\t\tLoss: 0.6734 Acc@1: 60.28%\n","\n","=> Training Epoch #541, LR=0.0464\n","| Epoch [541/1080] Iter[  1/516]\t\tLoss: 2.6437 Acc@1: 56.250%\n","| Epoch [541/1080] Iter[ 16/516]\t\tLoss: 2.8817 Acc@1: 51.497%\n","| Epoch [541/1080] Iter[ 31/516]\t\tLoss: 2.7995 Acc@1: 52.823%\n","| Epoch [541/1080] Iter[ 46/516]\t\tLoss: 2.6780 Acc@1: 52.989%\n","\n","| Validation Epoch #541\t\t\tLoss: 0.0508 Acc@1: 65.90%\n","\n","=> Training Epoch #542, LR=0.0463\n","| Epoch [542/1080] Iter[  1/516]\t\tLoss: 2.9380 Acc@1: 53.125%\n","| Epoch [542/1080] Iter[ 16/516]\t\tLoss: 3.1096 Acc@1: 53.125%\n","| Epoch [542/1080] Iter[ 31/516]\t\tLoss: 2.9295 Acc@1: 53.125%\n","| Epoch [542/1080] Iter[ 46/516]\t\tLoss: 3.1100 Acc@1: 53.555%\n","\n","| Validation Epoch #542\t\t\tLoss: 0.1765 Acc@1: 63.70%\n","\n","=> Training Epoch #543, LR=0.0463\n","| Epoch [543/1080] Iter[  1/516]\t\tLoss: 2.9923 Acc@1: 51.042%\n","| Epoch [543/1080] Iter[ 16/516]\t\tLoss: 2.8958 Acc@1: 54.036%\n","| Epoch [543/1080] Iter[ 31/516]\t\tLoss: 2.7565 Acc@1: 54.503%\n","| Epoch [543/1080] Iter[ 46/516]\t\tLoss: 2.9715 Acc@1: 54.574%\n","\n","| Validation Epoch #543\t\t\tLoss: 0.0007 Acc@1: 62.16%\n","\n","=> Training Epoch #544, LR=0.0462\n","| Epoch [544/1080] Iter[  1/516]\t\tLoss: 2.9153 Acc@1: 52.083%\n","| Epoch [544/1080] Iter[ 16/516]\t\tLoss: 2.7859 Acc@1: 53.971%\n","| Epoch [544/1080] Iter[ 31/516]\t\tLoss: 3.0052 Acc@1: 53.528%\n","| Epoch [544/1080] Iter[ 46/516]\t\tLoss: 2.8189 Acc@1: 54.303%\n","\n","| Validation Epoch #544\t\t\tLoss: 0.0628 Acc@1: 61.66%\n","\n","=> Training Epoch #545, LR=0.0462\n","| Epoch [545/1080] Iter[  1/516]\t\tLoss: 2.8901 Acc@1: 56.250%\n","| Epoch [545/1080] Iter[ 16/516]\t\tLoss: 2.8608 Acc@1: 53.516%\n","| Epoch [545/1080] Iter[ 31/516]\t\tLoss: 2.7527 Acc@1: 54.066%\n","| Epoch [545/1080] Iter[ 46/516]\t\tLoss: 3.1403 Acc@1: 53.804%\n","\n","| Validation Epoch #545\t\t\tLoss: 0.0564 Acc@1: 64.44%\n","\n","=> Training Epoch #546, LR=0.0461\n","| Epoch [546/1080] Iter[  1/516]\t\tLoss: 2.9124 Acc@1: 54.167%\n","| Epoch [546/1080] Iter[ 16/516]\t\tLoss: 2.7800 Acc@1: 54.818%\n","| Epoch [546/1080] Iter[ 31/516]\t\tLoss: 2.8582 Acc@1: 54.940%\n","| Epoch [546/1080] Iter[ 46/516]\t\tLoss: 2.6442 Acc@1: 55.005%\n","\n","| Validation Epoch #546\t\t\tLoss: 0.0002 Acc@1: 59.16%\n","\n","=> Training Epoch #547, LR=0.0461\n","| Epoch [547/1080] Iter[  1/516]\t\tLoss: 2.7089 Acc@1: 54.167%\n","| Epoch [547/1080] Iter[ 16/516]\t\tLoss: 2.9921 Acc@1: 54.492%\n","| Epoch [547/1080] Iter[ 31/516]\t\tLoss: 2.7732 Acc@1: 54.435%\n","| Epoch [547/1080] Iter[ 46/516]\t\tLoss: 2.5558 Acc@1: 54.778%\n","\n","| Validation Epoch #547\t\t\tLoss: 0.0017 Acc@1: 58.48%\n","\n","=> Training Epoch #548, LR=0.0460\n","| Epoch [548/1080] Iter[  1/516]\t\tLoss: 2.9697 Acc@1: 51.042%\n","| Epoch [548/1080] Iter[ 16/516]\t\tLoss: 2.7240 Acc@1: 55.599%\n","| Epoch [548/1080] Iter[ 31/516]\t\tLoss: 2.7728 Acc@1: 54.133%\n","| Epoch [548/1080] Iter[ 46/516]\t\tLoss: 2.9011 Acc@1: 53.782%\n","\n","| Validation Epoch #548\t\t\tLoss: 0.2015 Acc@1: 63.94%\n","\n","=> Training Epoch #549, LR=0.0460\n","| Epoch [549/1080] Iter[  1/516]\t\tLoss: 2.8444 Acc@1: 53.125%\n","| Epoch [549/1080] Iter[ 16/516]\t\tLoss: 2.8950 Acc@1: 54.036%\n","| Epoch [549/1080] Iter[ 31/516]\t\tLoss: 2.8593 Acc@1: 54.570%\n","| Epoch [549/1080] Iter[ 46/516]\t\tLoss: 3.0104 Acc@1: 54.189%\n","\n","| Validation Epoch #549\t\t\tLoss: 0.0667 Acc@1: 69.22%\n","| Saving Best model...\t\t\tTop1 = 69.22%\n","\n","=> Training Epoch #550, LR=0.0459\n","| Epoch [550/1080] Iter[  1/516]\t\tLoss: 3.1518 Acc@1: 48.958%\n","| Epoch [550/1080] Iter[ 16/516]\t\tLoss: 2.5742 Acc@1: 54.167%\n","| Epoch [550/1080] Iter[ 31/516]\t\tLoss: 2.9944 Acc@1: 54.066%\n","| Epoch [550/1080] Iter[ 46/516]\t\tLoss: 3.2753 Acc@1: 53.510%\n","\n","| Validation Epoch #550\t\t\tLoss: 0.0236 Acc@1: 64.08%\n","\n","=> Training Epoch #551, LR=0.0459\n","| Epoch [551/1080] Iter[  1/516]\t\tLoss: 2.8008 Acc@1: 55.208%\n","| Epoch [551/1080] Iter[ 16/516]\t\tLoss: 2.8275 Acc@1: 55.143%\n","| Epoch [551/1080] Iter[ 31/516]\t\tLoss: 2.6983 Acc@1: 54.603%\n","| Epoch [551/1080] Iter[ 46/516]\t\tLoss: 2.9406 Acc@1: 54.053%\n","\n","| Validation Epoch #551\t\t\tLoss: 0.0531 Acc@1: 66.52%\n","\n","=> Training Epoch #552, LR=0.0458\n","| Epoch [552/1080] Iter[  1/516]\t\tLoss: 2.9889 Acc@1: 54.167%\n","| Epoch [552/1080] Iter[ 16/516]\t\tLoss: 2.7083 Acc@1: 56.120%\n","| Epoch [552/1080] Iter[ 31/516]\t\tLoss: 2.5352 Acc@1: 54.906%\n","| Epoch [552/1080] Iter[ 46/516]\t\tLoss: 2.8399 Acc@1: 54.574%\n","\n","| Validation Epoch #552\t\t\tLoss: 0.0258 Acc@1: 65.36%\n","\n","=> Training Epoch #553, LR=0.0458\n","| Epoch [553/1080] Iter[  1/516]\t\tLoss: 2.6709 Acc@1: 60.417%\n","| Epoch [553/1080] Iter[ 16/516]\t\tLoss: 2.7173 Acc@1: 54.818%\n","| Epoch [553/1080] Iter[ 31/516]\t\tLoss: 2.7591 Acc@1: 54.200%\n","| Epoch [553/1080] Iter[ 46/516]\t\tLoss: 3.0768 Acc@1: 54.167%\n","\n","| Validation Epoch #553\t\t\tLoss: 0.2097 Acc@1: 63.46%\n","\n","=> Training Epoch #554, LR=0.0457\n","| Epoch [554/1080] Iter[  1/516]\t\tLoss: 2.9135 Acc@1: 54.167%\n","| Epoch [554/1080] Iter[ 16/516]\t\tLoss: 2.7856 Acc@1: 53.190%\n","| Epoch [554/1080] Iter[ 31/516]\t\tLoss: 2.8196 Acc@1: 54.200%\n","| Epoch [554/1080] Iter[ 46/516]\t\tLoss: 2.8987 Acc@1: 53.668%\n","\n","| Validation Epoch #554\t\t\tLoss: 0.0029 Acc@1: 63.74%\n","\n","=> Training Epoch #555, LR=0.0457\n","| Epoch [555/1080] Iter[  1/516]\t\tLoss: 2.9809 Acc@1: 52.083%\n","| Epoch [555/1080] Iter[ 16/516]\t\tLoss: 2.9539 Acc@1: 54.688%\n","| Epoch [555/1080] Iter[ 31/516]\t\tLoss: 3.1480 Acc@1: 54.200%\n","| Epoch [555/1080] Iter[ 46/516]\t\tLoss: 3.1374 Acc@1: 54.416%\n","\n","| Validation Epoch #555\t\t\tLoss: 0.0359 Acc@1: 64.38%\n","\n","=> Training Epoch #556, LR=0.0456\n","| Epoch [556/1080] Iter[  1/516]\t\tLoss: 2.9374 Acc@1: 57.292%\n","| Epoch [556/1080] Iter[ 16/516]\t\tLoss: 2.8619 Acc@1: 54.818%\n","| Epoch [556/1080] Iter[ 31/516]\t\tLoss: 2.8270 Acc@1: 54.503%\n","| Epoch [556/1080] Iter[ 46/516]\t\tLoss: 3.2726 Acc@1: 54.076%\n","\n","| Validation Epoch #556\t\t\tLoss: 0.0002 Acc@1: 59.78%\n","\n","=> Training Epoch #557, LR=0.0456\n","| Epoch [557/1080] Iter[  1/516]\t\tLoss: 2.8390 Acc@1: 55.208%\n","| Epoch [557/1080] Iter[ 16/516]\t\tLoss: 2.6287 Acc@1: 54.753%\n","| Epoch [557/1080] Iter[ 31/516]\t\tLoss: 2.7573 Acc@1: 53.629%\n","| Epoch [557/1080] Iter[ 46/516]\t\tLoss: 2.8906 Acc@1: 53.487%\n","\n","| Validation Epoch #557\t\t\tLoss: 0.0356 Acc@1: 64.58%\n","\n","=> Training Epoch #558, LR=0.0455\n","| Epoch [558/1080] Iter[  1/516]\t\tLoss: 2.8396 Acc@1: 57.292%\n","| Epoch [558/1080] Iter[ 16/516]\t\tLoss: 3.1163 Acc@1: 53.451%\n","| Epoch [558/1080] Iter[ 31/516]\t\tLoss: 3.1296 Acc@1: 53.629%\n","| Epoch [558/1080] Iter[ 46/516]\t\tLoss: 3.0695 Acc@1: 53.329%\n","\n","| Validation Epoch #558\t\t\tLoss: 0.0508 Acc@1: 59.28%\n","\n","=> Training Epoch #559, LR=0.0455\n","| Epoch [559/1080] Iter[  1/516]\t\tLoss: 2.9946 Acc@1: 52.083%\n","| Epoch [559/1080] Iter[ 16/516]\t\tLoss: 2.7446 Acc@1: 54.622%\n","| Epoch [559/1080] Iter[ 31/516]\t\tLoss: 2.9070 Acc@1: 54.940%\n","| Epoch [559/1080] Iter[ 46/516]\t\tLoss: 3.0118 Acc@1: 54.710%\n","\n","| Validation Epoch #559\t\t\tLoss: 0.5675 Acc@1: 60.42%\n","\n","=> Training Epoch #560, LR=0.0454\n","| Epoch [560/1080] Iter[  1/516]\t\tLoss: 2.7653 Acc@1: 60.417%\n","| Epoch [560/1080] Iter[ 16/516]\t\tLoss: 2.7758 Acc@1: 55.143%\n","| Epoch [560/1080] Iter[ 31/516]\t\tLoss: 2.6644 Acc@1: 54.973%\n","| Epoch [560/1080] Iter[ 46/516]\t\tLoss: 2.8899 Acc@1: 54.733%\n","\n","| Validation Epoch #560\t\t\tLoss: 0.0052 Acc@1: 53.60%\n","\n","=> Training Epoch #561, LR=0.0454\n","| Epoch [561/1080] Iter[  1/516]\t\tLoss: 2.6942 Acc@1: 56.250%\n","| Epoch [561/1080] Iter[ 16/516]\t\tLoss: 2.9805 Acc@1: 54.427%\n","| Epoch [561/1080] Iter[ 31/516]\t\tLoss: 3.1216 Acc@1: 53.360%\n","| Epoch [561/1080] Iter[ 46/516]\t\tLoss: 2.7783 Acc@1: 53.782%\n","\n","| Validation Epoch #561\t\t\tLoss: 0.0556 Acc@1: 64.06%\n","\n","=> Training Epoch #562, LR=0.0453\n","| Epoch [562/1080] Iter[  1/516]\t\tLoss: 2.8168 Acc@1: 57.292%\n","| Epoch [562/1080] Iter[ 16/516]\t\tLoss: 2.7834 Acc@1: 54.688%\n","| Epoch [562/1080] Iter[ 31/516]\t\tLoss: 2.8803 Acc@1: 54.066%\n","| Epoch [562/1080] Iter[ 46/516]\t\tLoss: 2.9482 Acc@1: 53.850%\n","\n","| Validation Epoch #562\t\t\tLoss: 0.0196 Acc@1: 66.60%\n","\n","=> Training Epoch #563, LR=0.0453\n","| Epoch [563/1080] Iter[  1/516]\t\tLoss: 2.8783 Acc@1: 57.292%\n","| Epoch [563/1080] Iter[ 16/516]\t\tLoss: 3.2184 Acc@1: 55.078%\n","| Epoch [563/1080] Iter[ 31/516]\t\tLoss: 2.9592 Acc@1: 54.738%\n","| Epoch [563/1080] Iter[ 46/516]\t\tLoss: 2.8683 Acc@1: 54.620%\n","\n","| Validation Epoch #563\t\t\tLoss: 0.0007 Acc@1: 57.20%\n","\n","=> Training Epoch #564, LR=0.0452\n","| Epoch [564/1080] Iter[  1/516]\t\tLoss: 2.3855 Acc@1: 63.542%\n","| Epoch [564/1080] Iter[ 16/516]\t\tLoss: 2.8308 Acc@1: 55.143%\n","| Epoch [564/1080] Iter[ 31/516]\t\tLoss: 2.6754 Acc@1: 55.175%\n","| Epoch [564/1080] Iter[ 46/516]\t\tLoss: 2.7607 Acc@1: 54.506%\n","\n","| Validation Epoch #564\t\t\tLoss: 0.8199 Acc@1: 63.16%\n","\n","=> Training Epoch #565, LR=0.0452\n","| Epoch [565/1080] Iter[  1/516]\t\tLoss: 2.7869 Acc@1: 54.167%\n","| Epoch [565/1080] Iter[ 16/516]\t\tLoss: 2.8891 Acc@1: 53.646%\n","| Epoch [565/1080] Iter[ 31/516]\t\tLoss: 2.7425 Acc@1: 54.570%\n","| Epoch [565/1080] Iter[ 46/516]\t\tLoss: 3.0356 Acc@1: 53.668%\n","\n","| Validation Epoch #565\t\t\tLoss: 0.2212 Acc@1: 65.54%\n","\n","=> Training Epoch #566, LR=0.0451\n","| Epoch [566/1080] Iter[  1/516]\t\tLoss: 2.8358 Acc@1: 53.125%\n","| Epoch [566/1080] Iter[ 16/516]\t\tLoss: 3.0616 Acc@1: 54.622%\n","| Epoch [566/1080] Iter[ 31/516]\t\tLoss: 2.9829 Acc@1: 53.427%\n","| Epoch [566/1080] Iter[ 46/516]\t\tLoss: 3.0716 Acc@1: 52.989%\n","\n","| Validation Epoch #566\t\t\tLoss: 0.3874 Acc@1: 63.76%\n","\n","=> Training Epoch #567, LR=0.0451\n","| Epoch [567/1080] Iter[  1/516]\t\tLoss: 2.9956 Acc@1: 51.042%\n","| Epoch [567/1080] Iter[ 16/516]\t\tLoss: 2.8215 Acc@1: 53.581%\n","| Epoch [567/1080] Iter[ 31/516]\t\tLoss: 3.0912 Acc@1: 53.394%\n","| Epoch [567/1080] Iter[ 46/516]\t\tLoss: 2.9095 Acc@1: 52.944%\n","\n","| Validation Epoch #567\t\t\tLoss: 0.3152 Acc@1: 66.32%\n","\n","=> Training Epoch #568, LR=0.0450\n","| Epoch [568/1080] Iter[  1/516]\t\tLoss: 2.8912 Acc@1: 52.083%\n","| Epoch [568/1080] Iter[ 16/516]\t\tLoss: 2.7322 Acc@1: 55.013%\n","| Epoch [568/1080] Iter[ 31/516]\t\tLoss: 3.0610 Acc@1: 54.704%\n","| Epoch [568/1080] Iter[ 46/516]\t\tLoss: 2.9132 Acc@1: 54.869%\n","\n","| Validation Epoch #568\t\t\tLoss: 0.0001 Acc@1: 65.94%\n","\n","=> Training Epoch #569, LR=0.0450\n","| Epoch [569/1080] Iter[  1/516]\t\tLoss: 2.7841 Acc@1: 55.208%\n","| Epoch [569/1080] Iter[ 16/516]\t\tLoss: 3.0406 Acc@1: 53.060%\n","| Epoch [569/1080] Iter[ 31/516]\t\tLoss: 3.0206 Acc@1: 53.831%\n","| Epoch [569/1080] Iter[ 46/516]\t\tLoss: 3.0198 Acc@1: 53.827%\n","\n","| Validation Epoch #569\t\t\tLoss: 0.2919 Acc@1: 68.56%\n","\n","=> Training Epoch #570, LR=0.0449\n","| Epoch [570/1080] Iter[  1/516]\t\tLoss: 3.1060 Acc@1: 47.917%\n","| Epoch [570/1080] Iter[ 16/516]\t\tLoss: 3.0531 Acc@1: 53.516%\n","| Epoch [570/1080] Iter[ 31/516]\t\tLoss: 2.9851 Acc@1: 54.167%\n","| Epoch [570/1080] Iter[ 46/516]\t\tLoss: 3.0155 Acc@1: 54.053%\n","\n","| Validation Epoch #570\t\t\tLoss: 0.1081 Acc@1: 64.54%\n","\n","=> Training Epoch #571, LR=0.0449\n","| Epoch [571/1080] Iter[  1/516]\t\tLoss: 2.8675 Acc@1: 55.208%\n","| Epoch [571/1080] Iter[ 16/516]\t\tLoss: 3.0390 Acc@1: 52.279%\n","| Epoch [571/1080] Iter[ 31/516]\t\tLoss: 3.1627 Acc@1: 53.293%\n","| Epoch [571/1080] Iter[ 46/516]\t\tLoss: 3.0992 Acc@1: 53.465%\n","\n","| Validation Epoch #571\t\t\tLoss: 0.1155 Acc@1: 62.36%\n","\n","=> Training Epoch #572, LR=0.0448\n","| Epoch [572/1080] Iter[  1/516]\t\tLoss: 3.2274 Acc@1: 52.083%\n","| Epoch [572/1080] Iter[ 16/516]\t\tLoss: 2.7617 Acc@1: 53.776%\n","| Epoch [572/1080] Iter[ 31/516]\t\tLoss: 2.9208 Acc@1: 53.663%\n","| Epoch [572/1080] Iter[ 46/516]\t\tLoss: 2.8074 Acc@1: 53.827%\n","\n","| Validation Epoch #572\t\t\tLoss: 0.0382 Acc@1: 65.14%\n","\n","=> Training Epoch #573, LR=0.0448\n","| Epoch [573/1080] Iter[  1/516]\t\tLoss: 2.8160 Acc@1: 55.208%\n","| Epoch [573/1080] Iter[ 16/516]\t\tLoss: 2.8403 Acc@1: 53.385%\n","| Epoch [573/1080] Iter[ 31/516]\t\tLoss: 2.9643 Acc@1: 53.864%\n","| Epoch [573/1080] Iter[ 46/516]\t\tLoss: 2.8556 Acc@1: 53.940%\n","\n","| Validation Epoch #573\t\t\tLoss: 0.6941 Acc@1: 63.28%\n","\n","=> Training Epoch #574, LR=0.0447\n","| Epoch [574/1080] Iter[  1/516]\t\tLoss: 2.4438 Acc@1: 62.500%\n","| Epoch [574/1080] Iter[ 16/516]\t\tLoss: 3.1086 Acc@1: 55.013%\n","| Epoch [574/1080] Iter[ 31/516]\t\tLoss: 2.9119 Acc@1: 54.368%\n","| Epoch [574/1080] Iter[ 46/516]\t\tLoss: 3.0669 Acc@1: 53.714%\n","\n","| Validation Epoch #574\t\t\tLoss: 1.1937 Acc@1: 53.30%\n","\n","=> Training Epoch #575, LR=0.0447\n","| Epoch [575/1080] Iter[  1/516]\t\tLoss: 3.0347 Acc@1: 51.042%\n","| Epoch [575/1080] Iter[ 16/516]\t\tLoss: 2.6544 Acc@1: 53.646%\n","| Epoch [575/1080] Iter[ 31/516]\t\tLoss: 3.0469 Acc@1: 53.763%\n","| Epoch [575/1080] Iter[ 46/516]\t\tLoss: 2.8500 Acc@1: 53.736%\n","\n","| Validation Epoch #575\t\t\tLoss: 0.1196 Acc@1: 60.74%\n","\n","=> Training Epoch #576, LR=0.0446\n","| Epoch [576/1080] Iter[  1/516]\t\tLoss: 2.7546 Acc@1: 57.292%\n","| Epoch [576/1080] Iter[ 16/516]\t\tLoss: 2.6085 Acc@1: 53.711%\n","| Epoch [576/1080] Iter[ 31/516]\t\tLoss: 2.5947 Acc@1: 54.032%\n","| Epoch [576/1080] Iter[ 46/516]\t\tLoss: 2.7933 Acc@1: 53.284%\n","\n","| Validation Epoch #576\t\t\tLoss: 0.0461 Acc@1: 60.46%\n","\n","=> Training Epoch #577, LR=0.0446\n","| Epoch [577/1080] Iter[  1/516]\t\tLoss: 2.9842 Acc@1: 53.125%\n","| Epoch [577/1080] Iter[ 16/516]\t\tLoss: 2.7917 Acc@1: 54.492%\n","| Epoch [577/1080] Iter[ 31/516]\t\tLoss: 2.6997 Acc@1: 54.503%\n","| Epoch [577/1080] Iter[ 46/516]\t\tLoss: 2.6599 Acc@1: 54.280%\n","\n","| Validation Epoch #577\t\t\tLoss: 0.0265 Acc@1: 65.46%\n","\n","=> Training Epoch #578, LR=0.0445\n","| Epoch [578/1080] Iter[  1/516]\t\tLoss: 2.9020 Acc@1: 54.167%\n","| Epoch [578/1080] Iter[ 16/516]\t\tLoss: 2.8488 Acc@1: 54.753%\n","| Epoch [578/1080] Iter[ 31/516]\t\tLoss: 3.2925 Acc@1: 53.192%\n","| Epoch [578/1080] Iter[ 46/516]\t\tLoss: 2.8977 Acc@1: 53.351%\n","\n","| Validation Epoch #578\t\t\tLoss: 0.2893 Acc@1: 68.04%\n","\n","=> Training Epoch #579, LR=0.0445\n","| Epoch [579/1080] Iter[  1/516]\t\tLoss: 2.9513 Acc@1: 56.250%\n","| Epoch [579/1080] Iter[ 16/516]\t\tLoss: 2.9449 Acc@1: 53.711%\n","| Epoch [579/1080] Iter[ 31/516]\t\tLoss: 2.8601 Acc@1: 54.066%\n","| Epoch [579/1080] Iter[ 46/516]\t\tLoss: 2.8750 Acc@1: 53.578%\n","\n","| Validation Epoch #579\t\t\tLoss: 0.3899 Acc@1: 64.08%\n","\n","=> Training Epoch #580, LR=0.0444\n","| Epoch [580/1080] Iter[  1/516]\t\tLoss: 2.4914 Acc@1: 63.542%\n","| Epoch [580/1080] Iter[ 16/516]\t\tLoss: 2.7493 Acc@1: 54.492%\n","| Epoch [580/1080] Iter[ 31/516]\t\tLoss: 2.6124 Acc@1: 55.141%\n","| Epoch [580/1080] Iter[ 46/516]\t\tLoss: 2.8340 Acc@1: 54.733%\n","\n","| Validation Epoch #580\t\t\tLoss: 0.2018 Acc@1: 63.48%\n","\n","=> Training Epoch #581, LR=0.0444\n","| Epoch [581/1080] Iter[  1/516]\t\tLoss: 2.9125 Acc@1: 58.333%\n","| Epoch [581/1080] Iter[ 16/516]\t\tLoss: 2.8653 Acc@1: 53.646%\n","| Epoch [581/1080] Iter[ 31/516]\t\tLoss: 2.8521 Acc@1: 54.536%\n","| Epoch [581/1080] Iter[ 46/516]\t\tLoss: 2.7322 Acc@1: 54.280%\n","\n","| Validation Epoch #581\t\t\tLoss: 0.6048 Acc@1: 60.16%\n","\n","=> Training Epoch #582, LR=0.0443\n","| Epoch [582/1080] Iter[  1/516]\t\tLoss: 2.9061 Acc@1: 54.167%\n","| Epoch [582/1080] Iter[ 16/516]\t\tLoss: 3.1534 Acc@1: 53.841%\n","| Epoch [582/1080] Iter[ 31/516]\t\tLoss: 2.8284 Acc@1: 53.528%\n","| Epoch [582/1080] Iter[ 46/516]\t\tLoss: 2.9585 Acc@1: 53.533%\n","\n","| Validation Epoch #582\t\t\tLoss: 0.8653 Acc@1: 62.66%\n","\n","=> Training Epoch #583, LR=0.0443\n","| Epoch [583/1080] Iter[  1/516]\t\tLoss: 2.7090 Acc@1: 55.208%\n","| Epoch [583/1080] Iter[ 16/516]\t\tLoss: 2.7574 Acc@1: 54.883%\n","| Epoch [583/1080] Iter[ 31/516]\t\tLoss: 3.2321 Acc@1: 54.435%\n","| Epoch [583/1080] Iter[ 46/516]\t\tLoss: 2.9663 Acc@1: 53.963%\n","\n","| Validation Epoch #583\t\t\tLoss: 0.2391 Acc@1: 61.34%\n","\n","=> Training Epoch #584, LR=0.0442\n","| Epoch [584/1080] Iter[  1/516]\t\tLoss: 2.8324 Acc@1: 62.500%\n","| Epoch [584/1080] Iter[ 16/516]\t\tLoss: 2.8313 Acc@1: 54.492%\n","| Epoch [584/1080] Iter[ 31/516]\t\tLoss: 2.6772 Acc@1: 53.931%\n","| Epoch [584/1080] Iter[ 46/516]\t\tLoss: 2.7543 Acc@1: 53.850%\n","\n","| Validation Epoch #584\t\t\tLoss: 0.1188 Acc@1: 62.60%\n","\n","=> Training Epoch #585, LR=0.0442\n","| Epoch [585/1080] Iter[  1/516]\t\tLoss: 2.8886 Acc@1: 56.250%\n","| Epoch [585/1080] Iter[ 16/516]\t\tLoss: 3.0507 Acc@1: 54.883%\n","| Epoch [585/1080] Iter[ 31/516]\t\tLoss: 2.4241 Acc@1: 55.208%\n","| Epoch [585/1080] Iter[ 46/516]\t\tLoss: 2.9894 Acc@1: 54.642%\n","\n","| Validation Epoch #585\t\t\tLoss: 0.4584 Acc@1: 65.04%\n","\n","=> Training Epoch #586, LR=0.0441\n","| Epoch [586/1080] Iter[  1/516]\t\tLoss: 2.6964 Acc@1: 59.375%\n","| Epoch [586/1080] Iter[ 16/516]\t\tLoss: 2.8865 Acc@1: 54.492%\n","| Epoch [586/1080] Iter[ 31/516]\t\tLoss: 3.0777 Acc@1: 54.335%\n","| Epoch [586/1080] Iter[ 46/516]\t\tLoss: 3.0048 Acc@1: 54.506%\n","\n","| Validation Epoch #586\t\t\tLoss: 0.4728 Acc@1: 66.58%\n","\n","=> Training Epoch #587, LR=0.0441\n","| Epoch [587/1080] Iter[  1/516]\t\tLoss: 2.5551 Acc@1: 59.375%\n","| Epoch [587/1080] Iter[ 16/516]\t\tLoss: 2.5766 Acc@1: 55.859%\n","| Epoch [587/1080] Iter[ 31/516]\t\tLoss: 2.7080 Acc@1: 55.108%\n","| Epoch [587/1080] Iter[ 46/516]\t\tLoss: 2.8097 Acc@1: 54.438%\n","\n","| Validation Epoch #587\t\t\tLoss: 0.0937 Acc@1: 66.38%\n","\n","=> Training Epoch #588, LR=0.0440\n","| Epoch [588/1080] Iter[  1/516]\t\tLoss: 2.8310 Acc@1: 52.083%\n","| Epoch [588/1080] Iter[ 16/516]\t\tLoss: 2.8614 Acc@1: 54.297%\n","| Epoch [588/1080] Iter[ 31/516]\t\tLoss: 3.1187 Acc@1: 53.931%\n","| Epoch [588/1080] Iter[ 46/516]\t\tLoss: 2.9105 Acc@1: 53.736%\n","\n","| Validation Epoch #588\t\t\tLoss: 0.2096 Acc@1: 62.92%\n","\n","=> Training Epoch #589, LR=0.0440\n","| Epoch [589/1080] Iter[  1/516]\t\tLoss: 2.5177 Acc@1: 60.417%\n","| Epoch [589/1080] Iter[ 16/516]\t\tLoss: 2.6587 Acc@1: 53.906%\n","| Epoch [589/1080] Iter[ 31/516]\t\tLoss: 2.9664 Acc@1: 53.696%\n","| Epoch [589/1080] Iter[ 46/516]\t\tLoss: 2.8008 Acc@1: 53.465%\n","\n","| Validation Epoch #589\t\t\tLoss: 0.3162 Acc@1: 66.48%\n","\n","=> Training Epoch #590, LR=0.0439\n","| Epoch [590/1080] Iter[  1/516]\t\tLoss: 3.0027 Acc@1: 50.000%\n","| Epoch [590/1080] Iter[ 16/516]\t\tLoss: 2.6688 Acc@1: 56.510%\n","| Epoch [590/1080] Iter[ 31/516]\t\tLoss: 2.9966 Acc@1: 55.645%\n","| Epoch [590/1080] Iter[ 46/516]\t\tLoss: 3.1453 Acc@1: 55.005%\n","\n","| Validation Epoch #590\t\t\tLoss: 0.1022 Acc@1: 65.60%\n","\n","=> Training Epoch #591, LR=0.0439\n","| Epoch [591/1080] Iter[  1/516]\t\tLoss: 2.8468 Acc@1: 50.000%\n","| Epoch [591/1080] Iter[ 16/516]\t\tLoss: 2.7338 Acc@1: 55.013%\n","| Epoch [591/1080] Iter[ 31/516]\t\tLoss: 2.6911 Acc@1: 54.503%\n","| Epoch [591/1080] Iter[ 46/516]\t\tLoss: 2.7366 Acc@1: 53.963%\n","\n","| Validation Epoch #591\t\t\tLoss: 0.1002 Acc@1: 59.40%\n","\n","=> Training Epoch #592, LR=0.0438\n","| Epoch [592/1080] Iter[  1/516]\t\tLoss: 2.8905 Acc@1: 52.083%\n","| Epoch [592/1080] Iter[ 16/516]\t\tLoss: 2.9869 Acc@1: 53.906%\n","| Epoch [592/1080] Iter[ 31/516]\t\tLoss: 2.8692 Acc@1: 54.435%\n","| Epoch [592/1080] Iter[ 46/516]\t\tLoss: 2.7273 Acc@1: 54.167%\n","\n","| Validation Epoch #592\t\t\tLoss: 0.1305 Acc@1: 63.66%\n","\n","=> Training Epoch #593, LR=0.0438\n","| Epoch [593/1080] Iter[  1/516]\t\tLoss: 2.8764 Acc@1: 51.042%\n","| Epoch [593/1080] Iter[ 16/516]\t\tLoss: 2.8282 Acc@1: 53.711%\n","| Epoch [593/1080] Iter[ 31/516]\t\tLoss: 2.8263 Acc@1: 53.394%\n","| Epoch [593/1080] Iter[ 46/516]\t\tLoss: 2.8457 Acc@1: 53.419%\n","\n","| Validation Epoch #593\t\t\tLoss: 0.3610 Acc@1: 62.08%\n","\n","=> Training Epoch #594, LR=0.0437\n","| Epoch [594/1080] Iter[  1/516]\t\tLoss: 2.4356 Acc@1: 63.542%\n","| Epoch [594/1080] Iter[ 16/516]\t\tLoss: 2.8557 Acc@1: 54.362%\n","| Epoch [594/1080] Iter[ 31/516]\t\tLoss: 2.6216 Acc@1: 54.368%\n","| Epoch [594/1080] Iter[ 46/516]\t\tLoss: 2.9017 Acc@1: 53.986%\n","\n","| Validation Epoch #594\t\t\tLoss: 0.1562 Acc@1: 62.74%\n","\n","=> Training Epoch #595, LR=0.0437\n","| Epoch [595/1080] Iter[  1/516]\t\tLoss: 3.1550 Acc@1: 45.833%\n","| Epoch [595/1080] Iter[ 16/516]\t\tLoss: 2.9332 Acc@1: 52.995%\n","| Epoch [595/1080] Iter[ 31/516]\t\tLoss: 2.8015 Acc@1: 54.032%\n","| Epoch [595/1080] Iter[ 46/516]\t\tLoss: 3.1202 Acc@1: 53.442%\n","\n","| Validation Epoch #595\t\t\tLoss: 0.6164 Acc@1: 63.10%\n","\n","=> Training Epoch #596, LR=0.0436\n","| Epoch [596/1080] Iter[  1/516]\t\tLoss: 2.8910 Acc@1: 51.042%\n","| Epoch [596/1080] Iter[ 16/516]\t\tLoss: 2.7310 Acc@1: 52.930%\n","| Epoch [596/1080] Iter[ 31/516]\t\tLoss: 2.8625 Acc@1: 53.763%\n","| Epoch [596/1080] Iter[ 46/516]\t\tLoss: 2.9102 Acc@1: 53.057%\n","\n","| Validation Epoch #596\t\t\tLoss: 0.4543 Acc@1: 61.86%\n","\n","=> Training Epoch #597, LR=0.0436\n","| Epoch [597/1080] Iter[  1/516]\t\tLoss: 3.0489 Acc@1: 51.042%\n","| Epoch [597/1080] Iter[ 16/516]\t\tLoss: 2.8919 Acc@1: 53.711%\n","| Epoch [597/1080] Iter[ 31/516]\t\tLoss: 2.7157 Acc@1: 53.327%\n","| Epoch [597/1080] Iter[ 46/516]\t\tLoss: 3.0104 Acc@1: 53.487%\n","\n","| Validation Epoch #597\t\t\tLoss: 1.0636 Acc@1: 61.14%\n","\n","=> Training Epoch #598, LR=0.0435\n","| Epoch [598/1080] Iter[  1/516]\t\tLoss: 2.8600 Acc@1: 52.083%\n","| Epoch [598/1080] Iter[ 16/516]\t\tLoss: 2.6316 Acc@1: 53.385%\n","| Epoch [598/1080] Iter[ 31/516]\t\tLoss: 2.7492 Acc@1: 54.335%\n","| Epoch [598/1080] Iter[ 46/516]\t\tLoss: 2.8538 Acc@1: 54.076%\n","\n","| Validation Epoch #598\t\t\tLoss: 0.0146 Acc@1: 65.02%\n","\n","=> Training Epoch #599, LR=0.0434\n","| Epoch [599/1080] Iter[  1/516]\t\tLoss: 2.8873 Acc@1: 57.292%\n","| Epoch [599/1080] Iter[ 16/516]\t\tLoss: 2.5153 Acc@1: 55.339%\n","| Epoch [599/1080] Iter[ 31/516]\t\tLoss: 2.8298 Acc@1: 54.973%\n","| Epoch [599/1080] Iter[ 46/516]\t\tLoss: 2.7534 Acc@1: 54.733%\n","\n","| Validation Epoch #599\t\t\tLoss: 0.4081 Acc@1: 66.56%\n","| New Samples 32653\n","\n","=> Training Epoch #600, LR=0.0434\n","| Epoch [600/1080] Iter[  1/557]\t\tLoss: 2.8947 Acc@1: 47.917%\n","| Epoch [600/1080] Iter[ 16/557]\t\tLoss: 2.7440 Acc@1: 55.273%\n","| Epoch [600/1080] Iter[ 31/557]\t\tLoss: 2.9818 Acc@1: 54.368%\n","| Epoch [600/1080] Iter[ 46/557]\t\tLoss: 2.9658 Acc@1: 54.235%\n","\n","| Validation Epoch #600\t\t\tLoss: 0.0153 Acc@1: 63.48%\n","\n","=> Training Epoch #601, LR=0.0433\n","| Epoch [601/1080] Iter[  1/557]\t\tLoss: 2.8717 Acc@1: 55.208%\n","| Epoch [601/1080] Iter[ 16/557]\t\tLoss: 3.2629 Acc@1: 53.841%\n","| Epoch [601/1080] Iter[ 31/557]\t\tLoss: 3.0249 Acc@1: 53.528%\n","| Epoch [601/1080] Iter[ 46/557]\t\tLoss: 2.8038 Acc@1: 53.623%\n","\n","| Validation Epoch #601\t\t\tLoss: 0.1997 Acc@1: 65.36%\n","\n","=> Training Epoch #602, LR=0.0433\n","| Epoch [602/1080] Iter[  1/557]\t\tLoss: 2.8478 Acc@1: 51.042%\n","| Epoch [602/1080] Iter[ 16/557]\t\tLoss: 2.7490 Acc@1: 53.646%\n","| Epoch [602/1080] Iter[ 31/557]\t\tLoss: 2.5194 Acc@1: 53.360%\n","| Epoch [602/1080] Iter[ 46/557]\t\tLoss: 2.8555 Acc@1: 53.555%\n","\n","| Validation Epoch #602\t\t\tLoss: 0.2528 Acc@1: 67.94%\n","\n","=> Training Epoch #603, LR=0.0432\n","| Epoch [603/1080] Iter[  1/557]\t\tLoss: 2.9079 Acc@1: 56.250%\n","| Epoch [603/1080] Iter[ 16/557]\t\tLoss: 3.0129 Acc@1: 54.427%\n","| Epoch [603/1080] Iter[ 31/557]\t\tLoss: 2.6885 Acc@1: 54.267%\n","| Epoch [603/1080] Iter[ 46/557]\t\tLoss: 3.0763 Acc@1: 53.465%\n","\n","| Validation Epoch #603\t\t\tLoss: 0.2813 Acc@1: 57.54%\n","\n","=> Training Epoch #604, LR=0.0432\n","| Epoch [604/1080] Iter[  1/557]\t\tLoss: 3.0338 Acc@1: 52.083%\n","| Epoch [604/1080] Iter[ 16/557]\t\tLoss: 3.0525 Acc@1: 53.516%\n","| Epoch [604/1080] Iter[ 31/557]\t\tLoss: 3.1403 Acc@1: 53.058%\n","| Epoch [604/1080] Iter[ 46/557]\t\tLoss: 3.0673 Acc@1: 54.099%\n","\n","| Validation Epoch #604\t\t\tLoss: 0.3443 Acc@1: 64.06%\n","\n","=> Training Epoch #605, LR=0.0431\n","| Epoch [605/1080] Iter[  1/557]\t\tLoss: 2.8158 Acc@1: 55.208%\n","| Epoch [605/1080] Iter[ 16/557]\t\tLoss: 2.7126 Acc@1: 54.297%\n","| Epoch [605/1080] Iter[ 31/557]\t\tLoss: 2.7497 Acc@1: 54.503%\n","| Epoch [605/1080] Iter[ 46/557]\t\tLoss: 2.7963 Acc@1: 54.144%\n","\n","| Validation Epoch #605\t\t\tLoss: 0.7237 Acc@1: 63.66%\n","\n","=> Training Epoch #606, LR=0.0431\n","| Epoch [606/1080] Iter[  1/557]\t\tLoss: 3.1676 Acc@1: 51.042%\n","| Epoch [606/1080] Iter[ 16/557]\t\tLoss: 2.8114 Acc@1: 53.841%\n","| Epoch [606/1080] Iter[ 31/557]\t\tLoss: 2.8866 Acc@1: 53.327%\n","| Epoch [606/1080] Iter[ 46/557]\t\tLoss: 3.0898 Acc@1: 53.533%\n","\n","| Validation Epoch #606\t\t\tLoss: 0.1656 Acc@1: 64.34%\n","\n","=> Training Epoch #607, LR=0.0430\n","| Epoch [607/1080] Iter[  1/557]\t\tLoss: 3.0127 Acc@1: 50.000%\n","| Epoch [607/1080] Iter[ 16/557]\t\tLoss: 2.7315 Acc@1: 53.906%\n","| Epoch [607/1080] Iter[ 31/557]\t\tLoss: 2.7596 Acc@1: 54.335%\n","| Epoch [607/1080] Iter[ 46/557]\t\tLoss: 2.9040 Acc@1: 54.303%\n","\n","| Validation Epoch #607\t\t\tLoss: 0.1718 Acc@1: 63.06%\n","\n","=> Training Epoch #608, LR=0.0430\n","| Epoch [608/1080] Iter[  1/557]\t\tLoss: 3.0331 Acc@1: 54.167%\n","| Epoch [608/1080] Iter[ 16/557]\t\tLoss: 2.9044 Acc@1: 54.753%\n","| Epoch [608/1080] Iter[ 31/557]\t\tLoss: 2.8523 Acc@1: 53.360%\n","| Epoch [608/1080] Iter[ 46/557]\t\tLoss: 3.1589 Acc@1: 53.397%\n","\n","| Validation Epoch #608\t\t\tLoss: 0.0266 Acc@1: 64.46%\n","\n","=> Training Epoch #609, LR=0.0429\n","| Epoch [609/1080] Iter[  1/557]\t\tLoss: 2.8342 Acc@1: 56.250%\n","| Epoch [609/1080] Iter[ 16/557]\t\tLoss: 2.9335 Acc@1: 52.995%\n","| Epoch [609/1080] Iter[ 31/557]\t\tLoss: 2.9366 Acc@1: 53.797%\n","| Epoch [609/1080] Iter[ 46/557]\t\tLoss: 3.0367 Acc@1: 54.008%\n","\n","| Validation Epoch #609\t\t\tLoss: 0.0443 Acc@1: 68.38%\n","\n","=> Training Epoch #610, LR=0.0429\n","| Epoch [610/1080] Iter[  1/557]\t\tLoss: 3.0459 Acc@1: 50.000%\n","| Epoch [610/1080] Iter[ 16/557]\t\tLoss: 3.1698 Acc@1: 54.232%\n","| Epoch [610/1080] Iter[ 31/557]\t\tLoss: 2.9102 Acc@1: 54.503%\n","| Epoch [610/1080] Iter[ 46/557]\t\tLoss: 3.0159 Acc@1: 53.986%\n","\n","| Validation Epoch #610\t\t\tLoss: 0.7524 Acc@1: 63.00%\n","\n","=> Training Epoch #611, LR=0.0428\n","| Epoch [611/1080] Iter[  1/557]\t\tLoss: 2.8122 Acc@1: 54.167%\n","| Epoch [611/1080] Iter[ 16/557]\t\tLoss: 2.7038 Acc@1: 52.604%\n","| Epoch [611/1080] Iter[ 31/557]\t\tLoss: 3.2461 Acc@1: 53.293%\n","| Epoch [611/1080] Iter[ 46/557]\t\tLoss: 2.8297 Acc@1: 53.442%\n","\n","| Validation Epoch #611\t\t\tLoss: 0.3221 Acc@1: 63.28%\n","\n","=> Training Epoch #612, LR=0.0428\n","| Epoch [612/1080] Iter[  1/557]\t\tLoss: 2.8815 Acc@1: 55.208%\n","| Epoch [612/1080] Iter[ 16/557]\t\tLoss: 2.8120 Acc@1: 53.125%\n","| Epoch [612/1080] Iter[ 31/557]\t\tLoss: 2.8771 Acc@1: 53.293%\n","| Epoch [612/1080] Iter[ 46/557]\t\tLoss: 2.7368 Acc@1: 53.510%\n","\n","| Validation Epoch #612\t\t\tLoss: 0.3040 Acc@1: 62.20%\n","\n","=> Training Epoch #613, LR=0.0427\n","| Epoch [613/1080] Iter[  1/557]\t\tLoss: 2.7583 Acc@1: 58.333%\n","| Epoch [613/1080] Iter[ 16/557]\t\tLoss: 2.8582 Acc@1: 52.539%\n","| Epoch [613/1080] Iter[ 31/557]\t\tLoss: 2.9661 Acc@1: 53.058%\n","| Epoch [613/1080] Iter[ 46/557]\t\tLoss: 2.7523 Acc@1: 53.510%\n","\n","| Validation Epoch #613\t\t\tLoss: 0.0396 Acc@1: 65.14%\n","\n","=> Training Epoch #614, LR=0.0426\n","| Epoch [614/1080] Iter[  1/557]\t\tLoss: 3.2246 Acc@1: 43.750%\n","| Epoch [614/1080] Iter[ 16/557]\t\tLoss: 2.6387 Acc@1: 52.799%\n","| Epoch [614/1080] Iter[ 31/557]\t\tLoss: 3.2761 Acc@1: 53.226%\n","| Epoch [614/1080] Iter[ 46/557]\t\tLoss: 2.7387 Acc@1: 53.102%\n","\n","| Validation Epoch #614\t\t\tLoss: 0.0006 Acc@1: 63.04%\n","\n","=> Training Epoch #615, LR=0.0426\n","| Epoch [615/1080] Iter[  1/557]\t\tLoss: 3.0951 Acc@1: 56.250%\n","| Epoch [615/1080] Iter[ 16/557]\t\tLoss: 2.8212 Acc@1: 56.706%\n","| Epoch [615/1080] Iter[ 31/557]\t\tLoss: 2.7483 Acc@1: 54.671%\n","| Epoch [615/1080] Iter[ 46/557]\t\tLoss: 3.0088 Acc@1: 54.529%\n","\n","| Validation Epoch #615\t\t\tLoss: 0.1564 Acc@1: 64.42%\n","\n","=> Training Epoch #616, LR=0.0425\n","| Epoch [616/1080] Iter[  1/557]\t\tLoss: 2.9933 Acc@1: 51.042%\n","| Epoch [616/1080] Iter[ 16/557]\t\tLoss: 2.5699 Acc@1: 54.036%\n","| Epoch [616/1080] Iter[ 31/557]\t\tLoss: 3.1260 Acc@1: 53.763%\n","| Epoch [616/1080] Iter[ 46/557]\t\tLoss: 2.9481 Acc@1: 53.442%\n","\n","| Validation Epoch #616\t\t\tLoss: 0.2289 Acc@1: 62.66%\n","\n","=> Training Epoch #617, LR=0.0425\n","| Epoch [617/1080] Iter[  1/557]\t\tLoss: 2.4975 Acc@1: 60.417%\n","| Epoch [617/1080] Iter[ 16/557]\t\tLoss: 2.7869 Acc@1: 54.232%\n","| Epoch [617/1080] Iter[ 31/557]\t\tLoss: 2.7834 Acc@1: 54.637%\n","| Epoch [617/1080] Iter[ 46/557]\t\tLoss: 2.9706 Acc@1: 53.578%\n","\n","| Validation Epoch #617\t\t\tLoss: 0.6741 Acc@1: 61.12%\n","\n","=> Training Epoch #618, LR=0.0424\n","| Epoch [618/1080] Iter[  1/557]\t\tLoss: 3.1782 Acc@1: 50.000%\n","| Epoch [618/1080] Iter[ 16/557]\t\tLoss: 3.1179 Acc@1: 52.865%\n","| Epoch [618/1080] Iter[ 31/557]\t\tLoss: 2.9474 Acc@1: 53.663%\n","| Epoch [618/1080] Iter[ 46/557]\t\tLoss: 2.7261 Acc@1: 54.257%\n","\n","| Validation Epoch #618\t\t\tLoss: 0.0170 Acc@1: 66.88%\n","\n","=> Training Epoch #619, LR=0.0424\n","| Epoch [619/1080] Iter[  1/557]\t\tLoss: 2.7894 Acc@1: 55.208%\n","| Epoch [619/1080] Iter[ 16/557]\t\tLoss: 2.8547 Acc@1: 55.143%\n","| Epoch [619/1080] Iter[ 31/557]\t\tLoss: 3.0062 Acc@1: 54.570%\n","| Epoch [619/1080] Iter[ 46/557]\t\tLoss: 3.2562 Acc@1: 53.691%\n","\n","| Validation Epoch #619\t\t\tLoss: 0.0786 Acc@1: 65.58%\n","\n","=> Training Epoch #620, LR=0.0423\n","| Epoch [620/1080] Iter[  1/557]\t\tLoss: 2.7180 Acc@1: 55.208%\n","| Epoch [620/1080] Iter[ 16/557]\t\tLoss: 2.9206 Acc@1: 53.516%\n","| Epoch [620/1080] Iter[ 31/557]\t\tLoss: 2.6742 Acc@1: 53.763%\n","| Epoch [620/1080] Iter[ 46/557]\t\tLoss: 3.0619 Acc@1: 53.782%\n","\n","| Validation Epoch #620\t\t\tLoss: 0.5561 Acc@1: 63.16%\n","\n","=> Training Epoch #621, LR=0.0423\n","| Epoch [621/1080] Iter[  1/557]\t\tLoss: 3.2681 Acc@1: 44.792%\n","| Epoch [621/1080] Iter[ 16/557]\t\tLoss: 2.5585 Acc@1: 53.906%\n","| Epoch [621/1080] Iter[ 31/557]\t\tLoss: 3.0450 Acc@1: 53.663%\n","| Epoch [621/1080] Iter[ 46/557]\t\tLoss: 2.9459 Acc@1: 53.601%\n","\n","| Validation Epoch #621\t\t\tLoss: 0.2170 Acc@1: 62.26%\n","\n","=> Training Epoch #622, LR=0.0422\n","| Epoch [622/1080] Iter[  1/557]\t\tLoss: 2.7254 Acc@1: 55.208%\n","| Epoch [622/1080] Iter[ 16/557]\t\tLoss: 2.9801 Acc@1: 54.948%\n","| Epoch [622/1080] Iter[ 31/557]\t\tLoss: 3.0830 Acc@1: 53.797%\n","| Epoch [622/1080] Iter[ 46/557]\t\tLoss: 2.7598 Acc@1: 53.736%\n","\n","| Validation Epoch #622\t\t\tLoss: 0.4344 Acc@1: 60.18%\n","\n","=> Training Epoch #623, LR=0.0422\n","| Epoch [623/1080] Iter[  1/557]\t\tLoss: 2.9046 Acc@1: 55.208%\n","| Epoch [623/1080] Iter[ 16/557]\t\tLoss: 3.0118 Acc@1: 54.883%\n","| Epoch [623/1080] Iter[ 31/557]\t\tLoss: 2.8658 Acc@1: 54.435%\n","| Epoch [623/1080] Iter[ 46/557]\t\tLoss: 2.9406 Acc@1: 54.053%\n","\n","| Validation Epoch #623\t\t\tLoss: 0.4710 Acc@1: 59.34%\n","\n","=> Training Epoch #624, LR=0.0421\n","| Epoch [624/1080] Iter[  1/557]\t\tLoss: 3.1656 Acc@1: 46.875%\n","| Epoch [624/1080] Iter[ 16/557]\t\tLoss: 3.1197 Acc@1: 52.865%\n","| Epoch [624/1080] Iter[ 31/557]\t\tLoss: 2.8175 Acc@1: 53.058%\n","| Epoch [624/1080] Iter[ 46/557]\t\tLoss: 3.0329 Acc@1: 53.329%\n","\n","| Validation Epoch #624\t\t\tLoss: 0.5670 Acc@1: 63.84%\n","\n","=> Training Epoch #625, LR=0.0421\n","| Epoch [625/1080] Iter[  1/557]\t\tLoss: 2.8656 Acc@1: 55.208%\n","| Epoch [625/1080] Iter[ 16/557]\t\tLoss: 2.8180 Acc@1: 53.320%\n","| Epoch [625/1080] Iter[ 31/557]\t\tLoss: 2.5337 Acc@1: 53.461%\n","| Epoch [625/1080] Iter[ 46/557]\t\tLoss: 2.6193 Acc@1: 53.804%\n","\n","| Validation Epoch #625\t\t\tLoss: 0.0985 Acc@1: 62.18%\n","\n","=> Training Epoch #626, LR=0.0420\n","| Epoch [626/1080] Iter[  1/557]\t\tLoss: 2.8289 Acc@1: 54.167%\n","| Epoch [626/1080] Iter[ 16/557]\t\tLoss: 2.9202 Acc@1: 51.628%\n","| Epoch [626/1080] Iter[ 31/557]\t\tLoss: 3.1366 Acc@1: 52.789%\n","| Epoch [626/1080] Iter[ 46/557]\t\tLoss: 2.9226 Acc@1: 53.578%\n","\n","| Validation Epoch #626\t\t\tLoss: 1.3171 Acc@1: 67.74%\n","\n","=> Training Epoch #627, LR=0.0419\n","| Epoch [627/1080] Iter[  1/557]\t\tLoss: 2.8854 Acc@1: 53.125%\n","| Epoch [627/1080] Iter[ 16/557]\t\tLoss: 2.8711 Acc@1: 53.711%\n","| Epoch [627/1080] Iter[ 31/557]\t\tLoss: 3.0400 Acc@1: 53.898%\n","| Epoch [627/1080] Iter[ 46/557]\t\tLoss: 2.8367 Acc@1: 53.782%\n","\n","| Validation Epoch #627\t\t\tLoss: 0.0354 Acc@1: 62.26%\n","\n","=> Training Epoch #628, LR=0.0419\n","| Epoch [628/1080] Iter[  1/557]\t\tLoss: 3.0299 Acc@1: 51.042%\n","| Epoch [628/1080] Iter[ 16/557]\t\tLoss: 2.8432 Acc@1: 52.734%\n","| Epoch [628/1080] Iter[ 31/557]\t\tLoss: 3.0598 Acc@1: 53.360%\n","| Epoch [628/1080] Iter[ 46/557]\t\tLoss: 2.9323 Acc@1: 53.080%\n","\n","| Validation Epoch #628\t\t\tLoss: 0.5655 Acc@1: 63.14%\n","\n","=> Training Epoch #629, LR=0.0418\n","| Epoch [629/1080] Iter[  1/557]\t\tLoss: 3.0856 Acc@1: 52.083%\n","| Epoch [629/1080] Iter[ 16/557]\t\tLoss: 2.7306 Acc@1: 54.167%\n","| Epoch [629/1080] Iter[ 31/557]\t\tLoss: 3.1302 Acc@1: 53.797%\n","| Epoch [629/1080] Iter[ 46/557]\t\tLoss: 2.7917 Acc@1: 54.212%\n","\n","| Validation Epoch #629\t\t\tLoss: 0.2116 Acc@1: 63.42%\n","\n","=> Training Epoch #630, LR=0.0418\n","| Epoch [630/1080] Iter[  1/557]\t\tLoss: 2.9272 Acc@1: 59.375%\n","| Epoch [630/1080] Iter[ 16/557]\t\tLoss: 2.7987 Acc@1: 54.818%\n","| Epoch [630/1080] Iter[ 31/557]\t\tLoss: 2.8365 Acc@1: 53.965%\n","| Epoch [630/1080] Iter[ 46/557]\t\tLoss: 2.6928 Acc@1: 54.484%\n","\n","| Validation Epoch #630\t\t\tLoss: 0.1769 Acc@1: 64.38%\n","\n","=> Training Epoch #631, LR=0.0417\n","| Epoch [631/1080] Iter[  1/557]\t\tLoss: 2.8334 Acc@1: 56.250%\n","| Epoch [631/1080] Iter[ 16/557]\t\tLoss: 2.7906 Acc@1: 54.427%\n","| Epoch [631/1080] Iter[ 31/557]\t\tLoss: 2.9355 Acc@1: 53.965%\n","| Epoch [631/1080] Iter[ 46/557]\t\tLoss: 3.1471 Acc@1: 53.465%\n","\n","| Validation Epoch #631\t\t\tLoss: 0.3027 Acc@1: 66.16%\n","\n","=> Training Epoch #632, LR=0.0417\n","| Epoch [632/1080] Iter[  1/557]\t\tLoss: 2.6272 Acc@1: 61.458%\n","| Epoch [632/1080] Iter[ 16/557]\t\tLoss: 2.8918 Acc@1: 54.362%\n","| Epoch [632/1080] Iter[ 31/557]\t\tLoss: 3.1958 Acc@1: 53.595%\n","| Epoch [632/1080] Iter[ 46/557]\t\tLoss: 3.0794 Acc@1: 53.125%\n","\n","| Validation Epoch #632\t\t\tLoss: 0.3829 Acc@1: 51.40%\n","\n","=> Training Epoch #633, LR=0.0416\n","| Epoch [633/1080] Iter[  1/557]\t\tLoss: 2.8944 Acc@1: 57.292%\n","| Epoch [633/1080] Iter[ 16/557]\t\tLoss: 3.0192 Acc@1: 54.232%\n","| Epoch [633/1080] Iter[ 31/557]\t\tLoss: 2.8374 Acc@1: 55.175%\n","| Epoch [633/1080] Iter[ 46/557]\t\tLoss: 3.1715 Acc@1: 54.438%\n","\n","| Validation Epoch #633\t\t\tLoss: 0.1958 Acc@1: 59.10%\n","\n","=> Training Epoch #634, LR=0.0416\n","| Epoch [634/1080] Iter[  1/557]\t\tLoss: 2.8428 Acc@1: 54.167%\n","| Epoch [634/1080] Iter[ 16/557]\t\tLoss: 2.7067 Acc@1: 54.036%\n","| Epoch [634/1080] Iter[ 31/557]\t\tLoss: 2.7638 Acc@1: 54.099%\n","| Epoch [634/1080] Iter[ 46/557]\t\tLoss: 2.8545 Acc@1: 53.533%\n","\n","| Validation Epoch #634\t\t\tLoss: 0.0810 Acc@1: 66.12%\n","\n","=> Training Epoch #635, LR=0.0415\n","| Epoch [635/1080] Iter[  1/557]\t\tLoss: 2.9120 Acc@1: 50.000%\n","| Epoch [635/1080] Iter[ 16/557]\t\tLoss: 2.7165 Acc@1: 52.995%\n","| Epoch [635/1080] Iter[ 31/557]\t\tLoss: 2.7960 Acc@1: 54.435%\n","| Epoch [635/1080] Iter[ 46/557]\t\tLoss: 3.0095 Acc@1: 53.691%\n","\n","| Validation Epoch #635\t\t\tLoss: 0.8777 Acc@1: 65.22%\n","\n","=> Training Epoch #636, LR=0.0415\n","| Epoch [636/1080] Iter[  1/557]\t\tLoss: 2.7731 Acc@1: 65.625%\n","| Epoch [636/1080] Iter[ 16/557]\t\tLoss: 2.8111 Acc@1: 55.273%\n","| Epoch [636/1080] Iter[ 31/557]\t\tLoss: 3.2431 Acc@1: 54.099%\n","| Epoch [636/1080] Iter[ 46/557]\t\tLoss: 2.7389 Acc@1: 54.280%\n","\n","| Validation Epoch #636\t\t\tLoss: 0.0214 Acc@1: 63.56%\n","\n","=> Training Epoch #637, LR=0.0414\n","| Epoch [637/1080] Iter[  1/557]\t\tLoss: 3.0100 Acc@1: 56.250%\n","| Epoch [637/1080] Iter[ 16/557]\t\tLoss: 2.8284 Acc@1: 53.776%\n","| Epoch [637/1080] Iter[ 31/557]\t\tLoss: 3.0684 Acc@1: 53.024%\n","| Epoch [637/1080] Iter[ 46/557]\t\tLoss: 2.8691 Acc@1: 53.419%\n","\n","| Validation Epoch #637\t\t\tLoss: 0.1070 Acc@1: 64.72%\n","\n","=> Training Epoch #638, LR=0.0413\n","| Epoch [638/1080] Iter[  1/557]\t\tLoss: 2.9044 Acc@1: 56.250%\n","| Epoch [638/1080] Iter[ 16/557]\t\tLoss: 2.7183 Acc@1: 52.474%\n","| Epoch [638/1080] Iter[ 31/557]\t\tLoss: 2.8675 Acc@1: 52.319%\n","| Epoch [638/1080] Iter[ 46/557]\t\tLoss: 2.6454 Acc@1: 53.351%\n","\n","| Validation Epoch #638\t\t\tLoss: 0.0453 Acc@1: 64.30%\n","\n","=> Training Epoch #639, LR=0.0413\n","| Epoch [639/1080] Iter[  1/557]\t\tLoss: 3.0695 Acc@1: 52.083%\n","| Epoch [639/1080] Iter[ 16/557]\t\tLoss: 3.0283 Acc@1: 52.409%\n","| Epoch [639/1080] Iter[ 31/557]\t\tLoss: 2.9599 Acc@1: 53.058%\n","| Epoch [639/1080] Iter[ 46/557]\t\tLoss: 2.9931 Acc@1: 52.876%\n","\n","| Validation Epoch #639\t\t\tLoss: 0.1277 Acc@1: 66.02%\n","\n","=> Training Epoch #640, LR=0.0412\n","| Epoch [640/1080] Iter[  1/557]\t\tLoss: 2.7714 Acc@1: 58.333%\n","| Epoch [640/1080] Iter[ 16/557]\t\tLoss: 2.9662 Acc@1: 52.734%\n","| Epoch [640/1080] Iter[ 31/557]\t\tLoss: 2.7405 Acc@1: 54.066%\n","| Epoch [640/1080] Iter[ 46/557]\t\tLoss: 3.1405 Acc@1: 54.099%\n","\n","| Validation Epoch #640\t\t\tLoss: 0.2363 Acc@1: 69.40%\n","| Saving Best model...\t\t\tTop1 = 69.40%\n","\n","=> Training Epoch #641, LR=0.0412\n","| Epoch [641/1080] Iter[  1/557]\t\tLoss: 2.6482 Acc@1: 56.250%\n","| Epoch [641/1080] Iter[ 16/557]\t\tLoss: 3.1058 Acc@1: 52.930%\n","| Epoch [641/1080] Iter[ 31/557]\t\tLoss: 2.9765 Acc@1: 53.495%\n","| Epoch [641/1080] Iter[ 46/557]\t\tLoss: 2.6851 Acc@1: 53.329%\n","\n","| Validation Epoch #641\t\t\tLoss: 0.2319 Acc@1: 59.64%\n","\n","=> Training Epoch #642, LR=0.0411\n","| Epoch [642/1080] Iter[  1/557]\t\tLoss: 2.7877 Acc@1: 54.167%\n","| Epoch [642/1080] Iter[ 16/557]\t\tLoss: 2.8795 Acc@1: 54.102%\n","| Epoch [642/1080] Iter[ 31/557]\t\tLoss: 2.7077 Acc@1: 54.872%\n","| Epoch [642/1080] Iter[ 46/557]\t\tLoss: 3.0820 Acc@1: 54.552%\n","\n","| Validation Epoch #642\t\t\tLoss: 0.0008 Acc@1: 62.64%\n","\n","=> Training Epoch #643, LR=0.0411\n","| Epoch [643/1080] Iter[  1/557]\t\tLoss: 2.7011 Acc@1: 58.333%\n","| Epoch [643/1080] Iter[ 16/557]\t\tLoss: 3.2177 Acc@1: 55.013%\n","| Epoch [643/1080] Iter[ 31/557]\t\tLoss: 2.9569 Acc@1: 53.999%\n","| Epoch [643/1080] Iter[ 46/557]\t\tLoss: 2.8474 Acc@1: 53.963%\n","\n","| Validation Epoch #643\t\t\tLoss: 0.1924 Acc@1: 63.10%\n","\n","=> Training Epoch #644, LR=0.0410\n","| Epoch [644/1080] Iter[  1/557]\t\tLoss: 2.9372 Acc@1: 52.083%\n","| Epoch [644/1080] Iter[ 16/557]\t\tLoss: 2.4123 Acc@1: 54.492%\n","| Epoch [644/1080] Iter[ 31/557]\t\tLoss: 3.1814 Acc@1: 54.435%\n","| Epoch [644/1080] Iter[ 46/557]\t\tLoss: 2.9743 Acc@1: 53.918%\n","\n","| Validation Epoch #644\t\t\tLoss: 0.0025 Acc@1: 62.96%\n","\n","=> Training Epoch #645, LR=0.0410\n","| Epoch [645/1080] Iter[  1/557]\t\tLoss: 2.7845 Acc@1: 60.417%\n","| Epoch [645/1080] Iter[ 16/557]\t\tLoss: 3.1430 Acc@1: 53.255%\n","| Epoch [645/1080] Iter[ 31/557]\t\tLoss: 2.8956 Acc@1: 53.528%\n","| Epoch [645/1080] Iter[ 46/557]\t\tLoss: 2.7530 Acc@1: 53.850%\n","\n","| Validation Epoch #645\t\t\tLoss: 0.1522 Acc@1: 63.42%\n","\n","=> Training Epoch #646, LR=0.0409\n","| Epoch [646/1080] Iter[  1/557]\t\tLoss: 2.9574 Acc@1: 48.958%\n","| Epoch [646/1080] Iter[ 16/557]\t\tLoss: 2.8716 Acc@1: 53.516%\n","| Epoch [646/1080] Iter[ 31/557]\t\tLoss: 2.9762 Acc@1: 53.763%\n","| Epoch [646/1080] Iter[ 46/557]\t\tLoss: 2.8610 Acc@1: 53.601%\n","\n","| Validation Epoch #646\t\t\tLoss: 0.2721 Acc@1: 66.68%\n","\n","=> Training Epoch #647, LR=0.0408\n","| Epoch [647/1080] Iter[  1/557]\t\tLoss: 2.8892 Acc@1: 53.125%\n","| Epoch [647/1080] Iter[ 16/557]\t\tLoss: 3.2720 Acc@1: 51.693%\n","| Epoch [647/1080] Iter[ 31/557]\t\tLoss: 2.4451 Acc@1: 52.755%\n","| Epoch [647/1080] Iter[ 46/557]\t\tLoss: 2.7541 Acc@1: 52.808%\n","\n","| Validation Epoch #647\t\t\tLoss: 0.8159 Acc@1: 61.70%\n","\n","=> Training Epoch #648, LR=0.0408\n","| Epoch [648/1080] Iter[  1/557]\t\tLoss: 3.1064 Acc@1: 44.792%\n","| Epoch [648/1080] Iter[ 16/557]\t\tLoss: 2.8714 Acc@1: 54.557%\n","| Epoch [648/1080] Iter[ 31/557]\t\tLoss: 2.8149 Acc@1: 54.200%\n","| Epoch [648/1080] Iter[ 46/557]\t\tLoss: 2.9497 Acc@1: 53.827%\n","\n","| Validation Epoch #648\t\t\tLoss: 0.3464 Acc@1: 63.44%\n","\n","=> Training Epoch #649, LR=0.0407\n","| Epoch [649/1080] Iter[  1/557]\t\tLoss: 2.7280 Acc@1: 59.375%\n","| Epoch [649/1080] Iter[ 16/557]\t\tLoss: 2.8638 Acc@1: 55.273%\n","| Epoch [649/1080] Iter[ 31/557]\t\tLoss: 2.6697 Acc@1: 54.167%\n","| Epoch [649/1080] Iter[ 46/557]\t\tLoss: 2.8162 Acc@1: 54.099%\n","\n","| Validation Epoch #649\t\t\tLoss: 0.6696 Acc@1: 65.08%\n","\n","=> Training Epoch #650, LR=0.0407\n","| Epoch [650/1080] Iter[  1/557]\t\tLoss: 2.9130 Acc@1: 53.125%\n","| Epoch [650/1080] Iter[ 16/557]\t\tLoss: 2.7787 Acc@1: 54.167%\n","| Epoch [650/1080] Iter[ 31/557]\t\tLoss: 3.2436 Acc@1: 53.931%\n","| Epoch [650/1080] Iter[ 46/557]\t\tLoss: 2.8355 Acc@1: 53.555%\n","\n","| Validation Epoch #650\t\t\tLoss: 0.3849 Acc@1: 66.38%\n","\n","=> Training Epoch #651, LR=0.0406\n","| Epoch [651/1080] Iter[  1/557]\t\tLoss: 3.1679 Acc@1: 46.875%\n","| Epoch [651/1080] Iter[ 16/557]\t\tLoss: 3.3026 Acc@1: 54.557%\n","| Epoch [651/1080] Iter[ 31/557]\t\tLoss: 2.8057 Acc@1: 54.066%\n","| Epoch [651/1080] Iter[ 46/557]\t\tLoss: 2.8485 Acc@1: 53.804%\n","\n","| Validation Epoch #651\t\t\tLoss: 0.0471 Acc@1: 63.54%\n","\n","=> Training Epoch #652, LR=0.0406\n","| Epoch [652/1080] Iter[  1/557]\t\tLoss: 2.7616 Acc@1: 57.292%\n","| Epoch [652/1080] Iter[ 16/557]\t\tLoss: 2.8122 Acc@1: 54.036%\n","| Epoch [652/1080] Iter[ 31/557]\t\tLoss: 2.9186 Acc@1: 54.167%\n","| Epoch [652/1080] Iter[ 46/557]\t\tLoss: 3.0474 Acc@1: 54.076%\n","\n","| Validation Epoch #652\t\t\tLoss: 0.0014 Acc@1: 60.52%\n","\n","=> Training Epoch #653, LR=0.0405\n","| Epoch [653/1080] Iter[  1/557]\t\tLoss: 2.6456 Acc@1: 58.333%\n","| Epoch [653/1080] Iter[ 16/557]\t\tLoss: 2.9119 Acc@1: 55.990%\n","| Epoch [653/1080] Iter[ 31/557]\t\tLoss: 3.0525 Acc@1: 53.898%\n","| Epoch [653/1080] Iter[ 46/557]\t\tLoss: 3.0117 Acc@1: 53.623%\n","\n","| Validation Epoch #653\t\t\tLoss: 0.1352 Acc@1: 63.38%\n","\n","=> Training Epoch #654, LR=0.0404\n","| Epoch [654/1080] Iter[  1/557]\t\tLoss: 2.7934 Acc@1: 55.208%\n","| Epoch [654/1080] Iter[ 16/557]\t\tLoss: 3.0934 Acc@1: 55.339%\n","| Epoch [654/1080] Iter[ 31/557]\t\tLoss: 2.5749 Acc@1: 54.603%\n","| Epoch [654/1080] Iter[ 46/557]\t\tLoss: 2.7717 Acc@1: 53.986%\n","\n","| Validation Epoch #654\t\t\tLoss: 0.0587 Acc@1: 59.88%\n","\n","=> Training Epoch #655, LR=0.0404\n","| Epoch [655/1080] Iter[  1/557]\t\tLoss: 2.7836 Acc@1: 57.292%\n","| Epoch [655/1080] Iter[ 16/557]\t\tLoss: 2.8550 Acc@1: 53.711%\n","| Epoch [655/1080] Iter[ 31/557]\t\tLoss: 3.0787 Acc@1: 53.327%\n","| Epoch [655/1080] Iter[ 46/557]\t\tLoss: 2.8807 Acc@1: 53.601%\n","\n","| Validation Epoch #655\t\t\tLoss: 0.0470 Acc@1: 64.54%\n","\n","=> Training Epoch #656, LR=0.0403\n","| Epoch [656/1080] Iter[  1/557]\t\tLoss: 3.0775 Acc@1: 51.042%\n","| Epoch [656/1080] Iter[ 16/557]\t\tLoss: 2.8403 Acc@1: 52.995%\n","| Epoch [656/1080] Iter[ 31/557]\t\tLoss: 2.7180 Acc@1: 53.528%\n","| Epoch [656/1080] Iter[ 46/557]\t\tLoss: 2.6912 Acc@1: 53.986%\n","\n","| Validation Epoch #656\t\t\tLoss: 0.2247 Acc@1: 69.48%\n","| Saving Best model...\t\t\tTop1 = 69.48%\n","\n","=> Training Epoch #657, LR=0.0403\n","| Epoch [657/1080] Iter[  1/557]\t\tLoss: 2.6950 Acc@1: 63.542%\n","| Epoch [657/1080] Iter[ 16/557]\t\tLoss: 2.7982 Acc@1: 54.036%\n","| Epoch [657/1080] Iter[ 31/557]\t\tLoss: 3.0429 Acc@1: 53.999%\n","| Epoch [657/1080] Iter[ 46/557]\t\tLoss: 2.6237 Acc@1: 54.212%\n","\n","| Validation Epoch #657\t\t\tLoss: 0.3484 Acc@1: 62.56%\n","\n","=> Training Epoch #658, LR=0.0402\n","| Epoch [658/1080] Iter[  1/557]\t\tLoss: 3.1325 Acc@1: 47.917%\n","| Epoch [658/1080] Iter[ 16/557]\t\tLoss: 3.1217 Acc@1: 52.734%\n","| Epoch [658/1080] Iter[ 31/557]\t\tLoss: 2.9018 Acc@1: 53.495%\n","| Epoch [658/1080] Iter[ 46/557]\t\tLoss: 2.6106 Acc@1: 53.759%\n","\n","| Validation Epoch #658\t\t\tLoss: 0.0017 Acc@1: 58.98%\n","\n","=> Training Epoch #659, LR=0.0402\n","| Epoch [659/1080] Iter[  1/557]\t\tLoss: 2.8747 Acc@1: 54.167%\n","| Epoch [659/1080] Iter[ 16/557]\t\tLoss: 2.8433 Acc@1: 53.711%\n","| Epoch [659/1080] Iter[ 31/557]\t\tLoss: 2.5835 Acc@1: 55.040%\n","| Epoch [659/1080] Iter[ 46/557]\t\tLoss: 2.8750 Acc@1: 54.552%\n","\n","| Validation Epoch #659\t\t\tLoss: 0.1568 Acc@1: 62.84%\n","\n","=> Training Epoch #660, LR=0.0401\n","| Epoch [660/1080] Iter[  1/557]\t\tLoss: 2.6289 Acc@1: 62.500%\n","| Epoch [660/1080] Iter[ 16/557]\t\tLoss: 3.0060 Acc@1: 53.190%\n","| Epoch [660/1080] Iter[ 31/557]\t\tLoss: 3.0139 Acc@1: 54.200%\n","| Epoch [660/1080] Iter[ 46/557]\t\tLoss: 2.9808 Acc@1: 53.419%\n","\n","| Validation Epoch #660\t\t\tLoss: 0.2563 Acc@1: 67.28%\n","\n","=> Training Epoch #661, LR=0.0401\n","| Epoch [661/1080] Iter[  1/557]\t\tLoss: 3.2525 Acc@1: 42.708%\n","| Epoch [661/1080] Iter[ 16/557]\t\tLoss: 2.8543 Acc@1: 54.688%\n","| Epoch [661/1080] Iter[ 31/557]\t\tLoss: 2.8224 Acc@1: 54.368%\n","| Epoch [661/1080] Iter[ 46/557]\t\tLoss: 3.0072 Acc@1: 54.461%\n","\n","| Validation Epoch #661\t\t\tLoss: 0.0134 Acc@1: 60.98%\n","\n","=> Training Epoch #662, LR=0.0400\n","| Epoch [662/1080] Iter[  1/557]\t\tLoss: 3.2748 Acc@1: 40.625%\n","| Epoch [662/1080] Iter[ 16/557]\t\tLoss: 2.5638 Acc@1: 53.190%\n","| Epoch [662/1080] Iter[ 31/557]\t\tLoss: 2.7280 Acc@1: 53.461%\n","| Epoch [662/1080] Iter[ 46/557]\t\tLoss: 3.1008 Acc@1: 53.850%\n","\n","| Validation Epoch #662\t\t\tLoss: 0.1717 Acc@1: 65.60%\n","\n","=> Training Epoch #663, LR=0.0399\n","| Epoch [663/1080] Iter[  1/557]\t\tLoss: 2.6919 Acc@1: 64.583%\n","| Epoch [663/1080] Iter[ 16/557]\t\tLoss: 3.0102 Acc@1: 54.948%\n","| Epoch [663/1080] Iter[ 31/557]\t\tLoss: 3.0180 Acc@1: 53.931%\n","| Epoch [663/1080] Iter[ 46/557]\t\tLoss: 2.7115 Acc@1: 54.325%\n","\n","| Validation Epoch #663\t\t\tLoss: 1.7361 Acc@1: 55.88%\n","\n","=> Training Epoch #664, LR=0.0399\n","| Epoch [664/1080] Iter[  1/557]\t\tLoss: 2.5671 Acc@1: 62.500%\n","| Epoch [664/1080] Iter[ 16/557]\t\tLoss: 2.8296 Acc@1: 52.865%\n","| Epoch [664/1080] Iter[ 31/557]\t\tLoss: 3.1245 Acc@1: 53.226%\n","| Epoch [664/1080] Iter[ 46/557]\t\tLoss: 2.7710 Acc@1: 53.306%\n","\n","| Validation Epoch #664\t\t\tLoss: 0.0033 Acc@1: 65.50%\n","\n","=> Training Epoch #665, LR=0.0398\n","| Epoch [665/1080] Iter[  1/557]\t\tLoss: 2.8721 Acc@1: 52.083%\n","| Epoch [665/1080] Iter[ 16/557]\t\tLoss: 3.2882 Acc@1: 53.451%\n","| Epoch [665/1080] Iter[ 31/557]\t\tLoss: 2.7036 Acc@1: 52.319%\n","| Epoch [665/1080] Iter[ 46/557]\t\tLoss: 3.1078 Acc@1: 52.264%\n","\n","| Validation Epoch #665\t\t\tLoss: 0.1837 Acc@1: 67.56%\n","\n","=> Training Epoch #666, LR=0.0398\n","| Epoch [666/1080] Iter[  1/557]\t\tLoss: 3.2643 Acc@1: 42.708%\n","| Epoch [666/1080] Iter[ 16/557]\t\tLoss: 2.8284 Acc@1: 52.409%\n","| Epoch [666/1080] Iter[ 31/557]\t\tLoss: 2.9299 Acc@1: 53.293%\n","| Epoch [666/1080] Iter[ 46/557]\t\tLoss: 2.9758 Acc@1: 53.533%\n","\n","| Validation Epoch #666\t\t\tLoss: 0.3412 Acc@1: 60.18%\n","\n","=> Training Epoch #667, LR=0.0397\n","| Epoch [667/1080] Iter[  1/557]\t\tLoss: 3.0646 Acc@1: 51.042%\n","| Epoch [667/1080] Iter[ 16/557]\t\tLoss: 2.9650 Acc@1: 54.883%\n","| Epoch [667/1080] Iter[ 31/557]\t\tLoss: 2.7411 Acc@1: 53.595%\n","| Epoch [667/1080] Iter[ 46/557]\t\tLoss: 2.8663 Acc@1: 54.189%\n","\n","| Validation Epoch #667\t\t\tLoss: 0.0609 Acc@1: 66.16%\n","\n","=> Training Epoch #668, LR=0.0397\n","| Epoch [668/1080] Iter[  1/557]\t\tLoss: 3.1002 Acc@1: 57.292%\n","| Epoch [668/1080] Iter[ 16/557]\t\tLoss: 2.8875 Acc@1: 55.339%\n","| Epoch [668/1080] Iter[ 31/557]\t\tLoss: 3.0610 Acc@1: 54.267%\n","| Epoch [668/1080] Iter[ 46/557]\t\tLoss: 2.8811 Acc@1: 54.665%\n","\n","| Validation Epoch #668\t\t\tLoss: 0.0075 Acc@1: 65.06%\n","\n","=> Training Epoch #669, LR=0.0396\n","| Epoch [669/1080] Iter[  1/557]\t\tLoss: 2.7573 Acc@1: 58.333%\n","| Epoch [669/1080] Iter[ 16/557]\t\tLoss: 2.7968 Acc@1: 53.190%\n","| Epoch [669/1080] Iter[ 31/557]\t\tLoss: 2.9216 Acc@1: 53.495%\n","| Epoch [669/1080] Iter[ 46/557]\t\tLoss: 2.7635 Acc@1: 53.986%\n","\n","| Validation Epoch #669\t\t\tLoss: 0.1803 Acc@1: 62.80%\n","\n","=> Training Epoch #670, LR=0.0395\n","| Epoch [670/1080] Iter[  1/557]\t\tLoss: 2.7949 Acc@1: 57.292%\n","| Epoch [670/1080] Iter[ 16/557]\t\tLoss: 2.8641 Acc@1: 54.297%\n","| Epoch [670/1080] Iter[ 31/557]\t\tLoss: 3.0387 Acc@1: 54.167%\n","| Epoch [670/1080] Iter[ 46/557]\t\tLoss: 3.1131 Acc@1: 54.370%\n","\n","| Validation Epoch #670\t\t\tLoss: 0.1002 Acc@1: 63.54%\n","\n","=> Training Epoch #671, LR=0.0395\n","| Epoch [671/1080] Iter[  1/557]\t\tLoss: 2.6774 Acc@1: 57.292%\n","| Epoch [671/1080] Iter[ 16/557]\t\tLoss: 3.0087 Acc@1: 53.971%\n","| Epoch [671/1080] Iter[ 31/557]\t\tLoss: 3.1482 Acc@1: 54.167%\n","| Epoch [671/1080] Iter[ 46/557]\t\tLoss: 2.9133 Acc@1: 53.193%\n","\n","| Validation Epoch #671\t\t\tLoss: 0.0312 Acc@1: 61.40%\n","\n","=> Training Epoch #672, LR=0.0394\n","| Epoch [672/1080] Iter[  1/557]\t\tLoss: 2.6846 Acc@1: 56.250%\n","| Epoch [672/1080] Iter[ 16/557]\t\tLoss: 2.7613 Acc@1: 55.078%\n","| Epoch [672/1080] Iter[ 31/557]\t\tLoss: 3.1103 Acc@1: 54.637%\n","| Epoch [672/1080] Iter[ 46/557]\t\tLoss: 3.1185 Acc@1: 54.642%\n","\n","| Validation Epoch #672\t\t\tLoss: 0.3070 Acc@1: 64.52%\n","\n","=> Training Epoch #673, LR=0.0394\n","| Epoch [673/1080] Iter[  1/557]\t\tLoss: 3.0512 Acc@1: 51.042%\n","| Epoch [673/1080] Iter[ 16/557]\t\tLoss: 2.6815 Acc@1: 54.557%\n","| Epoch [673/1080] Iter[ 31/557]\t\tLoss: 2.9472 Acc@1: 53.427%\n","| Epoch [673/1080] Iter[ 46/557]\t\tLoss: 3.3435 Acc@1: 53.261%\n","\n","| Validation Epoch #673\t\t\tLoss: 1.2060 Acc@1: 57.42%\n","\n","=> Training Epoch #674, LR=0.0393\n","| Epoch [674/1080] Iter[  1/557]\t\tLoss: 2.9478 Acc@1: 55.208%\n","| Epoch [674/1080] Iter[ 16/557]\t\tLoss: 2.6942 Acc@1: 55.924%\n","| Epoch [674/1080] Iter[ 31/557]\t\tLoss: 2.6902 Acc@1: 54.133%\n","| Epoch [674/1080] Iter[ 46/557]\t\tLoss: 3.0103 Acc@1: 53.895%\n","\n","| Validation Epoch #674\t\t\tLoss: 0.4109 Acc@1: 62.34%\n","\n","=> Training Epoch #675, LR=0.0392\n","| Epoch [675/1080] Iter[  1/557]\t\tLoss: 2.8637 Acc@1: 52.083%\n","| Epoch [675/1080] Iter[ 16/557]\t\tLoss: 3.1290 Acc@1: 55.273%\n","| Epoch [675/1080] Iter[ 31/557]\t\tLoss: 3.2138 Acc@1: 53.965%\n","| Epoch [675/1080] Iter[ 46/557]\t\tLoss: 3.0040 Acc@1: 53.623%\n","\n","| Validation Epoch #675\t\t\tLoss: 0.0579 Acc@1: 62.46%\n","\n","=> Training Epoch #676, LR=0.0392\n","| Epoch [676/1080] Iter[  1/557]\t\tLoss: 2.7921 Acc@1: 52.083%\n","| Epoch [676/1080] Iter[ 16/557]\t\tLoss: 2.8426 Acc@1: 53.190%\n","| Epoch [676/1080] Iter[ 31/557]\t\tLoss: 2.8777 Acc@1: 54.738%\n","| Epoch [676/1080] Iter[ 46/557]\t\tLoss: 2.6536 Acc@1: 54.597%\n","\n","| Validation Epoch #676\t\t\tLoss: 0.8525 Acc@1: 62.28%\n","\n","=> Training Epoch #677, LR=0.0391\n","| Epoch [677/1080] Iter[  1/557]\t\tLoss: 2.8928 Acc@1: 56.250%\n","| Epoch [677/1080] Iter[ 16/557]\t\tLoss: 2.7314 Acc@1: 54.883%\n","| Epoch [677/1080] Iter[ 31/557]\t\tLoss: 2.6212 Acc@1: 53.831%\n","| Epoch [677/1080] Iter[ 46/557]\t\tLoss: 2.4063 Acc@1: 54.484%\n","\n","| Validation Epoch #677\t\t\tLoss: 0.0565 Acc@1: 65.36%\n","\n","=> Training Epoch #678, LR=0.0391\n","| Epoch [678/1080] Iter[  1/557]\t\tLoss: 2.9658 Acc@1: 52.083%\n","| Epoch [678/1080] Iter[ 16/557]\t\tLoss: 2.8495 Acc@1: 54.557%\n","| Epoch [678/1080] Iter[ 31/557]\t\tLoss: 2.9554 Acc@1: 54.099%\n","| Epoch [678/1080] Iter[ 46/557]\t\tLoss: 2.7900 Acc@1: 54.620%\n","\n","| Validation Epoch #678\t\t\tLoss: 0.3473 Acc@1: 60.14%\n","\n","=> Training Epoch #679, LR=0.0390\n","| Epoch [679/1080] Iter[  1/557]\t\tLoss: 2.5896 Acc@1: 59.375%\n","| Epoch [679/1080] Iter[ 16/557]\t\tLoss: 2.8801 Acc@1: 53.841%\n","| Epoch [679/1080] Iter[ 31/557]\t\tLoss: 2.6077 Acc@1: 53.831%\n","| Epoch [679/1080] Iter[ 46/557]\t\tLoss: 2.8922 Acc@1: 53.827%\n","\n","| Validation Epoch #679\t\t\tLoss: 0.0372 Acc@1: 59.72%\n","\n","=> Training Epoch #680, LR=0.0390\n","| Epoch [680/1080] Iter[  1/557]\t\tLoss: 2.8826 Acc@1: 55.208%\n","| Epoch [680/1080] Iter[ 16/557]\t\tLoss: 3.0328 Acc@1: 53.516%\n","| Epoch [680/1080] Iter[ 31/557]\t\tLoss: 2.5022 Acc@1: 54.267%\n","| Epoch [680/1080] Iter[ 46/557]\t\tLoss: 2.5543 Acc@1: 54.280%\n","\n","| Validation Epoch #680\t\t\tLoss: 0.0028 Acc@1: 63.46%\n","\n","=> Training Epoch #681, LR=0.0389\n","| Epoch [681/1080] Iter[  1/557]\t\tLoss: 3.2312 Acc@1: 43.750%\n","| Epoch [681/1080] Iter[ 16/557]\t\tLoss: 2.6003 Acc@1: 55.013%\n","| Epoch [681/1080] Iter[ 31/557]\t\tLoss: 2.8415 Acc@1: 54.671%\n","| Epoch [681/1080] Iter[ 46/557]\t\tLoss: 3.2121 Acc@1: 53.827%\n","\n","| Validation Epoch #681\t\t\tLoss: 0.0112 Acc@1: 65.24%\n","\n","=> Training Epoch #682, LR=0.0388\n","| Epoch [682/1080] Iter[  1/557]\t\tLoss: 2.4812 Acc@1: 62.500%\n","| Epoch [682/1080] Iter[ 16/557]\t\tLoss: 3.1048 Acc@1: 54.948%\n","| Epoch [682/1080] Iter[ 31/557]\t\tLoss: 2.9912 Acc@1: 53.999%\n","| Epoch [682/1080] Iter[ 46/557]\t\tLoss: 2.7775 Acc@1: 54.076%\n","\n","| Validation Epoch #682\t\t\tLoss: 0.0118 Acc@1: 67.28%\n","\n","=> Training Epoch #683, LR=0.0388\n","| Epoch [683/1080] Iter[  1/557]\t\tLoss: 2.8989 Acc@1: 57.292%\n","| Epoch [683/1080] Iter[ 16/557]\t\tLoss: 2.5911 Acc@1: 55.404%\n","| Epoch [683/1080] Iter[ 31/557]\t\tLoss: 2.9894 Acc@1: 53.999%\n","| Epoch [683/1080] Iter[ 46/557]\t\tLoss: 2.8972 Acc@1: 54.235%\n","\n","| Validation Epoch #683\t\t\tLoss: 0.0008 Acc@1: 67.54%\n","\n","=> Training Epoch #684, LR=0.0387\n","| Epoch [684/1080] Iter[  1/557]\t\tLoss: 2.9013 Acc@1: 51.042%\n","| Epoch [684/1080] Iter[ 16/557]\t\tLoss: 3.0806 Acc@1: 55.339%\n","| Epoch [684/1080] Iter[ 31/557]\t\tLoss: 2.9130 Acc@1: 54.335%\n","| Epoch [684/1080] Iter[ 46/557]\t\tLoss: 2.8842 Acc@1: 54.642%\n","\n","| Validation Epoch #684\t\t\tLoss: 0.0701 Acc@1: 67.24%\n","\n","=> Training Epoch #685, LR=0.0387\n","| Epoch [685/1080] Iter[  1/557]\t\tLoss: 2.6414 Acc@1: 61.458%\n","| Epoch [685/1080] Iter[ 16/557]\t\tLoss: 2.6558 Acc@1: 56.380%\n","| Epoch [685/1080] Iter[ 31/557]\t\tLoss: 3.1746 Acc@1: 55.040%\n","| Epoch [685/1080] Iter[ 46/557]\t\tLoss: 3.0837 Acc@1: 54.008%\n","\n","| Validation Epoch #685\t\t\tLoss: 0.3646 Acc@1: 59.50%\n","\n","=> Training Epoch #686, LR=0.0386\n","| Epoch [686/1080] Iter[  1/557]\t\tLoss: 3.1381 Acc@1: 47.917%\n","| Epoch [686/1080] Iter[ 16/557]\t\tLoss: 2.9530 Acc@1: 53.190%\n","| Epoch [686/1080] Iter[ 31/557]\t\tLoss: 3.0708 Acc@1: 53.898%\n","| Epoch [686/1080] Iter[ 46/557]\t\tLoss: 2.9667 Acc@1: 53.759%\n","\n","| Validation Epoch #686\t\t\tLoss: 0.0012 Acc@1: 63.42%\n","\n","=> Training Epoch #687, LR=0.0386\n","| Epoch [687/1080] Iter[  1/557]\t\tLoss: 2.9073 Acc@1: 56.250%\n","| Epoch [687/1080] Iter[ 16/557]\t\tLoss: 3.1253 Acc@1: 52.344%\n","| Epoch [687/1080] Iter[ 31/557]\t\tLoss: 2.5191 Acc@1: 53.965%\n","| Epoch [687/1080] Iter[ 46/557]\t\tLoss: 2.9628 Acc@1: 54.212%\n","\n","| Validation Epoch #687\t\t\tLoss: 0.2610 Acc@1: 65.70%\n","\n","=> Training Epoch #688, LR=0.0385\n","| Epoch [688/1080] Iter[  1/557]\t\tLoss: 2.9906 Acc@1: 52.083%\n","| Epoch [688/1080] Iter[ 16/557]\t\tLoss: 2.9839 Acc@1: 53.711%\n","| Epoch [688/1080] Iter[ 31/557]\t\tLoss: 3.0860 Acc@1: 53.898%\n","| Epoch [688/1080] Iter[ 46/557]\t\tLoss: 2.7055 Acc@1: 53.782%\n","\n","| Validation Epoch #688\t\t\tLoss: 0.0635 Acc@1: 68.72%\n","\n","=> Training Epoch #689, LR=0.0384\n","| Epoch [689/1080] Iter[  1/557]\t\tLoss: 2.8350 Acc@1: 54.167%\n","| Epoch [689/1080] Iter[ 16/557]\t\tLoss: 3.3001 Acc@1: 54.753%\n","| Epoch [689/1080] Iter[ 31/557]\t\tLoss: 2.9034 Acc@1: 54.536%\n","| Epoch [689/1080] Iter[ 46/557]\t\tLoss: 3.0119 Acc@1: 54.099%\n","\n","| Validation Epoch #689\t\t\tLoss: 0.0352 Acc@1: 63.98%\n","\n","=> Training Epoch #690, LR=0.0384\n","| Epoch [690/1080] Iter[  1/557]\t\tLoss: 2.7454 Acc@1: 56.250%\n","| Epoch [690/1080] Iter[ 16/557]\t\tLoss: 2.6747 Acc@1: 54.948%\n","| Epoch [690/1080] Iter[ 31/557]\t\tLoss: 2.7653 Acc@1: 54.335%\n","| Epoch [690/1080] Iter[ 46/557]\t\tLoss: 2.8264 Acc@1: 53.940%\n","\n","| Validation Epoch #690\t\t\tLoss: 0.1287 Acc@1: 65.10%\n","\n","=> Training Epoch #691, LR=0.0383\n","| Epoch [691/1080] Iter[  1/557]\t\tLoss: 3.0297 Acc@1: 48.958%\n","| Epoch [691/1080] Iter[ 16/557]\t\tLoss: 2.7482 Acc@1: 53.646%\n","| Epoch [691/1080] Iter[ 31/557]\t\tLoss: 2.6899 Acc@1: 53.663%\n","| Epoch [691/1080] Iter[ 46/557]\t\tLoss: 3.0335 Acc@1: 54.053%\n","\n","| Validation Epoch #691\t\t\tLoss: 1.8462 Acc@1: 62.30%\n","\n","=> Training Epoch #692, LR=0.0383\n","| Epoch [692/1080] Iter[  1/557]\t\tLoss: 2.6730 Acc@1: 57.292%\n","| Epoch [692/1080] Iter[ 16/557]\t\tLoss: 3.1662 Acc@1: 52.734%\n","| Epoch [692/1080] Iter[ 31/557]\t\tLoss: 2.8160 Acc@1: 54.032%\n","| Epoch [692/1080] Iter[ 46/557]\t\tLoss: 2.7468 Acc@1: 53.759%\n","\n","| Validation Epoch #692\t\t\tLoss: 0.0851 Acc@1: 66.16%\n","\n","=> Training Epoch #693, LR=0.0382\n","| Epoch [693/1080] Iter[  1/557]\t\tLoss: 2.8531 Acc@1: 53.125%\n","| Epoch [693/1080] Iter[ 16/557]\t\tLoss: 2.7546 Acc@1: 53.581%\n","| Epoch [693/1080] Iter[ 31/557]\t\tLoss: 2.8146 Acc@1: 53.931%\n","| Epoch [693/1080] Iter[ 46/557]\t\tLoss: 2.6129 Acc@1: 54.189%\n","\n","| Validation Epoch #693\t\t\tLoss: 0.0900 Acc@1: 58.22%\n","\n","=> Training Epoch #694, LR=0.0381\n","| Epoch [694/1080] Iter[  1/557]\t\tLoss: 2.8760 Acc@1: 52.083%\n","| Epoch [694/1080] Iter[ 16/557]\t\tLoss: 2.8152 Acc@1: 53.516%\n","| Epoch [694/1080] Iter[ 31/557]\t\tLoss: 2.7452 Acc@1: 54.200%\n","| Epoch [694/1080] Iter[ 46/557]\t\tLoss: 3.1972 Acc@1: 54.053%\n","\n","| Validation Epoch #694\t\t\tLoss: 0.0193 Acc@1: 63.42%\n","\n","=> Training Epoch #695, LR=0.0381\n","| Epoch [695/1080] Iter[  1/557]\t\tLoss: 2.8814 Acc@1: 55.208%\n","| Epoch [695/1080] Iter[ 16/557]\t\tLoss: 2.7889 Acc@1: 54.557%\n","| Epoch [695/1080] Iter[ 31/557]\t\tLoss: 2.8203 Acc@1: 54.839%\n","| Epoch [695/1080] Iter[ 46/557]\t\tLoss: 3.0520 Acc@1: 54.008%\n","\n","| Validation Epoch #695\t\t\tLoss: 0.7197 Acc@1: 62.92%\n","\n","=> Training Epoch #696, LR=0.0380\n","| Epoch [696/1080] Iter[  1/557]\t\tLoss: 3.1077 Acc@1: 47.917%\n","| Epoch [696/1080] Iter[ 16/557]\t\tLoss: 2.8273 Acc@1: 55.208%\n","| Epoch [696/1080] Iter[ 31/557]\t\tLoss: 2.4309 Acc@1: 54.099%\n","| Epoch [696/1080] Iter[ 46/557]\t\tLoss: 3.0728 Acc@1: 54.280%\n","\n","| Validation Epoch #696\t\t\tLoss: 0.4643 Acc@1: 66.62%\n","\n","=> Training Epoch #697, LR=0.0380\n","| Epoch [697/1080] Iter[  1/557]\t\tLoss: 3.0631 Acc@1: 57.292%\n","| Epoch [697/1080] Iter[ 16/557]\t\tLoss: 2.8782 Acc@1: 55.013%\n","| Epoch [697/1080] Iter[ 31/557]\t\tLoss: 2.8312 Acc@1: 55.007%\n","| Epoch [697/1080] Iter[ 46/557]\t\tLoss: 2.7360 Acc@1: 54.688%\n","\n","| Validation Epoch #697\t\t\tLoss: 0.0942 Acc@1: 67.36%\n","\n","=> Training Epoch #698, LR=0.0379\n","| Epoch [698/1080] Iter[  1/557]\t\tLoss: 2.8936 Acc@1: 52.083%\n","| Epoch [698/1080] Iter[ 16/557]\t\tLoss: 3.0343 Acc@1: 50.977%\n","| Epoch [698/1080] Iter[ 31/557]\t\tLoss: 2.9850 Acc@1: 52.554%\n","| Epoch [698/1080] Iter[ 46/557]\t\tLoss: 2.8471 Acc@1: 53.057%\n","\n","| Validation Epoch #698\t\t\tLoss: 0.1132 Acc@1: 67.34%\n","\n","=> Training Epoch #699, LR=0.0378\n","| Epoch [699/1080] Iter[  1/557]\t\tLoss: 2.8167 Acc@1: 55.208%\n","| Epoch [699/1080] Iter[ 16/557]\t\tLoss: 2.8829 Acc@1: 54.883%\n","| Epoch [699/1080] Iter[ 31/557]\t\tLoss: 2.7995 Acc@1: 55.208%\n","| Epoch [699/1080] Iter[ 46/557]\t\tLoss: 2.8244 Acc@1: 54.076%\n","\n","| Validation Epoch #699\t\t\tLoss: 0.0950 Acc@1: 63.66%\n","\n","=> Training Epoch #700, LR=0.0378\n","| Epoch [700/1080] Iter[  1/557]\t\tLoss: 2.7082 Acc@1: 58.333%\n","| Epoch [700/1080] Iter[ 16/557]\t\tLoss: 2.5166 Acc@1: 56.315%\n","| Epoch [700/1080] Iter[ 31/557]\t\tLoss: 2.9191 Acc@1: 54.234%\n","| Epoch [700/1080] Iter[ 46/557]\t\tLoss: 3.3233 Acc@1: 53.736%\n","\n","| Validation Epoch #700\t\t\tLoss: 0.0150 Acc@1: 67.72%\n","\n","=> Training Epoch #701, LR=0.0377\n","| Epoch [701/1080] Iter[  1/557]\t\tLoss: 2.9881 Acc@1: 54.167%\n","| Epoch [701/1080] Iter[ 16/557]\t\tLoss: 2.6654 Acc@1: 56.315%\n","| Epoch [701/1080] Iter[ 31/557]\t\tLoss: 3.1921 Acc@1: 54.335%\n","| Epoch [701/1080] Iter[ 46/557]\t\tLoss: 3.1050 Acc@1: 53.827%\n","\n","| Validation Epoch #701\t\t\tLoss: 0.0276 Acc@1: 63.32%\n","\n","=> Training Epoch #702, LR=0.0377\n","| Epoch [702/1080] Iter[  1/557]\t\tLoss: 2.9371 Acc@1: 58.333%\n","| Epoch [702/1080] Iter[ 16/557]\t\tLoss: 2.9624 Acc@1: 53.971%\n","| Epoch [702/1080] Iter[ 31/557]\t\tLoss: 2.8751 Acc@1: 53.663%\n","| Epoch [702/1080] Iter[ 46/557]\t\tLoss: 2.7853 Acc@1: 53.329%\n","\n","| Validation Epoch #702\t\t\tLoss: 0.2370 Acc@1: 61.84%\n","\n","=> Training Epoch #703, LR=0.0376\n","| Epoch [703/1080] Iter[  1/557]\t\tLoss: 2.9971 Acc@1: 55.208%\n","| Epoch [703/1080] Iter[ 16/557]\t\tLoss: 2.9912 Acc@1: 52.930%\n","| Epoch [703/1080] Iter[ 31/557]\t\tLoss: 2.7291 Acc@1: 53.024%\n","| Epoch [703/1080] Iter[ 46/557]\t\tLoss: 3.0784 Acc@1: 53.351%\n","\n","| Validation Epoch #703\t\t\tLoss: 0.4071 Acc@1: 58.92%\n","\n","=> Training Epoch #704, LR=0.0375\n","| Epoch [704/1080] Iter[  1/557]\t\tLoss: 2.6713 Acc@1: 57.292%\n","| Epoch [704/1080] Iter[ 16/557]\t\tLoss: 2.8183 Acc@1: 54.427%\n","| Epoch [704/1080] Iter[ 31/557]\t\tLoss: 2.6669 Acc@1: 53.898%\n","| Epoch [704/1080] Iter[ 46/557]\t\tLoss: 2.6559 Acc@1: 53.895%\n","\n","| Validation Epoch #704\t\t\tLoss: 0.0218 Acc@1: 64.20%\n","\n","=> Training Epoch #705, LR=0.0375\n","| Epoch [705/1080] Iter[  1/557]\t\tLoss: 2.7184 Acc@1: 58.333%\n","| Epoch [705/1080] Iter[ 16/557]\t\tLoss: 3.0164 Acc@1: 55.990%\n","| Epoch [705/1080] Iter[ 31/557]\t\tLoss: 3.2950 Acc@1: 54.402%\n","| Epoch [705/1080] Iter[ 46/557]\t\tLoss: 2.9430 Acc@1: 53.736%\n","\n","| Validation Epoch #705\t\t\tLoss: 0.0835 Acc@1: 67.32%\n","\n","=> Training Epoch #706, LR=0.0374\n","| Epoch [706/1080] Iter[  1/557]\t\tLoss: 2.7349 Acc@1: 57.292%\n","| Epoch [706/1080] Iter[ 16/557]\t\tLoss: 2.7737 Acc@1: 54.557%\n","| Epoch [706/1080] Iter[ 31/557]\t\tLoss: 2.7913 Acc@1: 54.805%\n","| Epoch [706/1080] Iter[ 46/557]\t\tLoss: 2.9067 Acc@1: 54.393%\n","\n","| Validation Epoch #706\t\t\tLoss: 0.1045 Acc@1: 63.24%\n","\n","=> Training Epoch #707, LR=0.0374\n","| Epoch [707/1080] Iter[  1/557]\t\tLoss: 2.7587 Acc@1: 55.208%\n","| Epoch [707/1080] Iter[ 16/557]\t\tLoss: 2.6761 Acc@1: 55.143%\n","| Epoch [707/1080] Iter[ 31/557]\t\tLoss: 3.1481 Acc@1: 54.503%\n","| Epoch [707/1080] Iter[ 46/557]\t\tLoss: 2.7166 Acc@1: 54.303%\n","\n","| Validation Epoch #707\t\t\tLoss: 0.0065 Acc@1: 61.02%\n","\n","=> Training Epoch #708, LR=0.0373\n","| Epoch [708/1080] Iter[  1/557]\t\tLoss: 3.0101 Acc@1: 47.917%\n","| Epoch [708/1080] Iter[ 16/557]\t\tLoss: 2.7380 Acc@1: 53.060%\n","| Epoch [708/1080] Iter[ 31/557]\t\tLoss: 3.2944 Acc@1: 53.394%\n","| Epoch [708/1080] Iter[ 46/557]\t\tLoss: 3.0297 Acc@1: 53.351%\n","\n","| Validation Epoch #708\t\t\tLoss: 0.5000 Acc@1: 64.88%\n","\n","=> Training Epoch #709, LR=0.0372\n","| Epoch [709/1080] Iter[  1/557]\t\tLoss: 2.7575 Acc@1: 57.292%\n","| Epoch [709/1080] Iter[ 16/557]\t\tLoss: 2.8303 Acc@1: 54.557%\n","| Epoch [709/1080] Iter[ 31/557]\t\tLoss: 2.7734 Acc@1: 54.906%\n","| Epoch [709/1080] Iter[ 46/557]\t\tLoss: 3.1415 Acc@1: 54.393%\n","\n","| Validation Epoch #709\t\t\tLoss: 0.0150 Acc@1: 64.72%\n","\n","=> Training Epoch #710, LR=0.0372\n","| Epoch [710/1080] Iter[  1/557]\t\tLoss: 2.7923 Acc@1: 58.333%\n","| Epoch [710/1080] Iter[ 16/557]\t\tLoss: 2.8139 Acc@1: 55.078%\n","| Epoch [710/1080] Iter[ 31/557]\t\tLoss: 3.2044 Acc@1: 53.931%\n","| Epoch [710/1080] Iter[ 46/557]\t\tLoss: 3.1032 Acc@1: 53.351%\n","\n","| Validation Epoch #710\t\t\tLoss: 0.1429 Acc@1: 61.50%\n","\n","=> Training Epoch #711, LR=0.0371\n","| Epoch [711/1080] Iter[  1/557]\t\tLoss: 2.7986 Acc@1: 58.333%\n","| Epoch [711/1080] Iter[ 16/557]\t\tLoss: 2.9775 Acc@1: 54.883%\n","| Epoch [711/1080] Iter[ 31/557]\t\tLoss: 3.0657 Acc@1: 54.402%\n","| Epoch [711/1080] Iter[ 46/557]\t\tLoss: 2.8816 Acc@1: 53.963%\n","\n","| Validation Epoch #711\t\t\tLoss: 0.0023 Acc@1: 67.10%\n","\n","=> Training Epoch #712, LR=0.0371\n","| Epoch [712/1080] Iter[  1/557]\t\tLoss: 2.9402 Acc@1: 55.208%\n","| Epoch [712/1080] Iter[ 16/557]\t\tLoss: 2.6765 Acc@1: 53.776%\n","| Epoch [712/1080] Iter[ 31/557]\t\tLoss: 2.8264 Acc@1: 55.410%\n","| Epoch [712/1080] Iter[ 46/557]\t\tLoss: 2.8978 Acc@1: 54.574%\n","\n","| Validation Epoch #712\t\t\tLoss: 0.2014 Acc@1: 56.36%\n","\n","=> Training Epoch #713, LR=0.0370\n","| Epoch [713/1080] Iter[  1/557]\t\tLoss: 3.0552 Acc@1: 48.958%\n","| Epoch [713/1080] Iter[ 16/557]\t\tLoss: 2.8586 Acc@1: 54.883%\n","| Epoch [713/1080] Iter[ 31/557]\t\tLoss: 2.9062 Acc@1: 54.267%\n","| Epoch [713/1080] Iter[ 46/557]\t\tLoss: 3.0213 Acc@1: 53.736%\n","\n","| Validation Epoch #713\t\t\tLoss: 0.8008 Acc@1: 66.66%\n","\n","=> Training Epoch #714, LR=0.0369\n","| Epoch [714/1080] Iter[  1/557]\t\tLoss: 2.7312 Acc@1: 57.292%\n","| Epoch [714/1080] Iter[ 16/557]\t\tLoss: 2.9232 Acc@1: 52.214%\n","| Epoch [714/1080] Iter[ 31/557]\t\tLoss: 2.7633 Acc@1: 53.226%\n","| Epoch [714/1080] Iter[ 46/557]\t\tLoss: 2.7719 Acc@1: 53.601%\n","\n","| Validation Epoch #714\t\t\tLoss: 0.0184 Acc@1: 62.78%\n","\n","=> Training Epoch #715, LR=0.0369\n","| Epoch [715/1080] Iter[  1/557]\t\tLoss: 2.9066 Acc@1: 53.125%\n","| Epoch [715/1080] Iter[ 16/557]\t\tLoss: 3.0947 Acc@1: 52.930%\n","| Epoch [715/1080] Iter[ 31/557]\t\tLoss: 2.8896 Acc@1: 52.789%\n","| Epoch [715/1080] Iter[ 46/557]\t\tLoss: 3.0186 Acc@1: 53.057%\n","\n","| Validation Epoch #715\t\t\tLoss: 0.0089 Acc@1: 59.20%\n","\n","=> Training Epoch #716, LR=0.0368\n","| Epoch [716/1080] Iter[  1/557]\t\tLoss: 3.1116 Acc@1: 48.958%\n","| Epoch [716/1080] Iter[ 16/557]\t\tLoss: 3.0750 Acc@1: 52.474%\n","| Epoch [716/1080] Iter[ 31/557]\t\tLoss: 2.8332 Acc@1: 53.159%\n","| Epoch [716/1080] Iter[ 46/557]\t\tLoss: 2.8796 Acc@1: 54.099%\n","\n","| Validation Epoch #716\t\t\tLoss: 0.2832 Acc@1: 63.88%\n","\n","=> Training Epoch #717, LR=0.0368\n","| Epoch [717/1080] Iter[  1/557]\t\tLoss: 2.8977 Acc@1: 55.208%\n","| Epoch [717/1080] Iter[ 16/557]\t\tLoss: 2.8672 Acc@1: 51.693%\n","| Epoch [717/1080] Iter[ 31/557]\t\tLoss: 2.5611 Acc@1: 53.663%\n","| Epoch [717/1080] Iter[ 46/557]\t\tLoss: 2.7426 Acc@1: 53.872%\n","\n","| Validation Epoch #717\t\t\tLoss: 0.0029 Acc@1: 64.90%\n","\n","=> Training Epoch #718, LR=0.0367\n","| Epoch [718/1080] Iter[  1/557]\t\tLoss: 3.0344 Acc@1: 52.083%\n","| Epoch [718/1080] Iter[ 16/557]\t\tLoss: 2.7835 Acc@1: 53.776%\n","| Epoch [718/1080] Iter[ 31/557]\t\tLoss: 2.9252 Acc@1: 55.242%\n","| Epoch [718/1080] Iter[ 46/557]\t\tLoss: 2.9106 Acc@1: 55.344%\n","\n","| Validation Epoch #718\t\t\tLoss: 1.3348 Acc@1: 61.30%\n","\n","=> Training Epoch #719, LR=0.0366\n","| Epoch [719/1080] Iter[  1/557]\t\tLoss: 3.0172 Acc@1: 53.125%\n","| Epoch [719/1080] Iter[ 16/557]\t\tLoss: 3.0111 Acc@1: 53.255%\n","| Epoch [719/1080] Iter[ 31/557]\t\tLoss: 3.0427 Acc@1: 53.293%\n","| Epoch [719/1080] Iter[ 46/557]\t\tLoss: 3.1801 Acc@1: 53.306%\n","\n","| Validation Epoch #719\t\t\tLoss: 0.4040 Acc@1: 65.42%\n","| New Samples 34664\n","\n","=> Training Epoch #720, LR=0.0366\n","| Epoch [720/1080] Iter[  1/588]\t\tLoss: 2.9928 Acc@1: 48.958%\n","| Epoch [720/1080] Iter[ 16/588]\t\tLoss: 2.6995 Acc@1: 55.924%\n","| Epoch [720/1080] Iter[ 31/588]\t\tLoss: 3.0222 Acc@1: 54.267%\n","| Epoch [720/1080] Iter[ 46/588]\t\tLoss: 2.9086 Acc@1: 53.895%\n","\n","| Validation Epoch #720\t\t\tLoss: 0.3129 Acc@1: 62.78%\n","\n","=> Training Epoch #721, LR=0.0365\n","| Epoch [721/1080] Iter[  1/588]\t\tLoss: 2.6536 Acc@1: 55.208%\n","| Epoch [721/1080] Iter[ 16/588]\t\tLoss: 2.6872 Acc@1: 53.385%\n","| Epoch [721/1080] Iter[ 31/588]\t\tLoss: 2.8616 Acc@1: 54.335%\n","| Epoch [721/1080] Iter[ 46/588]\t\tLoss: 2.8031 Acc@1: 54.053%\n","\n","| Validation Epoch #721\t\t\tLoss: 0.2285 Acc@1: 66.16%\n","\n","=> Training Epoch #722, LR=0.0365\n","| Epoch [722/1080] Iter[  1/588]\t\tLoss: 3.0085 Acc@1: 52.083%\n","| Epoch [722/1080] Iter[ 16/588]\t\tLoss: 2.9214 Acc@1: 54.102%\n","| Epoch [722/1080] Iter[ 31/588]\t\tLoss: 2.5795 Acc@1: 54.839%\n","| Epoch [722/1080] Iter[ 46/588]\t\tLoss: 2.7842 Acc@1: 54.529%\n","\n","| Validation Epoch #722\t\t\tLoss: 0.0168 Acc@1: 66.54%\n","\n","=> Training Epoch #723, LR=0.0364\n","| Epoch [723/1080] Iter[  1/588]\t\tLoss: 2.9081 Acc@1: 55.208%\n","| Epoch [723/1080] Iter[ 16/588]\t\tLoss: 2.7876 Acc@1: 55.013%\n","| Epoch [723/1080] Iter[ 31/588]\t\tLoss: 2.7804 Acc@1: 55.141%\n","| Epoch [723/1080] Iter[ 46/588]\t\tLoss: 3.0888 Acc@1: 55.072%\n","\n","| Validation Epoch #723\t\t\tLoss: 0.2894 Acc@1: 63.58%\n","\n","=> Training Epoch #724, LR=0.0363\n","| Epoch [724/1080] Iter[  1/588]\t\tLoss: 2.7531 Acc@1: 58.333%\n","| Epoch [724/1080] Iter[ 16/588]\t\tLoss: 2.8752 Acc@1: 52.279%\n","| Epoch [724/1080] Iter[ 31/588]\t\tLoss: 2.8197 Acc@1: 53.394%\n","| Epoch [724/1080] Iter[ 46/588]\t\tLoss: 2.7390 Acc@1: 53.759%\n","\n","| Validation Epoch #724\t\t\tLoss: 2.2740 Acc@1: 54.66%\n","\n","=> Training Epoch #725, LR=0.0363\n","| Epoch [725/1080] Iter[  1/588]\t\tLoss: 2.8860 Acc@1: 57.292%\n","| Epoch [725/1080] Iter[ 16/588]\t\tLoss: 2.8899 Acc@1: 55.534%\n","| Epoch [725/1080] Iter[ 31/588]\t\tLoss: 3.0775 Acc@1: 54.133%\n","| Epoch [725/1080] Iter[ 46/588]\t\tLoss: 2.8985 Acc@1: 53.193%\n","\n","| Validation Epoch #725\t\t\tLoss: 0.0805 Acc@1: 63.86%\n","\n","=> Training Epoch #726, LR=0.0362\n","| Epoch [726/1080] Iter[  1/588]\t\tLoss: 3.0097 Acc@1: 54.167%\n","| Epoch [726/1080] Iter[ 16/588]\t\tLoss: 2.9123 Acc@1: 53.451%\n","| Epoch [726/1080] Iter[ 31/588]\t\tLoss: 2.8945 Acc@1: 53.999%\n","| Epoch [726/1080] Iter[ 46/588]\t\tLoss: 2.6950 Acc@1: 54.031%\n","\n","| Validation Epoch #726\t\t\tLoss: 0.5782 Acc@1: 64.32%\n","\n","=> Training Epoch #727, LR=0.0362\n","| Epoch [727/1080] Iter[  1/588]\t\tLoss: 2.7889 Acc@1: 54.167%\n","| Epoch [727/1080] Iter[ 16/588]\t\tLoss: 3.0282 Acc@1: 55.599%\n","| Epoch [727/1080] Iter[ 31/588]\t\tLoss: 2.6835 Acc@1: 54.536%\n","| Epoch [727/1080] Iter[ 46/588]\t\tLoss: 2.6998 Acc@1: 53.986%\n","\n","| Validation Epoch #727\t\t\tLoss: 0.0075 Acc@1: 66.64%\n","\n","=> Training Epoch #728, LR=0.0361\n","| Epoch [728/1080] Iter[  1/588]\t\tLoss: 3.2335 Acc@1: 43.750%\n","| Epoch [728/1080] Iter[ 16/588]\t\tLoss: 3.1990 Acc@1: 53.906%\n","| Epoch [728/1080] Iter[ 31/588]\t\tLoss: 3.1128 Acc@1: 53.999%\n","| Epoch [728/1080] Iter[ 46/588]\t\tLoss: 2.8785 Acc@1: 54.121%\n","\n","| Validation Epoch #728\t\t\tLoss: 0.0938 Acc@1: 65.98%\n","\n","=> Training Epoch #729, LR=0.0360\n","| Epoch [729/1080] Iter[  1/588]\t\tLoss: 3.0600 Acc@1: 48.958%\n","| Epoch [729/1080] Iter[ 16/588]\t\tLoss: 3.0618 Acc@1: 53.060%\n","| Epoch [729/1080] Iter[ 31/588]\t\tLoss: 3.3546 Acc@1: 52.083%\n","| Epoch [729/1080] Iter[ 46/588]\t\tLoss: 2.5046 Acc@1: 53.284%\n","\n","| Validation Epoch #729\t\t\tLoss: 0.0254 Acc@1: 67.96%\n","\n","=> Training Epoch #730, LR=0.0360\n","| Epoch [730/1080] Iter[  1/588]\t\tLoss: 2.8987 Acc@1: 55.208%\n","| Epoch [730/1080] Iter[ 16/588]\t\tLoss: 3.0344 Acc@1: 52.930%\n","| Epoch [730/1080] Iter[ 31/588]\t\tLoss: 3.1329 Acc@1: 53.629%\n","| Epoch [730/1080] Iter[ 46/588]\t\tLoss: 2.6612 Acc@1: 53.759%\n","\n","| Validation Epoch #730\t\t\tLoss: 0.1112 Acc@1: 64.74%\n","\n","=> Training Epoch #731, LR=0.0359\n","| Epoch [731/1080] Iter[  1/588]\t\tLoss: 3.0083 Acc@1: 50.000%\n","| Epoch [731/1080] Iter[ 16/588]\t\tLoss: 3.1804 Acc@1: 53.971%\n","| Epoch [731/1080] Iter[ 31/588]\t\tLoss: 3.0954 Acc@1: 54.738%\n","| Epoch [731/1080] Iter[ 46/588]\t\tLoss: 2.7507 Acc@1: 54.484%\n","\n","| Validation Epoch #731\t\t\tLoss: 0.0245 Acc@1: 64.20%\n","\n","=> Training Epoch #732, LR=0.0359\n","| Epoch [732/1080] Iter[  1/588]\t\tLoss: 2.9846 Acc@1: 53.125%\n","| Epoch [732/1080] Iter[ 16/588]\t\tLoss: 2.9247 Acc@1: 54.167%\n","| Epoch [732/1080] Iter[ 31/588]\t\tLoss: 3.1441 Acc@1: 53.696%\n","| Epoch [732/1080] Iter[ 46/588]\t\tLoss: 2.8402 Acc@1: 53.759%\n","\n","| Validation Epoch #732\t\t\tLoss: 0.0012 Acc@1: 60.02%\n","\n","=> Training Epoch #733, LR=0.0358\n","| Epoch [733/1080] Iter[  1/588]\t\tLoss: 3.2013 Acc@1: 46.875%\n","| Epoch [733/1080] Iter[ 16/588]\t\tLoss: 2.7849 Acc@1: 53.516%\n","| Epoch [733/1080] Iter[ 31/588]\t\tLoss: 2.9368 Acc@1: 53.327%\n","| Epoch [733/1080] Iter[ 46/588]\t\tLoss: 2.8936 Acc@1: 52.921%\n","\n","| Validation Epoch #733\t\t\tLoss: 0.2932 Acc@1: 62.52%\n","\n","=> Training Epoch #734, LR=0.0357\n","| Epoch [734/1080] Iter[  1/588]\t\tLoss: 2.9273 Acc@1: 52.083%\n","| Epoch [734/1080] Iter[ 16/588]\t\tLoss: 2.9937 Acc@1: 53.971%\n","| Epoch [734/1080] Iter[ 31/588]\t\tLoss: 3.0819 Acc@1: 53.763%\n","| Epoch [734/1080] Iter[ 46/588]\t\tLoss: 2.8850 Acc@1: 53.510%\n","\n","| Validation Epoch #734\t\t\tLoss: 0.4091 Acc@1: 67.38%\n","\n","=> Training Epoch #735, LR=0.0357\n","| Epoch [735/1080] Iter[  1/588]\t\tLoss: 2.7400 Acc@1: 58.333%\n","| Epoch [735/1080] Iter[ 16/588]\t\tLoss: 3.1246 Acc@1: 54.102%\n","| Epoch [735/1080] Iter[ 31/588]\t\tLoss: 3.0365 Acc@1: 53.999%\n","| Epoch [735/1080] Iter[ 46/588]\t\tLoss: 2.7052 Acc@1: 54.031%\n","\n","| Validation Epoch #735\t\t\tLoss: 0.0012 Acc@1: 65.80%\n","\n","=> Training Epoch #736, LR=0.0356\n","| Epoch [736/1080] Iter[  1/588]\t\tLoss: 2.9627 Acc@1: 53.125%\n","| Epoch [736/1080] Iter[ 16/588]\t\tLoss: 3.1403 Acc@1: 53.906%\n","| Epoch [736/1080] Iter[ 31/588]\t\tLoss: 2.7445 Acc@1: 53.562%\n","| Epoch [736/1080] Iter[ 46/588]\t\tLoss: 2.7976 Acc@1: 54.144%\n","\n","| Validation Epoch #736\t\t\tLoss: 0.0235 Acc@1: 64.18%\n","\n","=> Training Epoch #737, LR=0.0355\n","| Epoch [737/1080] Iter[  1/588]\t\tLoss: 2.9754 Acc@1: 53.125%\n","| Epoch [737/1080] Iter[ 16/588]\t\tLoss: 2.8017 Acc@1: 54.753%\n","| Epoch [737/1080] Iter[ 31/588]\t\tLoss: 3.0464 Acc@1: 53.696%\n","| Epoch [737/1080] Iter[ 46/588]\t\tLoss: 3.1536 Acc@1: 53.714%\n","\n","| Validation Epoch #737\t\t\tLoss: 0.2936 Acc@1: 67.66%\n","\n","=> Training Epoch #738, LR=0.0355\n","| Epoch [738/1080] Iter[  1/588]\t\tLoss: 3.0917 Acc@1: 53.125%\n","| Epoch [738/1080] Iter[ 16/588]\t\tLoss: 2.9570 Acc@1: 54.167%\n","| Epoch [738/1080] Iter[ 31/588]\t\tLoss: 2.7936 Acc@1: 54.200%\n","| Epoch [738/1080] Iter[ 46/588]\t\tLoss: 3.1587 Acc@1: 53.578%\n","\n","| Validation Epoch #738\t\t\tLoss: 0.0078 Acc@1: 66.40%\n","\n","=> Training Epoch #739, LR=0.0354\n","| Epoch [739/1080] Iter[  1/588]\t\tLoss: 2.5472 Acc@1: 60.417%\n","| Epoch [739/1080] Iter[ 16/588]\t\tLoss: 2.7588 Acc@1: 56.120%\n","| Epoch [739/1080] Iter[ 31/588]\t\tLoss: 2.9125 Acc@1: 54.772%\n","| Epoch [739/1080] Iter[ 46/588]\t\tLoss: 3.0998 Acc@1: 53.827%\n","\n","| Validation Epoch #739\t\t\tLoss: 0.2840 Acc@1: 65.52%\n","\n","=> Training Epoch #740, LR=0.0354\n","| Epoch [740/1080] Iter[  1/588]\t\tLoss: 3.1335 Acc@1: 53.125%\n","| Epoch [740/1080] Iter[ 16/588]\t\tLoss: 2.9569 Acc@1: 54.883%\n","| Epoch [740/1080] Iter[ 31/588]\t\tLoss: 2.7690 Acc@1: 55.410%\n","| Epoch [740/1080] Iter[ 46/588]\t\tLoss: 2.9062 Acc@1: 54.937%\n","\n","| Validation Epoch #740\t\t\tLoss: 0.0259 Acc@1: 62.48%\n","\n","=> Training Epoch #741, LR=0.0353\n","| Epoch [741/1080] Iter[  1/588]\t\tLoss: 3.1224 Acc@1: 48.958%\n","| Epoch [741/1080] Iter[ 16/588]\t\tLoss: 3.0040 Acc@1: 53.385%\n","| Epoch [741/1080] Iter[ 31/588]\t\tLoss: 2.9347 Acc@1: 53.763%\n","| Epoch [741/1080] Iter[ 46/588]\t\tLoss: 3.0155 Acc@1: 54.076%\n","\n","| Validation Epoch #741\t\t\tLoss: 1.6144 Acc@1: 64.66%\n","\n","=> Training Epoch #742, LR=0.0352\n","| Epoch [742/1080] Iter[  1/588]\t\tLoss: 2.8428 Acc@1: 53.125%\n","| Epoch [742/1080] Iter[ 16/588]\t\tLoss: 2.9921 Acc@1: 53.646%\n","| Epoch [742/1080] Iter[ 31/588]\t\tLoss: 2.6735 Acc@1: 54.133%\n","| Epoch [742/1080] Iter[ 46/588]\t\tLoss: 2.9136 Acc@1: 53.872%\n","\n","| Validation Epoch #742\t\t\tLoss: 0.0038 Acc@1: 66.32%\n","\n","=> Training Epoch #743, LR=0.0352\n","| Epoch [743/1080] Iter[  1/588]\t\tLoss: 2.6776 Acc@1: 57.292%\n","| Epoch [743/1080] Iter[ 16/588]\t\tLoss: 3.0046 Acc@1: 55.339%\n","| Epoch [743/1080] Iter[ 31/588]\t\tLoss: 2.9671 Acc@1: 55.276%\n","| Epoch [743/1080] Iter[ 46/588]\t\tLoss: 2.8262 Acc@1: 54.755%\n","\n","| Validation Epoch #743\t\t\tLoss: 0.1240 Acc@1: 67.48%\n","\n","=> Training Epoch #744, LR=0.0351\n","| Epoch [744/1080] Iter[  1/588]\t\tLoss: 2.8483 Acc@1: 56.250%\n","| Epoch [744/1080] Iter[ 16/588]\t\tLoss: 3.1490 Acc@1: 53.190%\n","| Epoch [744/1080] Iter[ 31/588]\t\tLoss: 2.8546 Acc@1: 53.293%\n","| Epoch [744/1080] Iter[ 46/588]\t\tLoss: 3.0733 Acc@1: 53.374%\n","\n","| Validation Epoch #744\t\t\tLoss: 0.1784 Acc@1: 67.56%\n","\n","=> Training Epoch #745, LR=0.0351\n","| Epoch [745/1080] Iter[  1/588]\t\tLoss: 2.9504 Acc@1: 50.000%\n","| Epoch [745/1080] Iter[ 16/588]\t\tLoss: 2.8108 Acc@1: 55.013%\n","| Epoch [745/1080] Iter[ 31/588]\t\tLoss: 2.8626 Acc@1: 53.663%\n","| Epoch [745/1080] Iter[ 46/588]\t\tLoss: 2.8630 Acc@1: 53.397%\n","\n","| Validation Epoch #745\t\t\tLoss: 0.3723 Acc@1: 63.78%\n","\n","=> Training Epoch #746, LR=0.0350\n","| Epoch [746/1080] Iter[  1/588]\t\tLoss: 2.9011 Acc@1: 54.167%\n","| Epoch [746/1080] Iter[ 16/588]\t\tLoss: 2.9509 Acc@1: 52.995%\n","| Epoch [746/1080] Iter[ 31/588]\t\tLoss: 2.7730 Acc@1: 54.503%\n","| Epoch [746/1080] Iter[ 46/588]\t\tLoss: 3.1150 Acc@1: 54.416%\n","\n","| Validation Epoch #746\t\t\tLoss: 0.0102 Acc@1: 62.62%\n","\n","=> Training Epoch #747, LR=0.0349\n","| Epoch [747/1080] Iter[  1/588]\t\tLoss: 2.6180 Acc@1: 60.417%\n","| Epoch [747/1080] Iter[ 16/588]\t\tLoss: 3.3602 Acc@1: 53.385%\n","| Epoch [747/1080] Iter[ 31/588]\t\tLoss: 2.9516 Acc@1: 54.099%\n","| Epoch [747/1080] Iter[ 46/588]\t\tLoss: 2.6469 Acc@1: 54.438%\n","\n","| Validation Epoch #747\t\t\tLoss: 0.6811 Acc@1: 67.64%\n","\n","=> Training Epoch #748, LR=0.0349\n","| Epoch [748/1080] Iter[  1/588]\t\tLoss: 2.9071 Acc@1: 53.125%\n","| Epoch [748/1080] Iter[ 16/588]\t\tLoss: 2.8276 Acc@1: 53.255%\n","| Epoch [748/1080] Iter[ 31/588]\t\tLoss: 2.8939 Acc@1: 54.402%\n","| Epoch [748/1080] Iter[ 46/588]\t\tLoss: 2.7863 Acc@1: 54.099%\n","\n","| Validation Epoch #748\t\t\tLoss: 1.4022 Acc@1: 61.90%\n","\n","=> Training Epoch #749, LR=0.0348\n","| Epoch [749/1080] Iter[  1/588]\t\tLoss: 3.0264 Acc@1: 53.125%\n","| Epoch [749/1080] Iter[ 16/588]\t\tLoss: 3.2440 Acc@1: 53.906%\n","| Epoch [749/1080] Iter[ 31/588]\t\tLoss: 2.7100 Acc@1: 54.435%\n","| Epoch [749/1080] Iter[ 46/588]\t\tLoss: 3.1108 Acc@1: 54.982%\n","\n","| Validation Epoch #749\t\t\tLoss: 0.3516 Acc@1: 65.44%\n","\n","=> Training Epoch #750, LR=0.0347\n","| Epoch [750/1080] Iter[  1/588]\t\tLoss: 2.8196 Acc@1: 58.333%\n","| Epoch [750/1080] Iter[ 16/588]\t\tLoss: 2.6948 Acc@1: 54.688%\n","| Epoch [750/1080] Iter[ 31/588]\t\tLoss: 2.9040 Acc@1: 54.402%\n","| Epoch [750/1080] Iter[ 46/588]\t\tLoss: 2.8597 Acc@1: 54.076%\n","\n","| Validation Epoch #750\t\t\tLoss: 0.1506 Acc@1: 64.02%\n","\n","=> Training Epoch #751, LR=0.0347\n","| Epoch [751/1080] Iter[  1/588]\t\tLoss: 3.0228 Acc@1: 48.958%\n","| Epoch [751/1080] Iter[ 16/588]\t\tLoss: 3.0620 Acc@1: 54.753%\n","| Epoch [751/1080] Iter[ 31/588]\t\tLoss: 2.9424 Acc@1: 53.965%\n","| Epoch [751/1080] Iter[ 46/588]\t\tLoss: 2.8363 Acc@1: 54.031%\n","\n","| Validation Epoch #751\t\t\tLoss: 0.1153 Acc@1: 57.24%\n","\n","=> Training Epoch #752, LR=0.0346\n","| Epoch [752/1080] Iter[  1/588]\t\tLoss: 3.0554 Acc@1: 50.000%\n","| Epoch [752/1080] Iter[ 16/588]\t\tLoss: 2.9368 Acc@1: 53.971%\n","| Epoch [752/1080] Iter[ 31/588]\t\tLoss: 3.2351 Acc@1: 53.763%\n","| Epoch [752/1080] Iter[ 46/588]\t\tLoss: 2.8518 Acc@1: 53.510%\n","\n","| Validation Epoch #752\t\t\tLoss: 0.6138 Acc@1: 65.28%\n","\n","=> Training Epoch #753, LR=0.0346\n","| Epoch [753/1080] Iter[  1/588]\t\tLoss: 2.9790 Acc@1: 50.000%\n","| Epoch [753/1080] Iter[ 16/588]\t\tLoss: 3.2245 Acc@1: 55.339%\n","| Epoch [753/1080] Iter[ 31/588]\t\tLoss: 3.2909 Acc@1: 55.074%\n","| Epoch [753/1080] Iter[ 46/588]\t\tLoss: 2.8582 Acc@1: 54.801%\n","\n","| Validation Epoch #753\t\t\tLoss: 0.1392 Acc@1: 61.68%\n","\n","=> Training Epoch #754, LR=0.0345\n","| Epoch [754/1080] Iter[  1/588]\t\tLoss: 2.7811 Acc@1: 55.208%\n","| Epoch [754/1080] Iter[ 16/588]\t\tLoss: 2.7280 Acc@1: 53.125%\n","| Epoch [754/1080] Iter[ 31/588]\t\tLoss: 2.6554 Acc@1: 54.335%\n","| Epoch [754/1080] Iter[ 46/588]\t\tLoss: 3.1445 Acc@1: 53.804%\n","\n","| Validation Epoch #754\t\t\tLoss: 0.0341 Acc@1: 65.94%\n","\n","=> Training Epoch #755, LR=0.0344\n","| Epoch [755/1080] Iter[  1/588]\t\tLoss: 2.8592 Acc@1: 52.083%\n","| Epoch [755/1080] Iter[ 16/588]\t\tLoss: 2.8917 Acc@1: 54.492%\n","| Epoch [755/1080] Iter[ 31/588]\t\tLoss: 3.1322 Acc@1: 54.772%\n","| Epoch [755/1080] Iter[ 46/588]\t\tLoss: 2.8423 Acc@1: 54.597%\n","\n","| Validation Epoch #755\t\t\tLoss: 0.4678 Acc@1: 64.66%\n","\n","=> Training Epoch #756, LR=0.0344\n","| Epoch [756/1080] Iter[  1/588]\t\tLoss: 2.9962 Acc@1: 53.125%\n","| Epoch [756/1080] Iter[ 16/588]\t\tLoss: 2.7060 Acc@1: 54.102%\n","| Epoch [756/1080] Iter[ 31/588]\t\tLoss: 2.8433 Acc@1: 54.200%\n","| Epoch [756/1080] Iter[ 46/588]\t\tLoss: 2.8075 Acc@1: 54.416%\n","\n","| Validation Epoch #756\t\t\tLoss: 0.3981 Acc@1: 66.60%\n","\n","=> Training Epoch #757, LR=0.0343\n","| Epoch [757/1080] Iter[  1/588]\t\tLoss: 2.9670 Acc@1: 50.000%\n","| Epoch [757/1080] Iter[ 16/588]\t\tLoss: 2.6865 Acc@1: 55.078%\n","| Epoch [757/1080] Iter[ 31/588]\t\tLoss: 2.7998 Acc@1: 54.435%\n","| Epoch [757/1080] Iter[ 46/588]\t\tLoss: 3.1424 Acc@1: 54.144%\n","\n","| Validation Epoch #757\t\t\tLoss: 0.0502 Acc@1: 63.16%\n","\n","=> Training Epoch #758, LR=0.0342\n","| Epoch [758/1080] Iter[  1/588]\t\tLoss: 2.9448 Acc@1: 54.167%\n","| Epoch [758/1080] Iter[ 16/588]\t\tLoss: 2.9851 Acc@1: 54.297%\n","| Epoch [758/1080] Iter[ 31/588]\t\tLoss: 2.9450 Acc@1: 53.192%\n","| Epoch [758/1080] Iter[ 46/588]\t\tLoss: 2.6714 Acc@1: 53.601%\n","\n","| Validation Epoch #758\t\t\tLoss: 0.0901 Acc@1: 63.30%\n","\n","=> Training Epoch #759, LR=0.0342\n","| Epoch [759/1080] Iter[  1/588]\t\tLoss: 2.8239 Acc@1: 56.250%\n","| Epoch [759/1080] Iter[ 16/588]\t\tLoss: 3.0336 Acc@1: 55.990%\n","| Epoch [759/1080] Iter[ 31/588]\t\tLoss: 2.9128 Acc@1: 55.074%\n","| Epoch [759/1080] Iter[ 46/588]\t\tLoss: 2.9912 Acc@1: 54.008%\n","\n","| Validation Epoch #759\t\t\tLoss: 0.0531 Acc@1: 66.10%\n","\n","=> Training Epoch #760, LR=0.0341\n","| Epoch [760/1080] Iter[  1/588]\t\tLoss: 2.7654 Acc@1: 62.500%\n","| Epoch [760/1080] Iter[ 16/588]\t\tLoss: 2.9181 Acc@1: 53.841%\n","| Epoch [760/1080] Iter[ 31/588]\t\tLoss: 3.0545 Acc@1: 53.226%\n","| Epoch [760/1080] Iter[ 46/588]\t\tLoss: 3.2283 Acc@1: 53.623%\n","\n","| Validation Epoch #760\t\t\tLoss: 0.0307 Acc@1: 64.00%\n","\n","=> Training Epoch #761, LR=0.0341\n","| Epoch [761/1080] Iter[  1/588]\t\tLoss: 2.8829 Acc@1: 54.167%\n","| Epoch [761/1080] Iter[ 16/588]\t\tLoss: 3.0935 Acc@1: 54.102%\n","| Epoch [761/1080] Iter[ 31/588]\t\tLoss: 2.6508 Acc@1: 54.469%\n","| Epoch [761/1080] Iter[ 46/588]\t\tLoss: 2.9264 Acc@1: 53.691%\n","\n","| Validation Epoch #761\t\t\tLoss: 0.0128 Acc@1: 63.18%\n","\n","=> Training Epoch #762, LR=0.0340\n","| Epoch [762/1080] Iter[  1/588]\t\tLoss: 2.8137 Acc@1: 58.333%\n","| Epoch [762/1080] Iter[ 16/588]\t\tLoss: 2.7183 Acc@1: 55.404%\n","| Epoch [762/1080] Iter[ 31/588]\t\tLoss: 2.9023 Acc@1: 54.267%\n","| Epoch [762/1080] Iter[ 46/588]\t\tLoss: 2.9041 Acc@1: 54.235%\n","\n","| Validation Epoch #762\t\t\tLoss: 0.2314 Acc@1: 66.96%\n","\n","=> Training Epoch #763, LR=0.0339\n","| Epoch [763/1080] Iter[  1/588]\t\tLoss: 2.7010 Acc@1: 58.333%\n","| Epoch [763/1080] Iter[ 16/588]\t\tLoss: 2.8608 Acc@1: 53.841%\n","| Epoch [763/1080] Iter[ 31/588]\t\tLoss: 2.5854 Acc@1: 53.831%\n","| Epoch [763/1080] Iter[ 46/588]\t\tLoss: 3.0168 Acc@1: 54.303%\n","\n","| Validation Epoch #763\t\t\tLoss: 0.4016 Acc@1: 64.98%\n","\n","=> Training Epoch #764, LR=0.0339\n","| Epoch [764/1080] Iter[  1/588]\t\tLoss: 3.1114 Acc@1: 48.958%\n","| Epoch [764/1080] Iter[ 16/588]\t\tLoss: 2.6783 Acc@1: 53.906%\n","| Epoch [764/1080] Iter[ 31/588]\t\tLoss: 2.8482 Acc@1: 54.839%\n","| Epoch [764/1080] Iter[ 46/588]\t\tLoss: 2.8532 Acc@1: 54.642%\n","\n","| Validation Epoch #764\t\t\tLoss: 0.0029 Acc@1: 63.82%\n","\n","=> Training Epoch #765, LR=0.0338\n","| Epoch [765/1080] Iter[  1/588]\t\tLoss: 2.7195 Acc@1: 57.292%\n","| Epoch [765/1080] Iter[ 16/588]\t\tLoss: 3.0125 Acc@1: 52.474%\n","| Epoch [765/1080] Iter[ 31/588]\t\tLoss: 2.9723 Acc@1: 52.923%\n","| Epoch [765/1080] Iter[ 46/588]\t\tLoss: 2.9764 Acc@1: 53.691%\n","\n","| Validation Epoch #765\t\t\tLoss: 0.0899 Acc@1: 65.54%\n","\n","=> Training Epoch #766, LR=0.0337\n","| Epoch [766/1080] Iter[  1/588]\t\tLoss: 3.3056 Acc@1: 50.000%\n","| Epoch [766/1080] Iter[ 16/588]\t\tLoss: 3.1466 Acc@1: 52.799%\n","| Epoch [766/1080] Iter[ 31/588]\t\tLoss: 2.9628 Acc@1: 53.125%\n","| Epoch [766/1080] Iter[ 46/588]\t\tLoss: 2.7027 Acc@1: 53.510%\n","\n","| Validation Epoch #766\t\t\tLoss: 0.2971 Acc@1: 65.16%\n","\n","=> Training Epoch #767, LR=0.0337\n","| Epoch [767/1080] Iter[  1/588]\t\tLoss: 3.0247 Acc@1: 54.167%\n","| Epoch [767/1080] Iter[ 16/588]\t\tLoss: 2.9029 Acc@1: 53.320%\n","| Epoch [767/1080] Iter[ 31/588]\t\tLoss: 3.0940 Acc@1: 53.360%\n","| Epoch [767/1080] Iter[ 46/588]\t\tLoss: 2.9155 Acc@1: 54.053%\n","\n","| Validation Epoch #767\t\t\tLoss: 0.0814 Acc@1: 67.10%\n","\n","=> Training Epoch #768, LR=0.0336\n","| Epoch [768/1080] Iter[  1/588]\t\tLoss: 2.9315 Acc@1: 53.125%\n","| Epoch [768/1080] Iter[ 16/588]\t\tLoss: 2.6445 Acc@1: 55.339%\n","| Epoch [768/1080] Iter[ 31/588]\t\tLoss: 2.7906 Acc@1: 55.813%\n","| Epoch [768/1080] Iter[ 46/588]\t\tLoss: 3.0635 Acc@1: 55.276%\n","\n","| Validation Epoch #768\t\t\tLoss: 0.0206 Acc@1: 65.36%\n","\n","=> Training Epoch #769, LR=0.0336\n","| Epoch [769/1080] Iter[  1/588]\t\tLoss: 3.0090 Acc@1: 53.125%\n","| Epoch [769/1080] Iter[ 16/588]\t\tLoss: 2.8543 Acc@1: 53.906%\n","| Epoch [769/1080] Iter[ 31/588]\t\tLoss: 2.7029 Acc@1: 54.368%\n","| Epoch [769/1080] Iter[ 46/588]\t\tLoss: 2.7193 Acc@1: 54.257%\n","\n","| Validation Epoch #769\t\t\tLoss: 0.0712 Acc@1: 62.90%\n","\n","=> Training Epoch #770, LR=0.0335\n","| Epoch [770/1080] Iter[  1/588]\t\tLoss: 2.7147 Acc@1: 59.375%\n","| Epoch [770/1080] Iter[ 16/588]\t\tLoss: 2.9260 Acc@1: 52.734%\n","| Epoch [770/1080] Iter[ 31/588]\t\tLoss: 2.9909 Acc@1: 53.461%\n","| Epoch [770/1080] Iter[ 46/588]\t\tLoss: 2.8739 Acc@1: 53.419%\n","\n","| Validation Epoch #770\t\t\tLoss: 0.4379 Acc@1: 56.50%\n","\n","=> Training Epoch #771, LR=0.0334\n","| Epoch [771/1080] Iter[  1/588]\t\tLoss: 3.0985 Acc@1: 46.875%\n","| Epoch [771/1080] Iter[ 16/588]\t\tLoss: 2.5827 Acc@1: 53.906%\n","| Epoch [771/1080] Iter[ 31/588]\t\tLoss: 2.8255 Acc@1: 54.301%\n","| Epoch [771/1080] Iter[ 46/588]\t\tLoss: 2.9476 Acc@1: 54.370%\n","\n","| Validation Epoch #771\t\t\tLoss: 0.0454 Acc@1: 64.54%\n","\n","=> Training Epoch #772, LR=0.0334\n","| Epoch [772/1080] Iter[  1/588]\t\tLoss: 2.8294 Acc@1: 51.042%\n","| Epoch [772/1080] Iter[ 16/588]\t\tLoss: 2.9803 Acc@1: 52.148%\n","| Epoch [772/1080] Iter[ 31/588]\t\tLoss: 2.8342 Acc@1: 52.923%\n","| Epoch [772/1080] Iter[ 46/588]\t\tLoss: 2.9941 Acc@1: 53.329%\n","\n","| Validation Epoch #772\t\t\tLoss: 0.0365 Acc@1: 66.68%\n","\n","=> Training Epoch #773, LR=0.0333\n","| Epoch [773/1080] Iter[  1/588]\t\tLoss: 2.5027 Acc@1: 61.458%\n","| Epoch [773/1080] Iter[ 16/588]\t\tLoss: 3.0218 Acc@1: 55.534%\n","| Epoch [773/1080] Iter[ 31/588]\t\tLoss: 2.9446 Acc@1: 55.309%\n","| Epoch [773/1080] Iter[ 46/588]\t\tLoss: 3.1090 Acc@1: 53.782%\n","\n","| Validation Epoch #773\t\t\tLoss: 0.0112 Acc@1: 67.10%\n","\n","=> Training Epoch #774, LR=0.0332\n","| Epoch [774/1080] Iter[  1/588]\t\tLoss: 2.9478 Acc@1: 51.042%\n","| Epoch [774/1080] Iter[ 16/588]\t\tLoss: 2.6517 Acc@1: 54.492%\n","| Epoch [774/1080] Iter[ 31/588]\t\tLoss: 2.9824 Acc@1: 54.032%\n","| Epoch [774/1080] Iter[ 46/588]\t\tLoss: 2.8761 Acc@1: 53.986%\n","\n","| Validation Epoch #774\t\t\tLoss: 0.0118 Acc@1: 65.78%\n","\n","=> Training Epoch #775, LR=0.0332\n","| Epoch [775/1080] Iter[  1/588]\t\tLoss: 2.7480 Acc@1: 57.292%\n","| Epoch [775/1080] Iter[ 16/588]\t\tLoss: 3.0465 Acc@1: 54.167%\n","| Epoch [775/1080] Iter[ 31/588]\t\tLoss: 2.9288 Acc@1: 53.159%\n","| Epoch [775/1080] Iter[ 46/588]\t\tLoss: 2.8124 Acc@1: 53.261%\n","\n","| Validation Epoch #775\t\t\tLoss: 0.0866 Acc@1: 63.88%\n","\n","=> Training Epoch #776, LR=0.0331\n","| Epoch [776/1080] Iter[  1/588]\t\tLoss: 3.0234 Acc@1: 51.042%\n","| Epoch [776/1080] Iter[ 16/588]\t\tLoss: 2.8142 Acc@1: 52.995%\n","| Epoch [776/1080] Iter[ 31/588]\t\tLoss: 3.0306 Acc@1: 53.360%\n","| Epoch [776/1080] Iter[ 46/588]\t\tLoss: 2.8467 Acc@1: 53.759%\n","\n","| Validation Epoch #776\t\t\tLoss: 0.0006 Acc@1: 66.74%\n","\n","=> Training Epoch #777, LR=0.0330\n","| Epoch [777/1080] Iter[  1/588]\t\tLoss: 3.0261 Acc@1: 47.917%\n","| Epoch [777/1080] Iter[ 16/588]\t\tLoss: 2.8642 Acc@1: 53.451%\n","| Epoch [777/1080] Iter[ 31/588]\t\tLoss: 2.7595 Acc@1: 54.536%\n","| Epoch [777/1080] Iter[ 46/588]\t\tLoss: 2.7564 Acc@1: 54.280%\n","\n","| Validation Epoch #777\t\t\tLoss: 0.2124 Acc@1: 68.24%\n","\n","=> Training Epoch #778, LR=0.0330\n","| Epoch [778/1080] Iter[  1/588]\t\tLoss: 3.0808 Acc@1: 48.958%\n","| Epoch [778/1080] Iter[ 16/588]\t\tLoss: 3.1439 Acc@1: 55.208%\n","| Epoch [778/1080] Iter[ 31/588]\t\tLoss: 2.7442 Acc@1: 54.805%\n","| Epoch [778/1080] Iter[ 46/588]\t\tLoss: 3.0152 Acc@1: 53.963%\n","\n","| Validation Epoch #778\t\t\tLoss: 0.0479 Acc@1: 69.88%\n","| Saving Best model...\t\t\tTop1 = 69.88%\n","\n","=> Training Epoch #779, LR=0.0329\n","| Epoch [779/1080] Iter[  1/588]\t\tLoss: 3.0170 Acc@1: 53.125%\n","| Epoch [779/1080] Iter[ 16/588]\t\tLoss: 2.9353 Acc@1: 53.776%\n","| Epoch [779/1080] Iter[ 31/588]\t\tLoss: 3.0141 Acc@1: 53.763%\n","| Epoch [779/1080] Iter[ 46/588]\t\tLoss: 2.7431 Acc@1: 53.057%\n","\n","| Validation Epoch #779\t\t\tLoss: 0.3461 Acc@1: 65.66%\n","\n","=> Training Epoch #780, LR=0.0329\n","| Epoch [780/1080] Iter[  1/588]\t\tLoss: 2.8870 Acc@1: 48.958%\n","| Epoch [780/1080] Iter[ 16/588]\t\tLoss: 2.7519 Acc@1: 53.776%\n","| Epoch [780/1080] Iter[ 31/588]\t\tLoss: 2.6672 Acc@1: 53.864%\n","| Epoch [780/1080] Iter[ 46/588]\t\tLoss: 2.7222 Acc@1: 53.487%\n","\n","| Validation Epoch #780\t\t\tLoss: 0.0463 Acc@1: 61.62%\n","\n","=> Training Epoch #781, LR=0.0328\n","| Epoch [781/1080] Iter[  1/588]\t\tLoss: 2.9571 Acc@1: 55.208%\n","| Epoch [781/1080] Iter[ 16/588]\t\tLoss: 2.9895 Acc@1: 55.208%\n","| Epoch [781/1080] Iter[ 31/588]\t\tLoss: 2.7059 Acc@1: 54.335%\n","| Epoch [781/1080] Iter[ 46/588]\t\tLoss: 2.9305 Acc@1: 54.529%\n","\n","| Validation Epoch #781\t\t\tLoss: 0.1099 Acc@1: 62.58%\n","\n","=> Training Epoch #782, LR=0.0327\n","| Epoch [782/1080] Iter[  1/588]\t\tLoss: 2.8606 Acc@1: 57.292%\n","| Epoch [782/1080] Iter[ 16/588]\t\tLoss: 2.9557 Acc@1: 52.474%\n","| Epoch [782/1080] Iter[ 31/588]\t\tLoss: 2.9915 Acc@1: 54.234%\n","| Epoch [782/1080] Iter[ 46/588]\t\tLoss: 2.9978 Acc@1: 54.212%\n","\n","| Validation Epoch #782\t\t\tLoss: 0.3261 Acc@1: 67.12%\n","\n","=> Training Epoch #783, LR=0.0327\n","| Epoch [783/1080] Iter[  1/588]\t\tLoss: 2.8558 Acc@1: 56.250%\n","| Epoch [783/1080] Iter[ 16/588]\t\tLoss: 2.6303 Acc@1: 54.492%\n","| Epoch [783/1080] Iter[ 31/588]\t\tLoss: 2.7660 Acc@1: 55.074%\n","| Epoch [783/1080] Iter[ 46/588]\t\tLoss: 2.7891 Acc@1: 54.710%\n","\n","| Validation Epoch #783\t\t\tLoss: 0.0684 Acc@1: 66.28%\n","\n","=> Training Epoch #784, LR=0.0326\n","| Epoch [784/1080] Iter[  1/588]\t\tLoss: 2.5846 Acc@1: 63.542%\n","| Epoch [784/1080] Iter[ 16/588]\t\tLoss: 2.8855 Acc@1: 54.102%\n","| Epoch [784/1080] Iter[ 31/588]\t\tLoss: 2.7877 Acc@1: 53.562%\n","| Epoch [784/1080] Iter[ 46/588]\t\tLoss: 2.8898 Acc@1: 53.668%\n","\n","| Validation Epoch #784\t\t\tLoss: 0.0881 Acc@1: 68.48%\n","\n","=> Training Epoch #785, LR=0.0325\n","| Epoch [785/1080] Iter[  1/588]\t\tLoss: 2.9793 Acc@1: 52.083%\n","| Epoch [785/1080] Iter[ 16/588]\t\tLoss: 2.8784 Acc@1: 54.167%\n","| Epoch [785/1080] Iter[ 31/588]\t\tLoss: 2.9186 Acc@1: 53.999%\n","| Epoch [785/1080] Iter[ 46/588]\t\tLoss: 2.6336 Acc@1: 54.144%\n","\n","| Validation Epoch #785\t\t\tLoss: 0.2246 Acc@1: 62.86%\n","\n","=> Training Epoch #786, LR=0.0325\n","| Epoch [786/1080] Iter[  1/588]\t\tLoss: 2.6634 Acc@1: 57.292%\n","| Epoch [786/1080] Iter[ 16/588]\t\tLoss: 2.8773 Acc@1: 55.273%\n","| Epoch [786/1080] Iter[ 31/588]\t\tLoss: 2.7118 Acc@1: 53.999%\n","| Epoch [786/1080] Iter[ 46/588]\t\tLoss: 2.8223 Acc@1: 54.778%\n","\n","| Validation Epoch #786\t\t\tLoss: 0.0547 Acc@1: 70.18%\n","| Saving Best model...\t\t\tTop1 = 70.18%\n","\n","=> Training Epoch #787, LR=0.0324\n","| Epoch [787/1080] Iter[  1/588]\t\tLoss: 2.9855 Acc@1: 48.958%\n","| Epoch [787/1080] Iter[ 16/588]\t\tLoss: 2.9024 Acc@1: 54.427%\n","| Epoch [787/1080] Iter[ 31/588]\t\tLoss: 2.9808 Acc@1: 53.999%\n","| Epoch [787/1080] Iter[ 46/588]\t\tLoss: 2.7204 Acc@1: 54.031%\n","\n","| Validation Epoch #787\t\t\tLoss: 0.0004 Acc@1: 62.28%\n","\n","=> Training Epoch #788, LR=0.0323\n","| Epoch [788/1080] Iter[  1/588]\t\tLoss: 2.9444 Acc@1: 53.125%\n","| Epoch [788/1080] Iter[ 16/588]\t\tLoss: 2.8816 Acc@1: 54.753%\n","| Epoch [788/1080] Iter[ 31/588]\t\tLoss: 3.0360 Acc@1: 54.301%\n","| Epoch [788/1080] Iter[ 46/588]\t\tLoss: 2.7467 Acc@1: 53.487%\n","\n","| Validation Epoch #788\t\t\tLoss: 0.0367 Acc@1: 65.72%\n","\n","=> Training Epoch #789, LR=0.0323\n","| Epoch [789/1080] Iter[  1/588]\t\tLoss: 2.9303 Acc@1: 51.042%\n","| Epoch [789/1080] Iter[ 16/588]\t\tLoss: 2.8480 Acc@1: 52.995%\n","| Epoch [789/1080] Iter[ 31/588]\t\tLoss: 3.1844 Acc@1: 53.595%\n","| Epoch [789/1080] Iter[ 46/588]\t\tLoss: 3.0153 Acc@1: 53.918%\n","\n","| Validation Epoch #789\t\t\tLoss: 0.0798 Acc@1: 65.42%\n","\n","=> Training Epoch #790, LR=0.0322\n","| Epoch [790/1080] Iter[  1/588]\t\tLoss: 2.9980 Acc@1: 46.875%\n","| Epoch [790/1080] Iter[ 16/588]\t\tLoss: 2.7600 Acc@1: 54.036%\n","| Epoch [790/1080] Iter[ 31/588]\t\tLoss: 2.9883 Acc@1: 53.663%\n","| Epoch [790/1080] Iter[ 46/588]\t\tLoss: 2.4834 Acc@1: 54.121%\n","\n","| Validation Epoch #790\t\t\tLoss: 0.3876 Acc@1: 64.90%\n","\n","=> Training Epoch #791, LR=0.0321\n","| Epoch [791/1080] Iter[  1/588]\t\tLoss: 3.0384 Acc@1: 55.208%\n","| Epoch [791/1080] Iter[ 16/588]\t\tLoss: 2.9029 Acc@1: 54.753%\n","| Epoch [791/1080] Iter[ 31/588]\t\tLoss: 3.1410 Acc@1: 53.763%\n","| Epoch [791/1080] Iter[ 46/588]\t\tLoss: 2.8787 Acc@1: 54.008%\n","\n","| Validation Epoch #791\t\t\tLoss: 0.5551 Acc@1: 68.38%\n","\n","=> Training Epoch #792, LR=0.0321\n","| Epoch [792/1080] Iter[  1/588]\t\tLoss: 2.8425 Acc@1: 55.208%\n","| Epoch [792/1080] Iter[ 16/588]\t\tLoss: 2.8108 Acc@1: 53.906%\n","| Epoch [792/1080] Iter[ 31/588]\t\tLoss: 2.8853 Acc@1: 55.276%\n","| Epoch [792/1080] Iter[ 46/588]\t\tLoss: 2.9648 Acc@1: 54.823%\n","\n","| Validation Epoch #792\t\t\tLoss: 0.0019 Acc@1: 69.30%\n","\n","=> Training Epoch #793, LR=0.0320\n","| Epoch [793/1080] Iter[  1/588]\t\tLoss: 2.7804 Acc@1: 53.125%\n","| Epoch [793/1080] Iter[ 16/588]\t\tLoss: 2.9174 Acc@1: 54.818%\n","| Epoch [793/1080] Iter[ 31/588]\t\tLoss: 2.8254 Acc@1: 55.242%\n","| Epoch [793/1080] Iter[ 46/588]\t\tLoss: 3.2324 Acc@1: 54.755%\n","\n","| Validation Epoch #793\t\t\tLoss: 0.0022 Acc@1: 62.42%\n","\n","=> Training Epoch #794, LR=0.0320\n","| Epoch [794/1080] Iter[  1/588]\t\tLoss: 2.9419 Acc@1: 54.167%\n","| Epoch [794/1080] Iter[ 16/588]\t\tLoss: 2.6209 Acc@1: 55.013%\n","| Epoch [794/1080] Iter[ 31/588]\t\tLoss: 2.8589 Acc@1: 54.267%\n","| Epoch [794/1080] Iter[ 46/588]\t\tLoss: 3.0751 Acc@1: 54.280%\n","\n","| Validation Epoch #794\t\t\tLoss: 0.1509 Acc@1: 68.72%\n","\n","=> Training Epoch #795, LR=0.0319\n","| Epoch [795/1080] Iter[  1/588]\t\tLoss: 2.5876 Acc@1: 63.542%\n","| Epoch [795/1080] Iter[ 16/588]\t\tLoss: 2.8798 Acc@1: 56.966%\n","| Epoch [795/1080] Iter[ 31/588]\t\tLoss: 2.9547 Acc@1: 55.410%\n","| Epoch [795/1080] Iter[ 46/588]\t\tLoss: 3.0164 Acc@1: 54.416%\n","\n","| Validation Epoch #795\t\t\tLoss: 0.0437 Acc@1: 66.80%\n","\n","=> Training Epoch #796, LR=0.0318\n","| Epoch [796/1080] Iter[  1/588]\t\tLoss: 2.9315 Acc@1: 53.125%\n","| Epoch [796/1080] Iter[ 16/588]\t\tLoss: 3.0125 Acc@1: 53.451%\n","| Epoch [796/1080] Iter[ 31/588]\t\tLoss: 2.9400 Acc@1: 54.368%\n","| Epoch [796/1080] Iter[ 46/588]\t\tLoss: 2.9843 Acc@1: 54.438%\n","\n","| Validation Epoch #796\t\t\tLoss: 0.1281 Acc@1: 67.40%\n","\n","=> Training Epoch #797, LR=0.0318\n","| Epoch [797/1080] Iter[  1/588]\t\tLoss: 2.8588 Acc@1: 54.167%\n","| Epoch [797/1080] Iter[ 16/588]\t\tLoss: 2.8422 Acc@1: 56.055%\n","| Epoch [797/1080] Iter[ 31/588]\t\tLoss: 2.8664 Acc@1: 55.074%\n","| Epoch [797/1080] Iter[ 46/588]\t\tLoss: 2.9789 Acc@1: 54.348%\n","\n","| Validation Epoch #797\t\t\tLoss: 0.3695 Acc@1: 66.98%\n","\n","=> Training Epoch #798, LR=0.0317\n","| Epoch [798/1080] Iter[  1/588]\t\tLoss: 2.9747 Acc@1: 51.042%\n","| Epoch [798/1080] Iter[ 16/588]\t\tLoss: 2.9544 Acc@1: 51.823%\n","| Epoch [798/1080] Iter[ 31/588]\t\tLoss: 2.7193 Acc@1: 52.991%\n","| Epoch [798/1080] Iter[ 46/588]\t\tLoss: 2.6782 Acc@1: 53.668%\n","\n","| Validation Epoch #798\t\t\tLoss: 0.0004 Acc@1: 67.06%\n","\n","=> Training Epoch #799, LR=0.0316\n","| Epoch [799/1080] Iter[  1/588]\t\tLoss: 2.8174 Acc@1: 57.292%\n","| Epoch [799/1080] Iter[ 16/588]\t\tLoss: 2.7519 Acc@1: 53.841%\n","| Epoch [799/1080] Iter[ 31/588]\t\tLoss: 2.8471 Acc@1: 54.469%\n","| Epoch [799/1080] Iter[ 46/588]\t\tLoss: 2.8747 Acc@1: 54.461%\n","\n","| Validation Epoch #799\t\t\tLoss: 0.3106 Acc@1: 62.26%\n","\n","=> Training Epoch #800, LR=0.0316\n","| Epoch [800/1080] Iter[  1/588]\t\tLoss: 2.9671 Acc@1: 56.250%\n","| Epoch [800/1080] Iter[ 16/588]\t\tLoss: 2.7047 Acc@1: 54.362%\n","| Epoch [800/1080] Iter[ 31/588]\t\tLoss: 3.0313 Acc@1: 54.032%\n","| Epoch [800/1080] Iter[ 46/588]\t\tLoss: 2.9807 Acc@1: 53.691%\n","\n","| Validation Epoch #800\t\t\tLoss: 0.0121 Acc@1: 67.08%\n","\n","=> Training Epoch #801, LR=0.0315\n","| Epoch [801/1080] Iter[  1/588]\t\tLoss: 2.5472 Acc@1: 63.542%\n","| Epoch [801/1080] Iter[ 16/588]\t\tLoss: 3.1996 Acc@1: 53.516%\n","| Epoch [801/1080] Iter[ 31/588]\t\tLoss: 2.9357 Acc@1: 53.931%\n","| Epoch [801/1080] Iter[ 46/588]\t\tLoss: 2.7023 Acc@1: 54.099%\n","\n","| Validation Epoch #801\t\t\tLoss: 0.0177 Acc@1: 71.42%\n","| Saving Best model...\t\t\tTop1 = 71.42%\n","\n","=> Training Epoch #802, LR=0.0314\n","| Epoch [802/1080] Iter[  1/588]\t\tLoss: 2.7187 Acc@1: 62.500%\n","| Epoch [802/1080] Iter[ 16/588]\t\tLoss: 2.8275 Acc@1: 55.339%\n","| Epoch [802/1080] Iter[ 31/588]\t\tLoss: 2.9436 Acc@1: 54.671%\n","| Epoch [802/1080] Iter[ 46/588]\t\tLoss: 2.5237 Acc@1: 54.574%\n","\n","| Validation Epoch #802\t\t\tLoss: 0.1117 Acc@1: 67.24%\n","\n","=> Training Epoch #803, LR=0.0314\n","| Epoch [803/1080] Iter[  1/588]\t\tLoss: 2.9702 Acc@1: 55.208%\n","| Epoch [803/1080] Iter[ 16/588]\t\tLoss: 2.9913 Acc@1: 54.688%\n","| Epoch [803/1080] Iter[ 31/588]\t\tLoss: 2.6528 Acc@1: 54.368%\n","| Epoch [803/1080] Iter[ 46/588]\t\tLoss: 2.7582 Acc@1: 53.963%\n","\n","| Validation Epoch #803\t\t\tLoss: 0.0579 Acc@1: 63.92%\n","\n","=> Training Epoch #804, LR=0.0313\n","| Epoch [804/1080] Iter[  1/588]\t\tLoss: 3.1443 Acc@1: 45.833%\n","| Epoch [804/1080] Iter[ 16/588]\t\tLoss: 2.6359 Acc@1: 54.036%\n","| Epoch [804/1080] Iter[ 31/588]\t\tLoss: 2.7216 Acc@1: 54.301%\n","| Epoch [804/1080] Iter[ 46/588]\t\tLoss: 3.0150 Acc@1: 54.506%\n","\n","| Validation Epoch #804\t\t\tLoss: 0.0205 Acc@1: 65.80%\n","\n","=> Training Epoch #805, LR=0.0312\n","| Epoch [805/1080] Iter[  1/588]\t\tLoss: 2.7528 Acc@1: 58.333%\n","| Epoch [805/1080] Iter[ 16/588]\t\tLoss: 2.8930 Acc@1: 56.120%\n","| Epoch [805/1080] Iter[ 31/588]\t\tLoss: 3.0391 Acc@1: 55.645%\n","| Epoch [805/1080] Iter[ 46/588]\t\tLoss: 3.0075 Acc@1: 54.937%\n","\n","| Validation Epoch #805\t\t\tLoss: 0.0021 Acc@1: 64.18%\n","\n","=> Training Epoch #806, LR=0.0312\n","| Epoch [806/1080] Iter[  1/588]\t\tLoss: 2.9422 Acc@1: 52.083%\n","| Epoch [806/1080] Iter[ 16/588]\t\tLoss: 2.8505 Acc@1: 54.948%\n","| Epoch [806/1080] Iter[ 31/588]\t\tLoss: 2.8958 Acc@1: 55.007%\n","| Epoch [806/1080] Iter[ 46/588]\t\tLoss: 2.9883 Acc@1: 54.801%\n","\n","| Validation Epoch #806\t\t\tLoss: 0.7621 Acc@1: 64.58%\n","\n","=> Training Epoch #807, LR=0.0311\n","| Epoch [807/1080] Iter[  1/588]\t\tLoss: 2.5314 Acc@1: 60.417%\n","| Epoch [807/1080] Iter[ 16/588]\t\tLoss: 3.1886 Acc@1: 53.776%\n","| Epoch [807/1080] Iter[ 31/588]\t\tLoss: 2.8202 Acc@1: 53.898%\n","| Epoch [807/1080] Iter[ 46/588]\t\tLoss: 2.9821 Acc@1: 54.121%\n","\n","| Validation Epoch #807\t\t\tLoss: 0.1187 Acc@1: 60.58%\n","\n","=> Training Epoch #808, LR=0.0310\n","| Epoch [808/1080] Iter[  1/588]\t\tLoss: 3.0152 Acc@1: 54.167%\n","| Epoch [808/1080] Iter[ 16/588]\t\tLoss: 3.0118 Acc@1: 54.102%\n","| Epoch [808/1080] Iter[ 31/588]\t\tLoss: 3.0209 Acc@1: 54.301%\n","| Epoch [808/1080] Iter[ 46/588]\t\tLoss: 3.0681 Acc@1: 54.416%\n","\n","| Validation Epoch #808\t\t\tLoss: 0.0052 Acc@1: 68.32%\n","\n","=> Training Epoch #809, LR=0.0310\n","| Epoch [809/1080] Iter[  1/588]\t\tLoss: 2.8228 Acc@1: 54.167%\n","| Epoch [809/1080] Iter[ 16/588]\t\tLoss: 2.6889 Acc@1: 55.143%\n","| Epoch [809/1080] Iter[ 31/588]\t\tLoss: 2.8678 Acc@1: 53.864%\n","| Epoch [809/1080] Iter[ 46/588]\t\tLoss: 2.8441 Acc@1: 54.121%\n","\n","| Validation Epoch #809\t\t\tLoss: 0.1267 Acc@1: 66.82%\n","\n","=> Training Epoch #810, LR=0.0309\n","| Epoch [810/1080] Iter[  1/588]\t\tLoss: 2.7056 Acc@1: 53.125%\n","| Epoch [810/1080] Iter[ 16/588]\t\tLoss: 2.7564 Acc@1: 53.581%\n","| Epoch [810/1080] Iter[ 31/588]\t\tLoss: 2.7517 Acc@1: 53.898%\n","| Epoch [810/1080] Iter[ 46/588]\t\tLoss: 2.9153 Acc@1: 54.325%\n","\n","| Validation Epoch #810\t\t\tLoss: 0.0152 Acc@1: 66.80%\n","\n","=> Training Epoch #811, LR=0.0308\n","| Epoch [811/1080] Iter[  1/588]\t\tLoss: 2.9786 Acc@1: 53.125%\n","| Epoch [811/1080] Iter[ 16/588]\t\tLoss: 3.0371 Acc@1: 53.646%\n","| Epoch [811/1080] Iter[ 31/588]\t\tLoss: 2.8280 Acc@1: 54.099%\n","| Epoch [811/1080] Iter[ 46/588]\t\tLoss: 3.0035 Acc@1: 54.257%\n","\n","| Validation Epoch #811\t\t\tLoss: 0.0567 Acc@1: 66.38%\n","\n","=> Training Epoch #812, LR=0.0308\n","| Epoch [812/1080] Iter[  1/588]\t\tLoss: 2.8174 Acc@1: 57.292%\n","| Epoch [812/1080] Iter[ 16/588]\t\tLoss: 2.9390 Acc@1: 54.232%\n","| Epoch [812/1080] Iter[ 31/588]\t\tLoss: 2.9480 Acc@1: 54.402%\n","| Epoch [812/1080] Iter[ 46/588]\t\tLoss: 3.2666 Acc@1: 54.506%\n","\n","| Validation Epoch #812\t\t\tLoss: 0.3758 Acc@1: 62.82%\n","\n","=> Training Epoch #813, LR=0.0307\n","| Epoch [813/1080] Iter[  1/588]\t\tLoss: 3.0769 Acc@1: 52.083%\n","| Epoch [813/1080] Iter[ 16/588]\t\tLoss: 2.8518 Acc@1: 53.385%\n","| Epoch [813/1080] Iter[ 31/588]\t\tLoss: 2.8998 Acc@1: 52.823%\n","| Epoch [813/1080] Iter[ 46/588]\t\tLoss: 2.9043 Acc@1: 53.442%\n","\n","| Validation Epoch #813\t\t\tLoss: 0.0605 Acc@1: 67.10%\n","\n","=> Training Epoch #814, LR=0.0306\n","| Epoch [814/1080] Iter[  1/588]\t\tLoss: 2.7719 Acc@1: 55.208%\n","| Epoch [814/1080] Iter[ 16/588]\t\tLoss: 2.8083 Acc@1: 56.445%\n","| Epoch [814/1080] Iter[ 31/588]\t\tLoss: 2.8000 Acc@1: 54.133%\n","| Epoch [814/1080] Iter[ 46/588]\t\tLoss: 3.0267 Acc@1: 53.963%\n","\n","| Validation Epoch #814\t\t\tLoss: 0.0044 Acc@1: 65.42%\n","\n","=> Training Epoch #815, LR=0.0306\n","| Epoch [815/1080] Iter[  1/588]\t\tLoss: 3.0485 Acc@1: 52.083%\n","| Epoch [815/1080] Iter[ 16/588]\t\tLoss: 2.7710 Acc@1: 52.865%\n","| Epoch [815/1080] Iter[ 31/588]\t\tLoss: 3.1212 Acc@1: 54.167%\n","| Epoch [815/1080] Iter[ 46/588]\t\tLoss: 3.1371 Acc@1: 54.597%\n","\n","| Validation Epoch #815\t\t\tLoss: 0.0026 Acc@1: 62.46%\n","\n","=> Training Epoch #816, LR=0.0305\n","| Epoch [816/1080] Iter[  1/588]\t\tLoss: 3.0350 Acc@1: 53.125%\n","| Epoch [816/1080] Iter[ 16/588]\t\tLoss: 2.9228 Acc@1: 55.013%\n","| Epoch [816/1080] Iter[ 31/588]\t\tLoss: 3.0954 Acc@1: 53.495%\n","| Epoch [816/1080] Iter[ 46/588]\t\tLoss: 2.9245 Acc@1: 53.714%\n","\n","| Validation Epoch #816\t\t\tLoss: 0.0523 Acc@1: 64.52%\n","\n","=> Training Epoch #817, LR=0.0305\n","| Epoch [817/1080] Iter[  1/588]\t\tLoss: 2.8728 Acc@1: 56.250%\n","| Epoch [817/1080] Iter[ 16/588]\t\tLoss: 3.1148 Acc@1: 54.036%\n","| Epoch [817/1080] Iter[ 31/588]\t\tLoss: 2.7837 Acc@1: 54.872%\n","| Epoch [817/1080] Iter[ 46/588]\t\tLoss: 3.0826 Acc@1: 54.823%\n","\n","| Validation Epoch #817\t\t\tLoss: 0.2013 Acc@1: 66.96%\n","\n","=> Training Epoch #818, LR=0.0304\n","| Epoch [818/1080] Iter[  1/588]\t\tLoss: 3.0391 Acc@1: 53.125%\n","| Epoch [818/1080] Iter[ 16/588]\t\tLoss: 3.1447 Acc@1: 52.865%\n","| Epoch [818/1080] Iter[ 31/588]\t\tLoss: 3.0664 Acc@1: 52.621%\n","| Epoch [818/1080] Iter[ 46/588]\t\tLoss: 2.8011 Acc@1: 53.668%\n","\n","| Validation Epoch #818\t\t\tLoss: 0.5906 Acc@1: 66.70%\n","\n","=> Training Epoch #819, LR=0.0303\n","| Epoch [819/1080] Iter[  1/588]\t\tLoss: 2.6515 Acc@1: 55.208%\n","| Epoch [819/1080] Iter[ 16/588]\t\tLoss: 2.8876 Acc@1: 54.622%\n","| Epoch [819/1080] Iter[ 31/588]\t\tLoss: 2.7407 Acc@1: 54.772%\n","| Epoch [819/1080] Iter[ 46/588]\t\tLoss: 2.7657 Acc@1: 54.303%\n","\n","| Validation Epoch #819\t\t\tLoss: 0.1689 Acc@1: 59.74%\n","\n","=> Training Epoch #820, LR=0.0303\n","| Epoch [820/1080] Iter[  1/588]\t\tLoss: 2.8209 Acc@1: 53.125%\n","| Epoch [820/1080] Iter[ 16/588]\t\tLoss: 2.9290 Acc@1: 55.273%\n","| Epoch [820/1080] Iter[ 31/588]\t\tLoss: 2.6832 Acc@1: 54.906%\n","| Epoch [820/1080] Iter[ 46/588]\t\tLoss: 3.0990 Acc@1: 54.597%\n","\n","| Validation Epoch #820\t\t\tLoss: 0.0581 Acc@1: 69.28%\n","\n","=> Training Epoch #821, LR=0.0302\n","| Epoch [821/1080] Iter[  1/588]\t\tLoss: 2.9341 Acc@1: 55.208%\n","| Epoch [821/1080] Iter[ 16/588]\t\tLoss: 2.5955 Acc@1: 54.753%\n","| Epoch [821/1080] Iter[ 31/588]\t\tLoss: 2.8940 Acc@1: 53.999%\n","| Epoch [821/1080] Iter[ 46/588]\t\tLoss: 2.8601 Acc@1: 54.099%\n","\n","| Validation Epoch #821\t\t\tLoss: 0.0068 Acc@1: 62.72%\n","\n","=> Training Epoch #822, LR=0.0301\n","| Epoch [822/1080] Iter[  1/588]\t\tLoss: 3.0936 Acc@1: 50.000%\n","| Epoch [822/1080] Iter[ 16/588]\t\tLoss: 2.6992 Acc@1: 55.794%\n","| Epoch [822/1080] Iter[ 31/588]\t\tLoss: 3.1753 Acc@1: 54.906%\n","| Epoch [822/1080] Iter[ 46/588]\t\tLoss: 2.9716 Acc@1: 54.167%\n","\n","| Validation Epoch #822\t\t\tLoss: 0.0017 Acc@1: 67.84%\n","\n","=> Training Epoch #823, LR=0.0301\n","| Epoch [823/1080] Iter[  1/588]\t\tLoss: 2.6867 Acc@1: 58.333%\n","| Epoch [823/1080] Iter[ 16/588]\t\tLoss: 2.7207 Acc@1: 54.297%\n","| Epoch [823/1080] Iter[ 31/588]\t\tLoss: 2.7915 Acc@1: 54.335%\n","| Epoch [823/1080] Iter[ 46/588]\t\tLoss: 2.9628 Acc@1: 54.031%\n","\n","| Validation Epoch #823\t\t\tLoss: 0.0470 Acc@1: 66.46%\n","\n","=> Training Epoch #824, LR=0.0300\n","| Epoch [824/1080] Iter[  1/588]\t\tLoss: 2.6696 Acc@1: 55.208%\n","| Epoch [824/1080] Iter[ 16/588]\t\tLoss: 2.6668 Acc@1: 55.339%\n","| Epoch [824/1080] Iter[ 31/588]\t\tLoss: 2.9554 Acc@1: 54.738%\n","| Epoch [824/1080] Iter[ 46/588]\t\tLoss: 2.9382 Acc@1: 54.620%\n","\n","| Validation Epoch #824\t\t\tLoss: 0.0140 Acc@1: 67.70%\n","\n","=> Training Epoch #825, LR=0.0299\n","| Epoch [825/1080] Iter[  1/588]\t\tLoss: 2.9934 Acc@1: 50.000%\n","| Epoch [825/1080] Iter[ 16/588]\t\tLoss: 2.9645 Acc@1: 51.953%\n","| Epoch [825/1080] Iter[ 31/588]\t\tLoss: 2.9248 Acc@1: 53.427%\n","| Epoch [825/1080] Iter[ 46/588]\t\tLoss: 2.7557 Acc@1: 53.487%\n","\n","| Validation Epoch #825\t\t\tLoss: 0.0338 Acc@1: 65.96%\n","\n","=> Training Epoch #826, LR=0.0299\n","| Epoch [826/1080] Iter[  1/588]\t\tLoss: 2.7645 Acc@1: 57.292%\n","| Epoch [826/1080] Iter[ 16/588]\t\tLoss: 2.9627 Acc@1: 53.646%\n","| Epoch [826/1080] Iter[ 31/588]\t\tLoss: 3.0507 Acc@1: 53.965%\n","| Epoch [826/1080] Iter[ 46/588]\t\tLoss: 3.0699 Acc@1: 54.665%\n","\n","| Validation Epoch #826\t\t\tLoss: 0.2842 Acc@1: 65.92%\n","\n","=> Training Epoch #827, LR=0.0298\n","| Epoch [827/1080] Iter[  1/588]\t\tLoss: 3.1334 Acc@1: 51.042%\n","| Epoch [827/1080] Iter[ 16/588]\t\tLoss: 2.6872 Acc@1: 53.841%\n","| Epoch [827/1080] Iter[ 31/588]\t\tLoss: 2.7060 Acc@1: 54.469%\n","| Epoch [827/1080] Iter[ 46/588]\t\tLoss: 2.8600 Acc@1: 54.484%\n","\n","| Validation Epoch #827\t\t\tLoss: 0.0016 Acc@1: 67.46%\n","\n","=> Training Epoch #828, LR=0.0297\n","| Epoch [828/1080] Iter[  1/588]\t\tLoss: 2.7559 Acc@1: 56.250%\n","| Epoch [828/1080] Iter[ 16/588]\t\tLoss: 2.9506 Acc@1: 54.688%\n","| Epoch [828/1080] Iter[ 31/588]\t\tLoss: 2.6153 Acc@1: 54.200%\n","| Epoch [828/1080] Iter[ 46/588]\t\tLoss: 2.4516 Acc@1: 53.986%\n","\n","| Validation Epoch #828\t\t\tLoss: 0.1674 Acc@1: 68.18%\n","\n","=> Training Epoch #829, LR=0.0297\n","| Epoch [829/1080] Iter[  1/588]\t\tLoss: 2.7261 Acc@1: 56.250%\n","| Epoch [829/1080] Iter[ 16/588]\t\tLoss: 2.7649 Acc@1: 56.445%\n","| Epoch [829/1080] Iter[ 31/588]\t\tLoss: 2.7591 Acc@1: 55.040%\n","| Epoch [829/1080] Iter[ 46/588]\t\tLoss: 3.0798 Acc@1: 54.484%\n","\n","| Validation Epoch #829\t\t\tLoss: 0.0833 Acc@1: 66.80%\n","\n","=> Training Epoch #830, LR=0.0296\n","| Epoch [830/1080] Iter[  1/588]\t\tLoss: 2.9409 Acc@1: 52.083%\n","| Epoch [830/1080] Iter[ 16/588]\t\tLoss: 2.9681 Acc@1: 55.794%\n","| Epoch [830/1080] Iter[ 31/588]\t\tLoss: 2.8198 Acc@1: 54.973%\n","| Epoch [830/1080] Iter[ 46/588]\t\tLoss: 2.9764 Acc@1: 54.801%\n","\n","| Validation Epoch #830\t\t\tLoss: 0.2893 Acc@1: 63.36%\n","\n","=> Training Epoch #831, LR=0.0295\n","| Epoch [831/1080] Iter[  1/588]\t\tLoss: 2.8546 Acc@1: 52.083%\n","| Epoch [831/1080] Iter[ 16/588]\t\tLoss: 2.7794 Acc@1: 54.622%\n","| Epoch [831/1080] Iter[ 31/588]\t\tLoss: 2.9983 Acc@1: 55.141%\n","| Epoch [831/1080] Iter[ 46/588]\t\tLoss: 2.8736 Acc@1: 54.552%\n","\n","| Validation Epoch #831\t\t\tLoss: 0.1419 Acc@1: 67.06%\n","\n","=> Training Epoch #832, LR=0.0295\n","| Epoch [832/1080] Iter[  1/588]\t\tLoss: 3.1300 Acc@1: 50.000%\n","| Epoch [832/1080] Iter[ 16/588]\t\tLoss: 3.1020 Acc@1: 54.818%\n","| Epoch [832/1080] Iter[ 31/588]\t\tLoss: 2.7136 Acc@1: 54.402%\n","| Epoch [832/1080] Iter[ 46/588]\t\tLoss: 3.0061 Acc@1: 54.053%\n","\n","| Validation Epoch #832\t\t\tLoss: 0.3106 Acc@1: 68.10%\n","\n","=> Training Epoch #833, LR=0.0294\n","| Epoch [833/1080] Iter[  1/588]\t\tLoss: 2.7809 Acc@1: 58.333%\n","| Epoch [833/1080] Iter[ 16/588]\t\tLoss: 2.7795 Acc@1: 54.557%\n","| Epoch [833/1080] Iter[ 31/588]\t\tLoss: 2.8587 Acc@1: 54.402%\n","| Epoch [833/1080] Iter[ 46/588]\t\tLoss: 3.0198 Acc@1: 53.963%\n","\n","| Validation Epoch #833\t\t\tLoss: 0.1094 Acc@1: 69.26%\n","\n","=> Training Epoch #834, LR=0.0293\n","| Epoch [834/1080] Iter[  1/588]\t\tLoss: 3.0949 Acc@1: 47.917%\n","| Epoch [834/1080] Iter[ 16/588]\t\tLoss: 2.8729 Acc@1: 55.404%\n","| Epoch [834/1080] Iter[ 31/588]\t\tLoss: 2.9743 Acc@1: 55.208%\n","| Epoch [834/1080] Iter[ 46/588]\t\tLoss: 3.0004 Acc@1: 54.688%\n","\n","| Validation Epoch #834\t\t\tLoss: 0.0149 Acc@1: 65.70%\n","\n","=> Training Epoch #835, LR=0.0293\n","| Epoch [835/1080] Iter[  1/588]\t\tLoss: 3.0510 Acc@1: 52.083%\n","| Epoch [835/1080] Iter[ 16/588]\t\tLoss: 3.0644 Acc@1: 52.279%\n","| Epoch [835/1080] Iter[ 31/588]\t\tLoss: 2.8437 Acc@1: 53.629%\n","| Epoch [835/1080] Iter[ 46/588]\t\tLoss: 2.7044 Acc@1: 54.257%\n","\n","| Validation Epoch #835\t\t\tLoss: 0.3787 Acc@1: 68.20%\n","\n","=> Training Epoch #836, LR=0.0292\n","| Epoch [836/1080] Iter[  1/588]\t\tLoss: 2.6635 Acc@1: 55.208%\n","| Epoch [836/1080] Iter[ 16/588]\t\tLoss: 2.9253 Acc@1: 55.990%\n","| Epoch [836/1080] Iter[ 31/588]\t\tLoss: 2.8902 Acc@1: 55.208%\n","| Epoch [836/1080] Iter[ 46/588]\t\tLoss: 3.1256 Acc@1: 55.163%\n","\n","| Validation Epoch #836\t\t\tLoss: 0.0238 Acc@1: 63.82%\n","\n","=> Training Epoch #837, LR=0.0291\n","| Epoch [837/1080] Iter[  1/588]\t\tLoss: 2.9740 Acc@1: 53.125%\n","| Epoch [837/1080] Iter[ 16/588]\t\tLoss: 2.7276 Acc@1: 54.622%\n","| Epoch [837/1080] Iter[ 31/588]\t\tLoss: 2.9882 Acc@1: 54.301%\n","| Epoch [837/1080] Iter[ 46/588]\t\tLoss: 2.7236 Acc@1: 54.189%\n","\n","| Validation Epoch #837\t\t\tLoss: 0.1992 Acc@1: 67.30%\n","\n","=> Training Epoch #838, LR=0.0291\n","| Epoch [838/1080] Iter[  1/588]\t\tLoss: 2.4349 Acc@1: 64.583%\n","| Epoch [838/1080] Iter[ 16/588]\t\tLoss: 2.5675 Acc@1: 55.990%\n","| Epoch [838/1080] Iter[ 31/588]\t\tLoss: 2.9631 Acc@1: 54.738%\n","| Epoch [838/1080] Iter[ 46/588]\t\tLoss: 2.8402 Acc@1: 54.257%\n","\n","| Validation Epoch #838\t\t\tLoss: 0.2139 Acc@1: 64.74%\n","\n","=> Training Epoch #839, LR=0.0290\n","| Epoch [839/1080] Iter[  1/588]\t\tLoss: 2.6559 Acc@1: 59.375%\n","| Epoch [839/1080] Iter[ 16/588]\t\tLoss: 2.6934 Acc@1: 53.906%\n","| Epoch [839/1080] Iter[ 31/588]\t\tLoss: 3.1322 Acc@1: 53.595%\n","| Epoch [839/1080] Iter[ 46/588]\t\tLoss: 2.7180 Acc@1: 54.574%\n","\n","| Validation Epoch #839\t\t\tLoss: 0.1939 Acc@1: 64.66%\n","| New Samples 36062\n","\n","=> Training Epoch #840, LR=0.0289\n","| Epoch [840/1080] Iter[  1/610]\t\tLoss: 3.1573 Acc@1: 45.833%\n","| Epoch [840/1080] Iter[ 16/610]\t\tLoss: 2.8019 Acc@1: 53.776%\n","| Epoch [840/1080] Iter[ 31/610]\t\tLoss: 2.9632 Acc@1: 54.368%\n","| Epoch [840/1080] Iter[ 46/610]\t\tLoss: 2.9052 Acc@1: 53.736%\n","\n","| Validation Epoch #840\t\t\tLoss: 0.2896 Acc@1: 67.06%\n","\n","=> Training Epoch #841, LR=0.0289\n","| Epoch [841/1080] Iter[  1/610]\t\tLoss: 2.7239 Acc@1: 56.250%\n","| Epoch [841/1080] Iter[ 16/610]\t\tLoss: 2.9166 Acc@1: 54.688%\n","| Epoch [841/1080] Iter[ 31/610]\t\tLoss: 3.0157 Acc@1: 54.032%\n","| Epoch [841/1080] Iter[ 46/610]\t\tLoss: 2.7440 Acc@1: 53.442%\n","\n","| Validation Epoch #841\t\t\tLoss: 0.4191 Acc@1: 65.52%\n","\n","=> Training Epoch #842, LR=0.0288\n","| Epoch [842/1080] Iter[  1/610]\t\tLoss: 2.9074 Acc@1: 52.083%\n","| Epoch [842/1080] Iter[ 16/610]\t\tLoss: 2.7846 Acc@1: 54.036%\n","| Epoch [842/1080] Iter[ 31/610]\t\tLoss: 3.1283 Acc@1: 54.671%\n","| Epoch [842/1080] Iter[ 46/610]\t\tLoss: 3.0306 Acc@1: 54.755%\n","\n","| Validation Epoch #842\t\t\tLoss: 0.0345 Acc@1: 63.32%\n","\n","=> Training Epoch #843, LR=0.0287\n","| Epoch [843/1080] Iter[  1/610]\t\tLoss: 2.6952 Acc@1: 56.250%\n","| Epoch [843/1080] Iter[ 16/610]\t\tLoss: 3.0336 Acc@1: 54.492%\n","| Epoch [843/1080] Iter[ 31/610]\t\tLoss: 2.9911 Acc@1: 53.965%\n","| Epoch [843/1080] Iter[ 46/610]\t\tLoss: 2.9680 Acc@1: 54.144%\n","\n","| Validation Epoch #843\t\t\tLoss: 0.3346 Acc@1: 66.30%\n","\n","=> Training Epoch #844, LR=0.0287\n","| Epoch [844/1080] Iter[  1/610]\t\tLoss: 2.9331 Acc@1: 55.208%\n","| Epoch [844/1080] Iter[ 16/610]\t\tLoss: 3.0851 Acc@1: 53.906%\n","| Epoch [844/1080] Iter[ 31/610]\t\tLoss: 3.3300 Acc@1: 54.133%\n","| Epoch [844/1080] Iter[ 46/610]\t\tLoss: 3.1711 Acc@1: 53.963%\n","\n","| Validation Epoch #844\t\t\tLoss: 0.0059 Acc@1: 66.84%\n","\n","=> Training Epoch #845, LR=0.0286\n","| Epoch [845/1080] Iter[  1/610]\t\tLoss: 2.5927 Acc@1: 59.375%\n","| Epoch [845/1080] Iter[ 16/610]\t\tLoss: 2.7447 Acc@1: 54.362%\n","| Epoch [845/1080] Iter[ 31/610]\t\tLoss: 2.9899 Acc@1: 53.831%\n","| Epoch [845/1080] Iter[ 46/610]\t\tLoss: 2.8641 Acc@1: 52.921%\n","\n","| Validation Epoch #845\t\t\tLoss: 0.2146 Acc@1: 66.72%\n","\n","=> Training Epoch #846, LR=0.0285\n","| Epoch [846/1080] Iter[  1/610]\t\tLoss: 2.9925 Acc@1: 55.208%\n","| Epoch [846/1080] Iter[ 16/610]\t\tLoss: 2.8170 Acc@1: 55.273%\n","| Epoch [846/1080] Iter[ 31/610]\t\tLoss: 2.9952 Acc@1: 53.898%\n","| Epoch [846/1080] Iter[ 46/610]\t\tLoss: 2.7798 Acc@1: 54.099%\n","\n","| Validation Epoch #846\t\t\tLoss: 0.4479 Acc@1: 65.70%\n","\n","=> Training Epoch #847, LR=0.0285\n","| Epoch [847/1080] Iter[  1/610]\t\tLoss: 2.8954 Acc@1: 57.292%\n","| Epoch [847/1080] Iter[ 16/610]\t\tLoss: 3.1538 Acc@1: 54.688%\n","| Epoch [847/1080] Iter[ 31/610]\t\tLoss: 2.6882 Acc@1: 54.671%\n","| Epoch [847/1080] Iter[ 46/610]\t\tLoss: 2.8793 Acc@1: 54.529%\n","\n","| Validation Epoch #847\t\t\tLoss: 0.1566 Acc@1: 67.00%\n","\n","=> Training Epoch #848, LR=0.0284\n","| Epoch [848/1080] Iter[  1/610]\t\tLoss: 2.8361 Acc@1: 56.250%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZYfULdP_JA6i"},"source":["import pandas as pd\n","\n","\n","def test_final(net,testloader):\n","    global best_acc\n","    net.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets,index) in enumerate(testloader):\n","            \n","            inputs, targets = inputs.cuda(), targets.cuda()\n","            inputs, targets = Variable(inputs), Variable(targets)\n","            outputs = net(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            test_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets.data).cpu().sum()\n","            if batch_idx == 0:\n","                predicted_concat = predicted.clone()\n","            else:\n","                predicted_concat = torch.cat((predicted_concat, predicted), 0)\n","\n","        # Save checkpoint when best model\n","    acc = 100.*correct/total\n","    print(\"\\n| TEST \\t\\t\\tLoss: %.4f Acc@1: %.2f%%\" %( loss.item(), acc))\n","    return predicted_concat.cpu().numpy()\n","    \n","\n","predicted_concat = test_final(net_save,test_loader)\n","\n","\n","id_concat =range(len(predicted_concat))\n","my_submission = pd.DataFrame({'Id': id_concat,'Expected': predicted_concat})\n","\n","# you could use any filename. We choose submission here\n","my_submission.to_csv('submission2.csv', index=False)\n","print('We have saved the submission !! ')"],"execution_count":null,"outputs":[]}]}